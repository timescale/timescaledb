-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\c :TEST_DBNAME :ROLE_CLUSTER_SUPERUSER
CREATE OR REPLACE FUNCTION ts_bgw_log_register_emit_log_hook(application_name TEXT) RETURNS VOID
AS :MODULE_PATHNAME LANGUAGE C VOLATILE;
CREATE OR REPLACE FUNCTION ts_bgw_log_unregister_emit_log_hook() RETURNS VOID
AS :MODULE_PATHNAME LANGUAGE C VOLATILE;
CREATE OR REPLACE FUNCTION ts_bgw_params_create() RETURNS VOID
AS :MODULE_PATHNAME LANGUAGE C VOLATILE;
-- Create a user with specific timezone and mock time
CREATE ROLE test_cagg_refresh_policy_user WITH LOGIN;
GRANT ALL ON SCHEMA public TO test_cagg_refresh_policy_user;
\c :TEST_DBNAME test_cagg_refresh_policy_user
CREATE PROCEDURE run_job_with_log(job_id INTEGER)
AS
$$
BEGIN
    SET LOCAL application_name = 'cagg_policy_incremental';
    CALL run_job(job_id);
END;
$$
LANGUAGE plpgsql;
SET timezone TO 'UTC';
CREATE TABLE public.bgw_log(
    msg_no INT,
    mock_time BIGINT,
    application_name TEXT,
    msg TEXT
);
CREATE VIEW sorted_bgw_log AS
SELECT
    row_number() OVER () AS msg_no,
    regexp_replace(regexp_replace(msg, '(Wait until|started at|execution time) [0-9]+(\.[0-9]+)?', '\1 (RANDOM)', 'g'), 'background worker "[^"]+"','connection') AS msg
FROM
    bgw_log
WHERE
    msg !~ '^(statement:|duration:|LOG:  background worker "[^"]+" )'
    AND application_name = 'cagg_policy_incremental'
ORDER BY
    mock_time,
    application_name COLLATE "C",
    msg_no;
CREATE TABLE public.bgw_dsm_handle_store(
    handle BIGINT
);
INSERT INTO public.bgw_dsm_handle_store VALUES (0);
SELECT ts_bgw_params_create();
 ts_bgw_params_create 
----------------------
 
(1 row)

SELECT ts_bgw_log_register_emit_log_hook('cagg_policy_incremental');
 ts_bgw_log_register_emit_log_hook 
-----------------------------------
 
(1 row)

CREATE TABLE conditions (
    time         TIMESTAMP WITH TIME ZONE NOT NULL,
    device_id    INTEGER,
    temperature  NUMERIC
);
SELECT FROM create_hypertable('conditions', by_range('time'));
--
(1 row)

INSERT INTO conditions
SELECT
    t, d, 10
FROM
    generate_series(
        '2025-02-05 00:00:00+00',
        '2025-03-05 00:00:00+00',
        '1 hour'::interval) AS t,
    generate_series(1,5) AS d;
CREATE MATERIALIZED VIEW conditions_by_day
WITH (timescaledb.continuous, timescaledb.materialized_only=true) AS
SELECT
    time_bucket('1 day', time),
    device_id,
    count(*),
    min(temperature),
    max(temperature),
    avg(temperature),
    sum(temperature)
FROM
    conditions
GROUP BY
    1, 2
WITH NO DATA;
SELECT
    add_continuous_aggregate_policy(
        'conditions_by_day',
        start_offset => NULL,
        end_offset => NULL,
        schedule_interval => INTERVAL '1 h',
        initial_start => NOW() + INTERVAL '1 h',
        buckets_per_batch => 10
    ) AS job_id \gset
SELECT
    config
FROM
    timescaledb_information.jobs
WHERE
    job_id = :'job_id' \gset
CALL run_job_with_log(:'job_id');
SELECT * FROM sorted_bgw_log;
 msg_no |                                                                            msg                                                                            
--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------
      1 | no valid batches produced for continuous aggregate "public.conditions_by_day", falling back to single batch processing
      2 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Mon Nov 24 00:00:00 4714 UTC BC, Thu Mar 06 00:00:00 2025 UTC ]
      3 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      4 | inserted 145 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
(4 rows)

CREATE MATERIALIZED VIEW conditions_by_day_manual_refresh
WITH (timescaledb.continuous, timescaledb.materialized_only=true) AS
SELECT
    time_bucket('1 day', time),
    device_id,
    count(*),
    min(temperature),
    max(temperature),
    avg(temperature),
    sum(temperature)
FROM
    conditions
GROUP BY
    1, 2
WITH NO DATA;
CALL refresh_continuous_aggregate('conditions_by_day_manual_refresh', NULL, NULL);
SELECT count(*) FROM conditions_by_day;
 count 
-------
   145
(1 row)

SELECT count(*) FROM conditions_by_day_manual_refresh;
 count 
-------
   145
(1 row)

-- Should have no differences
SELECT
    count(*) > 0 AS has_diff
FROM
    ((SELECT * FROM conditions_by_day_manual_refresh ORDER BY 1, 2)
    EXCEPT
    (SELECT * FROM conditions_by_day ORDER BY 1, 2)) AS diff;
 has_diff 
----------
 f
(1 row)

TRUNCATE bgw_log, conditions_by_day;
SELECT
    config
FROM
    alter_job(
        :'job_id',
        config => jsonb_set(:'config', '{max_batches_per_execution}', '2')
    );
                                                           config                                                            
-----------------------------------------------------------------------------------------------------------------------------
 {"end_offset": null, "start_offset": null, "buckets_per_batch": 10, "mat_hypertable_id": 2, "max_batches_per_execution": 2}
(1 row)

CALL run_job_with_log(:'job_id');
SELECT * FROM sorted_bgw_log;
 msg_no |                                                                                  msg                                                                                  
--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
      1 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Sat Mar 01 00:00:00 2025 UTC, Thu Mar 06 00:00:00 2025 UTC ] (batch 1 of 4)
      2 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      3 | inserted 25 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
      4 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Wed Feb 19 00:00:00 2025 UTC, Sat Mar 01 00:00:00 2025 UTC ] (batch 2 of 4)
      5 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      6 | inserted 50 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
      7 | reached maximum number of batches per execution (2), batches not processed (2)
(7 rows)

SELECT count(*) FROM conditions_by_day;
 count 
-------
    75
(1 row)

SELECT count(*) FROM conditions_by_day_manual_refresh;
 count 
-------
   145
(1 row)

-- Should have differences
SELECT
    count(*) > 0 AS has_diff
FROM
    ((SELECT * FROM conditions_by_day_manual_refresh ORDER BY 1, 2)
    EXCEPT
    (SELECT * FROM conditions_by_day ORDER BY 1, 2)) AS diff;
 has_diff 
----------
 t
(1 row)

CALL run_job_with_log(:'job_id');
SELECT * FROM sorted_bgw_log;
 msg_no |                                                                                   msg                                                                                    
--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      1 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Sat Mar 01 00:00:00 2025 UTC, Thu Mar 06 00:00:00 2025 UTC ] (batch 1 of 4)
      2 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      3 | inserted 25 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
      4 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Wed Feb 19 00:00:00 2025 UTC, Sat Mar 01 00:00:00 2025 UTC ] (batch 2 of 4)
      5 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      6 | inserted 50 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
      7 | reached maximum number of batches per execution (2), batches not processed (2)
      8 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Sun Feb 09 00:00:00 2025 UTC, Wed Feb 19 00:00:00 2025 UTC ] (batch 1 of 2)
      9 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
     10 | inserted 50 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
     11 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Mon Nov 24 00:00:00 4714 UTC BC, Sun Feb 09 00:00:00 2025 UTC ] (batch 2 of 2)
     12 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
     13 | inserted 20 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
(13 rows)

-- Should have no differences
SELECT
    count(*) > 0 AS has_diff
FROM
    ((SELECT * FROM conditions_by_day_manual_refresh ORDER BY 1, 2)
    EXCEPT
    (SELECT * FROM conditions_by_day ORDER BY 1, 2)) AS diff;
 has_diff 
----------
 f
(1 row)

-- Set max_batches_per_execution to 10
SELECT
    config
FROM
    alter_job(
        :'job_id',
        config => jsonb_set(:'config', '{max_batches_per_execution}', '10')
    );
                                                            config                                                            
------------------------------------------------------------------------------------------------------------------------------
 {"end_offset": null, "start_offset": null, "buckets_per_batch": 10, "mat_hypertable_id": 2, "max_batches_per_execution": 10}
(1 row)

TRUNCATE bgw_log;
-- Insert data into the past
INSERT INTO conditions
SELECT
    t, d, 10
FROM
    generate_series(
        '2020-02-05 00:00:00+00',
        '2020-03-05 00:00:00+00',
        '1 hour'::interval) AS t,
    generate_series(1,5) AS d;
CALL run_job_with_log(:'job_id');
SELECT * FROM sorted_bgw_log;
 msg_no |                                                                                  msg                                                                                  
--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
      1 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Sat Feb 29 00:00:00 2020 UTC, Fri Mar 06 00:00:00 2020 UTC ] (batch 1 of 4)
      2 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      3 | inserted 30 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
      4 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Wed Feb 19 00:00:00 2020 UTC, Sat Feb 29 00:00:00 2020 UTC ] (batch 2 of 4)
      5 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      6 | inserted 50 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
      7 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Sun Feb 09 00:00:00 2020 UTC, Wed Feb 19 00:00:00 2020 UTC ] (batch 3 of 4)
      8 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      9 | inserted 50 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
     10 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Wed Feb 05 00:00:00 2020 UTC, Sun Feb 09 00:00:00 2020 UTC ] (batch 4 of 4)
     11 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
     12 | inserted 20 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
(12 rows)

SELECT count(*) FROM conditions_by_day;
 count 
-------
   295
(1 row)

SELECT count(*) FROM conditions_by_day_manual_refresh;
 count 
-------
   145
(1 row)

CALL refresh_continuous_aggregate('conditions_by_day_manual_refresh', NULL, NULL);
SELECT count(*) FROM conditions_by_day;
 count 
-------
   295
(1 row)

SELECT count(*) FROM conditions_by_day_manual_refresh;
 count 
-------
   295
(1 row)

-- Should have no differences
SELECT
    count(*) > 0 AS has_diff
FROM
    ((SELECT * FROM conditions_by_day_manual_refresh ORDER BY 1, 2)
    EXCEPT
    (SELECT * FROM conditions_by_day ORDER BY 1, 2)) AS diff;
 has_diff 
----------
 f
(1 row)

-- Check invalid configurations
\set ON_ERROR_STOP 0
\set VERBOSITY default
SELECT
    config
FROM
    alter_job(
        :'job_id',
        config => jsonb_set(:'config', '{max_batches_per_execution}', '-1')
    );
ERROR:  invalid max batches per execution
DETAIL:  max_batches_per_execution: -1
HINT:  The max batches per execution should be greater than or equal to zero.
SELECT
    config
FROM
    alter_job(
        :'job_id',
        config => jsonb_set(:'config', '{buckets_per_batch}', '-1')
    );
ERROR:  invalid buckets per batch
DETAIL:  buckets_per_batch: -1
HINT:  The buckets per batch should be greater than or equal to zero.
\set VERBOSITY terse
\set ON_ERROR_STOP 1
-- Truncate all data from the original hypertable
TRUNCATE bgw_log, conditions;
CALL run_job_with_log(:'job_id');
SELECT * FROM sorted_bgw_log;
 msg_no |                                                                            msg                                                                            
--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------
      1 | no min slice range start for continuous aggregate "public.conditions_by_day", falling back to single batch processing
      2 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Mon Nov 24 00:00:00 4714 UTC BC, Thu Mar 06 00:00:00 2025 UTC ]
      3 | deleted 295 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      4 | inserted 0 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
(4 rows)

-- Should return zero rows
SELECT count(*) FROM conditions_by_day;
 count 
-------
     0
(1 row)

-- 1 day of data
INSERT INTO conditions
SELECT
    t, d, 10
FROM
    generate_series(
        '2020-02-05 00:00:00+00',
        '2020-02-06 00:00:00+00',
        '1 hour'::interval) AS t,
    generate_series(1,5) AS d;
TRUNCATE bgw_log;
CALL run_job_with_log(:'job_id');
SELECT * FROM sorted_bgw_log;
 msg_no |                                                                          msg                                                                           
--------+--------------------------------------------------------------------------------------------------------------------------------------------------------
      1 | only one batch produced for continuous aggregate "public.conditions_by_day", falling back to single batch processing
      2 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Wed Feb 05 00:00:00 2020 UTC, Fri Feb 07 00:00:00 2020 UTC ]
      3 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      4 | inserted 10 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
(4 rows)

-- Should return 10 rows because the bucket width is `1 day` and buckets per batch is `10`
SELECT count(*) FROM conditions_by_day;
 count 
-------
    10
(1 row)

TRUNCATE conditions_by_day, conditions, bgw_log;
-- Less than 1 day of data (smaller than the bucket width)
INSERT INTO conditions
VALUES ('2020-02-05 00:00:00+00', 1, 10);
CALL run_job_with_log(:'job_id');
SELECT * FROM sorted_bgw_log;
 msg_no |                                                                            msg                                                                            
--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------
      1 | refresh window size (@ 7 days) is smaller than or equal to batch size (@ 10 days), falling back to single batch processing
      2 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Mon Nov 24 00:00:00 4714 UTC BC, Thu Mar 06 00:00:00 2025 UTC ]
      3 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      4 | inserted 1 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
(4 rows)

-- Should return 1 row
SELECT count(*) FROM conditions_by_day;
 count 
-------
     1
(1 row)

SELECT delete_job(:job_id);
 delete_job 
------------
 
(1 row)

SELECT
    add_continuous_aggregate_policy(
        'conditions_by_day',
        start_offset => NULL,
        end_offset => NULL,
        schedule_interval => INTERVAL '1 h',
        initial_start => NOW() + INTERVAL '1 h',
        buckets_per_batch => 5,
        refresh_newest_first => true -- explicitly set to true to test the default behavior
    ) AS job_id \gset
SELECT
    add_continuous_aggregate_policy(
        'conditions_by_day_manual_refresh',
        start_offset => NULL,
        end_offset => NULL,
        schedule_interval => INTERVAL '1 h',
        initial_start => NOW() + INTERVAL '1 h',
        buckets_per_batch => 0 -- 0 means no batching, so it will refresh all buckets in one go
    ) AS job_id_manual \gset
TRUNCATE bgw_log, conditions_by_day, conditions_by_day_manual_refresh, conditions;
INSERT INTO conditions
SELECT
    t, d, 10
FROM
    generate_series(
        '2025-03-11 00:00:00+00'::timestamptz - INTERVAL '30 days',
        '2025-03-11 00:00:00+00'::timestamptz,
        '1 hour'::interval) AS t,
    generate_series(1,5) AS d;
CALL run_job_with_log(:'job_id');
CALL run_job_with_log(:'job_id_manual');
SELECT * FROM sorted_bgw_log;
 msg_no |                                                                                   msg                                                                                    
--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      1 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Mon Mar 03 00:00:00 2025 UTC, Wed Mar 12 00:00:00 2025 UTC ] (batch 1 of 6)
      2 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      3 | inserted 45 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
      4 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Wed Feb 26 00:00:00 2025 UTC, Mon Mar 03 00:00:00 2025 UTC ] (batch 2 of 6)
      5 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      6 | inserted 25 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
      7 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Fri Feb 21 00:00:00 2025 UTC, Wed Feb 26 00:00:00 2025 UTC ] (batch 3 of 6)
      8 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      9 | inserted 25 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
     10 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Sun Feb 16 00:00:00 2025 UTC, Fri Feb 21 00:00:00 2025 UTC ] (batch 4 of 6)
     11 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
     12 | inserted 25 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
     13 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Tue Feb 11 00:00:00 2025 UTC, Sun Feb 16 00:00:00 2025 UTC ] (batch 5 of 6)
     14 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
     15 | inserted 25 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
     16 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Mon Nov 24 00:00:00 4714 UTC BC, Tue Feb 11 00:00:00 2025 UTC ] (batch 6 of 6)
     17 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
     18 | inserted 10 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
     19 | continuous aggregate refresh (individual invalidation) on "conditions_by_day_manual_refresh" in window [ Mon Nov 24 00:00:00 4714 UTC BC, Wed Mar 12 00:00:00 2025 UTC ]
     20 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_3"
     21 | inserted 155 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_3"
(21 rows)

-- Both continuous aggregates should have the same data
SELECT count(*) FROM conditions_by_day;
 count 
-------
   155
(1 row)

SELECT count(*) FROM conditions_by_day_manual_refresh;
 count 
-------
   155
(1 row)

-- Should have no differences
SELECT
    count(*) > 0 AS has_diff
FROM
    ((SELECT * FROM conditions_by_day_manual_refresh ORDER BY 1, 2)
    EXCEPT
    (SELECT * FROM conditions_by_day ORDER BY 1, 2)) AS diff;
 has_diff 
----------
 f
(1 row)

-- Testing with explicit refresh_newest_first = false (from oldest to newest)
SELECT delete_job(:job_id);
 delete_job 
------------
 
(1 row)

SELECT delete_job(:job_id_manual);
 delete_job 
------------
 
(1 row)

SELECT
    add_continuous_aggregate_policy(
        'conditions_by_day',
        start_offset => NULL,
        end_offset => NULL,
        schedule_interval => INTERVAL '1 h',
        initial_start => NOW() + INTERVAL '1 h',
        buckets_per_batch => 5,
        refresh_newest_first => false
    ) AS job_id \gset
SELECT
    config
FROM
    timescaledb_information.jobs
WHERE
    job_id = :'job_id';
                                                          config                                                           
---------------------------------------------------------------------------------------------------------------------------
 {"end_offset": null, "start_offset": null, "buckets_per_batch": 5, "mat_hypertable_id": 2, "refresh_newest_first": false}
(1 row)

TRUNCATE bgw_log, conditions_by_day;
CALL run_job_with_log(:'job_id');
SELECT * FROM sorted_bgw_log;
 msg_no |                                                                                   msg                                                                                    
--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      1 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Mon Nov 24 00:00:00 4714 UTC BC, Tue Feb 11 00:00:00 2025 UTC ] (batch 1 of 7)
      2 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      3 | inserted 10 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
      4 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Tue Feb 11 00:00:00 2025 UTC, Sun Feb 16 00:00:00 2025 UTC ] (batch 2 of 7)
      5 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      6 | inserted 25 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
      7 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Sun Feb 16 00:00:00 2025 UTC, Fri Feb 21 00:00:00 2025 UTC ] (batch 3 of 7)
      8 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
      9 | inserted 25 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
     10 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Fri Feb 21 00:00:00 2025 UTC, Wed Feb 26 00:00:00 2025 UTC ] (batch 4 of 7)
     11 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
     12 | inserted 25 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
     13 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Wed Feb 26 00:00:00 2025 UTC, Mon Mar 03 00:00:00 2025 UTC ] (batch 5 of 7)
     14 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
     15 | inserted 25 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
     16 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Mon Mar 03 00:00:00 2025 UTC, Sat Mar 08 00:00:00 2025 UTC ] (batch 6 of 7)
     17 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
     18 | inserted 25 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
     19 | continuous aggregate refresh (individual invalidation) on "conditions_by_day" in window [ Sat Mar 08 00:00:00 2025 UTC, Wed Mar 12 00:00:00 2025 UTC ] (batch 7 of 7)
     20 | deleted 0 row(s) from materialization table "_timescaledb_internal._materialized_hypertable_2"
     21 | inserted 20 row(s) into materialization table "_timescaledb_internal._materialized_hypertable_2"
(21 rows)

-- Both continuous aggregates should have the same data
SELECT count(*) FROM conditions_by_day;
 count 
-------
   155
(1 row)

SELECT count(*) FROM conditions_by_day_manual_refresh;
 count 
-------
   155
(1 row)

-- Should have no differences
SELECT
    count(*) > 0 AS has_diff
FROM
    ((SELECT * FROM conditions_by_day_manual_refresh ORDER BY 1, 2)
    EXCEPT
    (SELECT * FROM conditions_by_day ORDER BY 1, 2)) AS diff;
 has_diff 
----------
 f
(1 row)

SELECT ts_bgw_log_unregister_emit_log_hook();
 ts_bgw_log_unregister_emit_log_hook 
-------------------------------------
 
(1 row)

\c :TEST_DBNAME :ROLE_CLUSTER_SUPERUSER
REASSIGN OWNED BY test_cagg_refresh_policy_user TO :ROLE_CLUSTER_SUPERUSER;
REVOKE ALL ON SCHEMA public FROM test_cagg_refresh_policy_user;
DROP ROLE test_cagg_refresh_policy_user;
