-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
create table readings(time timestamptz,
       location text,
       device int,
       temp float,
       humidity float,
       unique (device, location, time)
);
create index on readings(location);
create index on readings(device);
select create_hypertable('readings', 'time');
NOTICE:  adding not-null constraint to column "time"
   create_hypertable   
-----------------------
 (1,public,readings,t)
(1 row)

select setseed(1);
 setseed 
---------
 
(1 row)

insert into readings (time, location, device, temp, humidity)
select t, ceil(random()*10), ceil(random()*30), random()*40, random()*100
from generate_series('2022-06-01'::timestamptz, '2022-07-01', '5s') t;
alter table readings set (
      timescaledb.compress,
      timescaledb.compress_orderby = 'time',
      timescaledb.compress_segmentby = 'device'
);
WARNING:  column "location" should be used for segmenting or ordering
select format('%I.%I', chunk_schema, chunk_name)::regclass as chunk
  from timescaledb_information.chunks
 where format('%I.%I', hypertable_schema, hypertable_name)::regclass = 'readings'::regclass
 limit 1 \gset
alter table :chunk set access method hyperstore;
--
-- Check that TID scan works for both compressed and non-compressed
-- rows.
--
set timescaledb.enable_transparent_decompression to false;
-- Select any row and try to fetch it using CTID. We do not select the
-- first one just to also try to scan a few rows and make sure the
-- implementation works.
select ctid from :chunk limit 1 offset 10 \gset
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select * from :chunk where ctid = :'ctid';
                      QUERY PLAN                      
------------------------------------------------------
 Tid Scan on _hyper_1_1_chunk (actual rows=1 loops=1)
   TID Cond: (ctid = '(2147483649,11)'::tid)
 Arrays read from cache: 0
 Arrays decompressed: 0
(4 rows)

select * from :chunk where ctid = :'ctid';
             time             | location | device |       temp       |     humidity     
------------------------------+----------+--------+------------------+------------------
 Wed Jun 01 00:19:20 2022 PDT | 8        |      1 | 18.1995372460622 | 31.5529442138474
(1 row)

-- Insert a new row, which will then be non-compressed, and fetch it.
insert into :chunk values ('Wed May 25 17:34:56 2022 PDT', 1, 2, 3.14, 2.14);
select ctid from :chunk where time = 'Wed May 25 17:34:56 2022 PDT' \gset
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select * from :chunk where ctid = :'ctid';
                      QUERY PLAN                      
------------------------------------------------------
 Tid Scan on _hyper_1_1_chunk (actual rows=1 loops=1)
   TID Cond: (ctid = '(0,1)'::tid)
 Arrays read from cache: 0
 Arrays decompressed: 0
(4 rows)

select * from :chunk where ctid = :'ctid';
             time             | location | device | temp | humidity 
------------------------------+----------+--------+------+----------
 Wed May 25 17:34:56 2022 PDT | 1        |      2 | 3.14 |     2.14
(1 row)

-- Check that a bad option name generates an error.
\set ON_ERROR_STOP 0
explain (analyze, costs off, timing off, summary off, decopress_cache_stats)
select * from :chunk where device between 5 and 10;
ERROR:  unrecognized EXPLAIN option "decopress_cache_stats" at character 55
\set ON_ERROR_STOP 1
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select time, temp + humidity from readings where device between 5 and 10 and humidity > 5;
                                                    QUERY PLAN                                                     
-------------------------------------------------------------------------------------------------------------------
 Result (actual rows=97923 loops=1)
   ->  Append (actual rows=97923 loops=1)
         ->  Index Scan using _hyper_1_1_chunk_readings_device_idx on _hyper_1_1_chunk (actual rows=2340 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 119
         ->  Index Scan using _hyper_1_2_chunk_readings_device_idx on _hyper_1_2_chunk (actual rows=22692 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 1192
         ->  Index Scan using _hyper_1_3_chunk_readings_device_idx on _hyper_1_3_chunk (actual rows=22872 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 1258
         ->  Index Scan using _hyper_1_4_chunk_readings_device_idx on _hyper_1_4_chunk (actual rows=22902 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 1237
         ->  Index Scan using _hyper_1_5_chunk_readings_device_idx on _hyper_1_5_chunk (actual rows=22930 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 1273
         ->  Index Scan using _hyper_1_6_chunk_readings_device_idx on _hyper_1_6_chunk (actual rows=4187 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 223
 Arrays read from cache: 7359
 Arrays decompressed: 18
(28 rows)

-- Check the explain cache information output.
--
-- Query 1 and 3 should show the same explain plan, and the plan in
-- the middle should not include decompress stats:
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select time, temp + humidity from readings where device between 5 and 10 and humidity > 5;
                                                    QUERY PLAN                                                     
-------------------------------------------------------------------------------------------------------------------
 Result (actual rows=97923 loops=1)
   ->  Append (actual rows=97923 loops=1)
         ->  Index Scan using _hyper_1_1_chunk_readings_device_idx on _hyper_1_1_chunk (actual rows=2340 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 119
         ->  Index Scan using _hyper_1_2_chunk_readings_device_idx on _hyper_1_2_chunk (actual rows=22692 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 1192
         ->  Index Scan using _hyper_1_3_chunk_readings_device_idx on _hyper_1_3_chunk (actual rows=22872 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 1258
         ->  Index Scan using _hyper_1_4_chunk_readings_device_idx on _hyper_1_4_chunk (actual rows=22902 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 1237
         ->  Index Scan using _hyper_1_5_chunk_readings_device_idx on _hyper_1_5_chunk (actual rows=22930 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 1273
         ->  Index Scan using _hyper_1_6_chunk_readings_device_idx on _hyper_1_6_chunk (actual rows=4187 loops=1)
               Index Cond: ((device >= 5) AND (device <= 10))
               Filter: (humidity > '5'::double precision)
               Rows Removed by Filter: 223
 Arrays read from cache: 7359
 Arrays decompressed: 18
(28 rows)

-- Check the explain cache information output. Query 1 and 3 should
-- show the same explain plan, and the plan in the middle should not
-- include decompress stats:
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select * from :chunk where device between 5 and 10;
                                              QUERY PLAN                                              
------------------------------------------------------------------------------------------------------
 Index Scan using _hyper_1_1_chunk_readings_device_idx on _hyper_1_1_chunk (actual rows=2459 loops=1)
   Index Cond: ((device >= 5) AND (device <= 10))
 Arrays read from cache: 0
 Arrays decompressed: 0
(4 rows)

explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select * from :chunk where device between 5 and 10;
                                              QUERY PLAN                                              
------------------------------------------------------------------------------------------------------
 Index Scan using _hyper_1_1_chunk_readings_device_idx on _hyper_1_1_chunk (actual rows=2459 loops=1)
   Index Cond: ((device >= 5) AND (device <= 10))
 Arrays read from cache: 0
 Arrays decompressed: 0
(4 rows)

-- Queries that will select just a few columns
set max_parallel_workers_per_gather to 0;
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select device, humidity from readings where device between 5 and 10;
                                                 QUERY PLAN                                                  
-------------------------------------------------------------------------------------------------------------
 Append (actual rows=103225 loops=1)
   ->  Index Scan using _hyper_1_1_chunk_readings_device_idx on _hyper_1_1_chunk (actual rows=2459 loops=1)
         Index Cond: ((device >= 5) AND (device <= 10))
   ->  Index Scan using _hyper_1_2_chunk_readings_device_idx on _hyper_1_2_chunk (actual rows=23884 loops=1)
         Index Cond: ((device >= 5) AND (device <= 10))
   ->  Index Scan using _hyper_1_3_chunk_readings_device_idx on _hyper_1_3_chunk (actual rows=24130 loops=1)
         Index Cond: ((device >= 5) AND (device <= 10))
   ->  Index Scan using _hyper_1_4_chunk_readings_device_idx on _hyper_1_4_chunk (actual rows=24139 loops=1)
         Index Cond: ((device >= 5) AND (device <= 10))
   ->  Index Scan using _hyper_1_5_chunk_readings_device_idx on _hyper_1_5_chunk (actual rows=24203 loops=1)
         Index Cond: ((device >= 5) AND (device <= 10))
   ->  Index Scan using _hyper_1_6_chunk_readings_device_idx on _hyper_1_6_chunk (actual rows=4410 loops=1)
         Index Cond: ((device >= 5) AND (device <= 10))
 Arrays read from cache: 2453
 Arrays decompressed: 6
(15 rows)

explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select device, avg(humidity) from readings where device between 5 and 10
group by device;
                                                          QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Finalize GroupAggregate (actual rows=6 loops=1)
   Group Key: _hyper_1_1_chunk.device
   ->  Sort (actual rows=36 loops=1)
         Sort Key: _hyper_1_1_chunk.device
         Sort Method: quicksort 
         ->  Append (actual rows=36 loops=1)
               ->  Partial GroupAggregate (actual rows=6 loops=1)
                     Group Key: _hyper_1_1_chunk.device
                     ->  Index Scan using _hyper_1_1_chunk_readings_device_idx on _hyper_1_1_chunk (actual rows=2459 loops=1)
                           Index Cond: ((device >= 5) AND (device <= 10))
               ->  Partial GroupAggregate (actual rows=6 loops=1)
                     Group Key: _hyper_1_2_chunk.device
                     ->  Index Scan using _hyper_1_2_chunk_readings_device_idx on _hyper_1_2_chunk (actual rows=23884 loops=1)
                           Index Cond: ((device >= 5) AND (device <= 10))
               ->  Partial GroupAggregate (actual rows=6 loops=1)
                     Group Key: _hyper_1_3_chunk.device
                     ->  Index Scan using _hyper_1_3_chunk_readings_device_idx on _hyper_1_3_chunk (actual rows=24130 loops=1)
                           Index Cond: ((device >= 5) AND (device <= 10))
               ->  Partial GroupAggregate (actual rows=6 loops=1)
                     Group Key: _hyper_1_4_chunk.device
                     ->  Index Scan using _hyper_1_4_chunk_readings_device_idx on _hyper_1_4_chunk (actual rows=24139 loops=1)
                           Index Cond: ((device >= 5) AND (device <= 10))
               ->  Partial GroupAggregate (actual rows=6 loops=1)
                     Group Key: _hyper_1_5_chunk.device
                     ->  Index Scan using _hyper_1_5_chunk_readings_device_idx on _hyper_1_5_chunk (actual rows=24203 loops=1)
                           Index Cond: ((device >= 5) AND (device <= 10))
               ->  Partial GroupAggregate (actual rows=6 loops=1)
                     Group Key: _hyper_1_6_chunk.device
                     ->  Index Scan using _hyper_1_6_chunk_readings_device_idx on _hyper_1_6_chunk (actual rows=4410 loops=1)
                           Index Cond: ((device >= 5) AND (device <= 10))
 Arrays read from cache: 2453
 Arrays decompressed: 6
(32 rows)

-- Test on conflict: insert the same data as before, but throw away
-- the updates.
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
insert into readings (time, location, device, temp, humidity)
select t, ceil(random()*10), ceil(random()*30), random()*40, random()*100
from generate_series('2022-06-01'::timestamptz, '2022-07-01', '5s') t
on conflict (location, device, time) do nothing;
                                       QUERY PLAN                                        
-----------------------------------------------------------------------------------------
 Custom Scan (HypertableModify) (actual rows=0 loops=1)
   ->  Insert on readings (actual rows=0 loops=1)
         Conflict Resolution: NOTHING
         Conflict Arbiter Indexes: readings_device_location_time_key
         Tuples Inserted: 516712
         Conflicting Tuples: 1689
         ->  Custom Scan (ChunkDispatch) (actual rows=518401 loops=1)
               ->  Subquery Scan on "*SELECT*" (actual rows=518401 loops=1)
                     ->  Function Scan on generate_series t (actual rows=518401 loops=1)
 Arrays read from cache: 0
 Arrays decompressed: 88
(11 rows)

-- This should show values for all columns
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select time, temp + humidity from readings where device between 5 and 10 and humidity > 5 limit 5;
                                                     QUERY PLAN                                                      
---------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=5 loops=1)
   ->  Result (actual rows=5 loops=1)
         ->  Append (actual rows=5 loops=1)
               ->  Index Scan using _hyper_1_1_chunk_readings_device_idx on _hyper_1_1_chunk (actual rows=5 loops=1)
                     Index Cond: ((device >= 5) AND (device <= 10))
                     Filter: (humidity > '5'::double precision)
                     Rows Removed by Filter: 1
               ->  Index Scan using _hyper_1_2_chunk_readings_device_idx on _hyper_1_2_chunk (never executed)
                     Index Cond: ((device >= 5) AND (device <= 10))
                     Filter: (humidity > '5'::double precision)
               ->  Index Scan using _hyper_1_3_chunk_readings_device_idx on _hyper_1_3_chunk (never executed)
                     Index Cond: ((device >= 5) AND (device <= 10))
                     Filter: (humidity > '5'::double precision)
               ->  Index Scan using _hyper_1_4_chunk_readings_device_idx on _hyper_1_4_chunk (never executed)
                     Index Cond: ((device >= 5) AND (device <= 10))
                     Filter: (humidity > '5'::double precision)
               ->  Index Scan using _hyper_1_5_chunk_readings_device_idx on _hyper_1_5_chunk (never executed)
                     Index Cond: ((device >= 5) AND (device <= 10))
                     Filter: (humidity > '5'::double precision)
               ->  Index Scan using _hyper_1_6_chunk_readings_device_idx on _hyper_1_6_chunk (never executed)
                     Index Cond: ((device >= 5) AND (device <= 10))
                     Filter: (humidity > '5'::double precision)
 Arrays read from cache: 0
 Arrays decompressed: 0
(24 rows)

select time, temp + humidity from readings where device between 5 and 10 and humidity > 5 limit 5;
             time             |     ?column?     
------------------------------+------------------
 Wed Jun 01 00:09:30 2022 PDT | 58.2121830134964
 Wed Jun 01 00:11:30 2022 PDT | 78.7699285749949
 Wed Jun 01 00:13:50 2022 PDT | 90.6603130792196
 Wed Jun 01 00:15:25 2022 PDT | 11.6666413710752
 Wed Jun 01 00:16:05 2022 PDT | 98.9968121849908
(5 rows)

-- Get the compressed chunk
select format('%I.%I', c2.schema_name, c2.table_name)::regclass as cchunk
from _timescaledb_catalog.chunk c1
join _timescaledb_catalog.chunk c2
on (c1.compressed_chunk_id = c2.id)
where format('%I.%I', c1.schema_name, c1.table_name)::regclass = :'chunk'::regclass \gset
-- Show that location is using dictionary encoding
select (_timescaledb_functions.compressed_data_info(location)).* from :cchunk limit 1;
 algorithm  | has_nulls 
------------+-----------
 DICTIONARY | f
(1 row)

-- Test that vectorized filtering on text column works
set enable_indexscan=off;
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select time, location, temp from :chunk
where location = 1::text
order by time desc;
                                   QUERY PLAN                                    
---------------------------------------------------------------------------------
 Sort (actual rows=2417 loops=1)
   Sort Key: "time" DESC
   Sort Method: quicksort 
   ->  Custom Scan (ColumnarScan) on _hyper_1_1_chunk (actual rows=2417 loops=1)
         Vectorized Filter: (location = '1'::text)
         Rows Removed by Filter: 22020
 Arrays read from cache: 3573
 Arrays decompressed: 90
(8 rows)

--  Save the data for comparison with seqscan
create temp table chunk_saved as
select time, location, temp from :chunk
where location = 1::text
order by time desc;
-- Show same query with seqscan and compare output
set timescaledb.enable_columnarscan=off;
explain (analyze, costs off, timing off, summary off)
select time, location, temp from :chunk
where location = 1::text
order by time desc;
                          QUERY PLAN                           
---------------------------------------------------------------
 Sort (actual rows=2417 loops=1)
   Sort Key: "time" DESC
   Sort Method: quicksort 
   ->  Seq Scan on _hyper_1_1_chunk (actual rows=2417 loops=1)
         Filter: (location = '1'::text)
         Rows Removed by Filter: 22020
(6 rows)

-- If output is the same, this query should return nothing
(select time, location, temp from :chunk
where location = 1::text
order by time desc)
except
select * from chunk_saved;
 time | location | temp 
------+----------+------
(0 rows)

-- Insert some non-compressed values to see that vectorized filtering
-- works on those non-compressed text columns.
insert into :chunk values ('2022-06-01 15:30'::timestamptz, 1, 2, 3.14, 2.14), ('2022-06-01 15:30'::timestamptz, 2, 2, 3.14, 2.14);
-- Query should only return the one non-compressed row that has location=1
(select time, location, temp from :chunk
where location = 1::text
order by time desc)
except
select * from chunk_saved;
             time             | location | temp 
------------------------------+----------+------
 Wed Jun 01 15:30:00 2022 PDT | 1        | 3.14
(1 row)

-- Test that a ColumnarScan doesn't decompress anything if there are
-- no referenced columns, or the referenced column is a segmentby
-- column
set timescaledb.enable_columnarscan=true;
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select count(*) from :chunk where device = 1;
                                   QUERY PLAN                                   
--------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (ColumnarScan) on _hyper_1_1_chunk (actual rows=827 loops=1)
         Scankey: (device = 1)
 Arrays read from cache: 0
 Arrays decompressed: 0
(5 rows)

explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select device from :chunk where device = 1;
                                QUERY PLAN                                
--------------------------------------------------------------------------
 Custom Scan (ColumnarScan) on _hyper_1_1_chunk (actual rows=827 loops=1)
   Scankey: (device = 1)
 Arrays read from cache: 0
 Arrays decompressed: 0
(4 rows)

-- Using a non-segmentby column will decompress that column
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select count(*) from :chunk where location = 1::text;
                                   QUERY PLAN                                    
---------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (ColumnarScan) on _hyper_1_1_chunk (actual rows=2418 loops=1)
         Vectorized Filter: (location = '1'::text)
         Rows Removed by Filter: 22021
 Arrays read from cache: 0
 Arrays decompressed: 30
(6 rows)

-- Testing same thing with SeqScan. It still decompresses in the
-- count(*) case, although it shouldn't have to. So, probably an
-- opportunity to optimize.
set timescaledb.enable_columnarscan=false;
explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select count(*) from :chunk where device = 1;
                          QUERY PLAN                          
--------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Seq Scan on _hyper_1_1_chunk (actual rows=827 loops=1)
         Filter: (device = 1)
         Rows Removed by Filter: 23612
 Arrays read from cache: 24422
 Arrays decompressed: 62
(6 rows)

explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select device from :chunk where device = 1;
                       QUERY PLAN                       
--------------------------------------------------------
 Seq Scan on _hyper_1_1_chunk (actual rows=827 loops=1)
   Filter: (device = 1)
   Rows Removed by Filter: 23612
 Arrays read from cache: 0
 Arrays decompressed: 0
(5 rows)

explain (analyze, costs off, timing off, summary off, decompress_cache_stats)
select count(*) from :chunk where location = 1::text;
                          QUERY PLAN                           
---------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Seq Scan on _hyper_1_1_chunk (actual rows=2418 loops=1)
         Filter: (location = '1'::text)
         Rows Removed by Filter: 22021
 Arrays read from cache: 24422
 Arrays decompressed: 62
(6 rows)

