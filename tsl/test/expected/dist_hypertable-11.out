-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- Need to be super user to create extension and add data nodes
\c :TEST_DBNAME :ROLE_CLUSTER_SUPERUSER;
\unset ECHO
psql:include/filter_exec.sql:5: NOTICE:  schema "test" already exists, skipping
psql:include/remote_exec.sql:5: NOTICE:  schema "test" already exists, skipping
-- Cleanup from other potential tests that created these databases
SET client_min_messages TO ERROR;
DROP DATABASE IF EXISTS data_node_1;
DROP DATABASE IF EXISTS data_node_2;
DROP DATABASE IF EXISTS data_node_3;
SET client_min_messages TO NOTICE;
-- Add data nodes using the TimescaleDB node management API
SELECT * FROM add_data_node('data_node_1', host => 'localhost',
                            database => 'data_node_1');
  node_name  |   host    | port  |  database   | node_created | database_created | extension_created 
-------------+-----------+-------+-------------+--------------+------------------+-------------------
 data_node_1 | localhost | 55432 | data_node_1 | t            | t                | t
(1 row)

SELECT * FROM add_data_node('data_node_2', host => 'localhost',
                            database => 'data_node_2');
  node_name  |   host    | port  |  database   | node_created | database_created | extension_created 
-------------+-----------+-------+-------------+--------------+------------------+-------------------
 data_node_2 | localhost | 55432 | data_node_2 | t            | t                | t
(1 row)

SELECT * FROM add_data_node('data_node_3', host => 'localhost',
                            database => 'data_node_3');
  node_name  |   host    | port  |  database   | node_created | database_created | extension_created 
-------------+-----------+-------+-------------+--------------+------------------+-------------------
 data_node_3 | localhost | 55432 | data_node_3 | t            | t                | t
(1 row)

GRANT USAGE ON FOREIGN SERVER data_node_1, data_node_2, data_node_3 TO PUBLIC;
-- Import testsupport.sql file to data nodes
\unset ECHO
SET ROLE :ROLE_1;
-- Verify lack of tables
SELECT node_name, "options" FROM timescaledb_information.data_node ORDER BY node_name;
  node_name  |                    options                     
-------------+------------------------------------------------
 data_node_1 | {host=localhost,port=55432,dbname=data_node_1}
 data_node_2 | {host=localhost,port=55432,dbname=data_node_2}
 data_node_3 | {host=localhost,port=55432,dbname=data_node_3}
(3 rows)

\set ON_ERROR_STOP 0
-- Test that one cannot directly create TimescaleDB foreign tables
CREATE FOREIGN TABLE foreign_table (time timestamptz, device int, temp float) SERVER data_node_1;
ERROR:  operation not supported
\set ON_ERROR_STOP 1
-- Create distributed hypertables. Add a trigger and primary key
-- constraint to test how those work
CREATE TABLE disttable(time timestamptz, device int CHECK (device > 0), color int, temp float, PRIMARY KEY (time,device));
SELECT * FROM create_distributed_hypertable('disttable', 'time', 'device', 1);
WARNING:  the number of partitions in dimension "device" is too low to make use of all attached data nodes
 hypertable_id | schema_name | table_name | created 
---------------+-------------+------------+---------
             1 | public      | disttable  | t
(1 row)

-- Increase the number of partitions. Expect warning since still too low
SELECT * FROM set_number_partitions('disttable', 2);
WARNING:  the number of partitions in dimension "device" is too low to make use of all attached data nodes
 set_number_partitions 
-----------------------
 
(1 row)

-- Set number of partitions equal to the number of servers should not
-- raise a warning.
SELECT * FROM set_number_partitions('disttable', 3, 'device');
 set_number_partitions 
-----------------------
 
(1 row)

-- Show the number of slices
SELECT h.table_name, d.column_name, d.num_slices
FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id
AND h.table_name = 'disttable';
 table_name | column_name | num_slices 
------------+-------------+------------
 disttable  | device      |          3
 disttable  | time        |           
(2 rows)

-- This table tests both 1-dimensional tables and under-replication
-- (replication_factor > num_data_nodes).
CREATE TABLE underreplicated(time timestamptz, device int, temp float);
SELECT * FROM create_hypertable('underreplicated', 'time', replication_factor => 4);
NOTICE:  adding not-null constraint to column "time"
 hypertable_id | schema_name |   table_name    | created 
---------------+-------------+-----------------+---------
             2 | public      | underreplicated | t
(1 row)

SET ROLE :ROLE_1;
CREATE OR REPLACE FUNCTION test_trigger()
    RETURNS TRIGGER LANGUAGE PLPGSQL AS
$BODY$
DECLARE
    cnt INTEGER;
BEGIN
    SELECT count(*) INTO cnt FROM hyper;
    RAISE WARNING 'FIRING trigger when: % level: % op: % cnt: % trigger_name %',
        tg_when, tg_level, tg_op, cnt, tg_name;

    IF TG_OP = 'DELETE' THEN
        RETURN OLD;
    END IF;
    RETURN NEW;
END
$BODY$;
CREATE TRIGGER _0_test_trigger_insert
    BEFORE INSERT ON disttable
    FOR EACH ROW EXECUTE FUNCTION test_trigger();
SELECT * FROM _timescaledb_catalog.hypertable_data_node;
 hypertable_id | node_hypertable_id |  node_name  | block_chunks 
---------------+--------------------+-------------+--------------
             1 |                  1 | data_node_1 | f
             1 |                  1 | data_node_2 | f
             1 |                  1 | data_node_3 | f
             2 |                  2 | data_node_1 | f
             2 |                  2 | data_node_2 | f
             2 |                  2 | data_node_3 | f
(6 rows)

SELECT * FROM _timescaledb_catalog.chunk_data_node;
 chunk_id | node_chunk_id | node_name 
----------+---------------+-----------
(0 rows)

-- The constraints, indexes, and triggers on the hypertable
SELECT * FROM test.show_constraints('disttable');
       Constraint       | Type |    Columns    |     Index      |     Expr     | Deferrable | Deferred | Validated 
------------------------+------+---------------+----------------+--------------+------------+----------+-----------
 disttable_device_check | c    | {device}      | -              | (device > 0) | f          | f        | t
 disttable_pkey         | p    | {time,device} | disttable_pkey |              | f          | f        | t
(2 rows)

SELECT * FROM test.show_indexes('disttable');
           Index           |    Columns    | Expr | Unique | Primary | Exclusion | Tablespace 
---------------------------+---------------+------+--------+---------+-----------+------------
 disttable_device_time_idx | {device,time} |      | f      | f       | f         | 
 disttable_pkey            | {time,device} |      | t      | t       | f         | 
 disttable_time_idx        | {time}        |      | f      | f       | f         | 
(3 rows)

SELECT * FROM test.show_triggers('disttable');
        Trigger         | Type |               Function               
------------------------+------+--------------------------------------
 _0_test_trigger_insert |    7 | test_trigger
 ts_insert_blocker      |    7 | _timescaledb_internal.insert_blocker
(2 rows)

-- Drop a column. This will make the attribute numbers of the
-- hypertable's root relation differ from newly created chunks. It is
-- a way to test that we properly handle attributed conversion between
-- the root table and chunks
ALTER TABLE disttable DROP COLUMN color;
-- EXPLAIN some inserts to see what plans and explain output for
-- remote inserts look like
EXPLAIN (COSTS FALSE)
INSERT INTO disttable VALUES
       ('2017-01-01 06:01', 1, 1.1);
                  QUERY PLAN                   
-----------------------------------------------
 Custom Scan (HypertableInsert)
 Insert on distributed hypertable disttable
   ->  Insert on disttable
         ->  Custom Scan (DataNodeDispatch)
               Batch size: 1000
               ->  Custom Scan (ChunkDispatch)
                     ->  Result
(7 rows)

EXPLAIN (VERBOSE, COSTS FALSE)
INSERT INTO disttable VALUES
       ('2017-01-01 06:01', 1, 1.1);
                                                              QUERY PLAN                                                               
---------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (HypertableInsert)
 Insert on distributed hypertable public.disttable
   Data nodes: data_node_1, data_node_2, data_node_3
   ->  Insert on public.disttable
         ->  Custom Scan (DataNodeDispatch)
               Output: 'Sun Jan 01 06:01:00 2017 PST'::timestamp with time zone, 1, NULL::integer, '1.1'::double precision
               Batch size: 1000
               Remote SQL: INSERT INTO public.disttable("time", device, temp) VALUES ($1, $2, $3), ..., ($2998, $2999, $3000)
               ->  Custom Scan (ChunkDispatch)
                     Output: 'Sun Jan 01 06:01:00 2017 PST'::timestamp with time zone, 1, NULL::integer, '1.1'::double precision
                     ->  Result
                           Output: 'Sun Jan 01 06:01:00 2017 PST'::timestamp with time zone, 1, NULL::integer, '1.1'::double precision
(12 rows)

-- Create some chunks through insertion
INSERT INTO disttable VALUES
       ('2017-01-01 06:01', 1, 1.1),
       ('2017-01-01 09:11', 3, 2.1),
       ('2017-01-01 08:01', 1, 1.2),
       ('2017-01-02 08:01', 2, 1.3),
       ('2018-07-02 08:01', 87, 1.6),
       ('2018-07-01 06:01', 13, 1.4),
       ('2018-07-01 09:11', 90, 2.7),
       ('2018-07-01 08:01', 29, 1.5);
-- Test distributed ANALYZE.
--
-- First show no statistics
SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE oid = 'disttable'::regclass;
  relname  | relkind | reltuples | relpages 
-----------+---------+-----------+----------
 disttable | r       |         0 |        0
(1 row)

SELECT relname, relkind, reltuples, relpages
FROM pg_class cl, (SELECT show_chunks AS chunk FROM show_chunks('disttable')) ch
WHERE cl.oid = ch.chunk::regclass;
        relname        | relkind | reltuples | relpages 
-----------------------+---------+-----------+----------
 _dist_hyper_1_1_chunk | f       |         0 |        0
 _dist_hyper_1_2_chunk | f       |         0 |        0
 _dist_hyper_1_3_chunk | f       |         0 |        0
 _dist_hyper_1_4_chunk | f       |         0 |        0
 _dist_hyper_1_5_chunk | f       |         0 |        0
 _dist_hyper_1_6_chunk | f       |         0 |        0
(6 rows)

ANALYZE disttable;
-- Show updated statistics
SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE oid = 'disttable'::regclass;
  relname  | relkind | reltuples | relpages 
-----------+---------+-----------+----------
 disttable | r       |         0 |        0
(1 row)

SELECT relname, relkind, reltuples, relpages
FROM pg_class cl, (SELECT show_chunks AS chunk FROM show_chunks('disttable')) ch
WHERE cl.oid = ch.chunk::regclass;
        relname        | relkind | reltuples | relpages 
-----------------------+---------+-----------+----------
 _dist_hyper_1_1_chunk | f       |         2 |        1
 _dist_hyper_1_2_chunk | f       |         1 |        1
 _dist_hyper_1_3_chunk | f       |         1 |        1
 _dist_hyper_1_4_chunk | f       |         1 |        1
 _dist_hyper_1_5_chunk | f       |         1 |        1
 _dist_hyper_1_6_chunk | f       |         2 |        1
(6 rows)

-- Test distributed VACUUM.
--
VACUUM (FULL, ANALYZE) disttable;
VACUUM FULL disttable;
VACUUM disttable;
\set ON_ERROR_STOP 0
-- VACUUM VERBOSE is not supported at the moment
VACUUM VERBOSE disttable;
ERROR:  operation not supported on distributed hypertable
\set ON_ERROR_STOP 1
-- Test prepared statement
PREPARE dist_insert (timestamptz, int, float) AS
INSERT INTO disttable VALUES ($1, $2, $3);
EXECUTE dist_insert ('2017-01-01 06:05', 1, 1.4);
-- Show chunks created
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable');
 chunk_id | hypertable_id |      schema_name      |      table_name       | relkind |                                           slices                                            
----------+---------------+-----------------------+-----------------------+---------+---------------------------------------------------------------------------------------------
        1 |             1 | _timescaledb_internal | _dist_hyper_1_1_chunk | f       | {"time": [1482969600000000, 1483574400000000], "device": [-9223372036854775808, 715827882]}
        2 |             1 | _timescaledb_internal | _dist_hyper_1_2_chunk | f       | {"time": [1482969600000000, 1483574400000000], "device": [1431655764, 9223372036854775807]}
        3 |             1 | _timescaledb_internal | _dist_hyper_1_3_chunk | f       | {"time": [1482969600000000, 1483574400000000], "device": [715827882, 1431655764]}
        4 |             1 | _timescaledb_internal | _dist_hyper_1_4_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [-9223372036854775808, 715827882]}
        5 |             1 | _timescaledb_internal | _dist_hyper_1_5_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [715827882, 1431655764]}
        6 |             1 | _timescaledb_internal | _dist_hyper_1_6_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [1431655764, 9223372036854775807]}
(6 rows)

-- Show that there are assigned node_chunk_id:s in chunk data node mappings
SELECT * FROM _timescaledb_catalog.chunk_data_node;
 chunk_id | node_chunk_id |  node_name  
----------+---------------+-------------
        1 |             1 | data_node_1
        2 |             1 | data_node_3
        3 |             1 | data_node_2
        4 |             2 | data_node_1
        5 |             2 | data_node_2
        6 |             2 | data_node_3
(6 rows)

-- Show that chunks are created on data nodes and that each data node
-- has their own unique slice in the space (device) dimension.
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable');
$$);
NOTICE:  [data_node_1]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [data_node_1]:
chunk_id|hypertable_id|schema_name          |table_name           |relkind|slices                                                                                     
--------+-------------+---------------------+---------------------+-------+-------------------------------------------------------------------------------------------
       1|            1|_timescaledb_internal|_dist_hyper_1_1_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [-9223372036854775808, 715827882]}
       2|            1|_timescaledb_internal|_dist_hyper_1_4_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [-9223372036854775808, 715827882]}
(2 rows)


NOTICE:  [data_node_2]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [data_node_2]:
chunk_id|hypertable_id|schema_name          |table_name           |relkind|slices                                                                           
--------+-------------+---------------------+---------------------+-------+---------------------------------------------------------------------------------
       1|            1|_timescaledb_internal|_dist_hyper_1_3_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [715827882, 1431655764]}
       2|            1|_timescaledb_internal|_dist_hyper_1_5_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [715827882, 1431655764]}
(2 rows)


NOTICE:  [data_node_3]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [data_node_3]:
chunk_id|hypertable_id|schema_name          |table_name           |relkind|slices                                                                                     
--------+-------------+---------------------+---------------------+-------+-------------------------------------------------------------------------------------------
       1|            1|_timescaledb_internal|_dist_hyper_1_2_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [1431655764, 9223372036854775807]}
       2|            1|_timescaledb_internal|_dist_hyper_1_6_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [1431655764, 9223372036854775807]}
(2 rows)


 remote_exec 
-------------
 
(1 row)

SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT * FROM disttable;
$$);
NOTICE:  [data_node_1]: 
SELECT * FROM disttable
NOTICE:  [data_node_1]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
Sun Jan 01 08:01:00 2017 PST|     1| 1.2
Sun Jan 01 06:05:00 2017 PST|     1| 1.4
Mon Jul 02 08:01:00 2018 PDT|    87| 1.6
(4 rows)


NOTICE:  [data_node_2]: 
SELECT * FROM disttable
NOTICE:  [data_node_2]:
time                        |device|temp
----------------------------+------+----
Mon Jan 02 08:01:00 2017 PST|     2| 1.3
Sun Jul 01 06:01:00 2018 PDT|    13| 1.4
(2 rows)


NOTICE:  [data_node_3]: 
SELECT * FROM disttable
NOTICE:  [data_node_3]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 09:11:00 2017 PST|     3| 2.1
Sun Jul 01 09:11:00 2018 PDT|    90| 2.7
Sun Jul 01 08:01:00 2018 PDT|    29| 1.5
(3 rows)


 remote_exec 
-------------
 
(1 row)

SELECT node_name, "options" FROM timescaledb_information.data_node ORDER BY node_name;
  node_name  |                    options                     
-------------+------------------------------------------------
 data_node_1 | {host=localhost,port=55432,dbname=data_node_1}
 data_node_2 | {host=localhost,port=55432,dbname=data_node_2}
 data_node_3 | {host=localhost,port=55432,dbname=data_node_3}
(3 rows)

SELECT * FROM hypertable_detailed_size('disttable') ORDER BY node_name;
 table_bytes | index_bytes | toast_bytes | total_bytes |  node_name  
-------------+-------------+-------------+-------------+-------------
       81920 |       98304 |           0 |      180224 | data_node_1
       81920 |       98304 |           0 |      180224 | data_node_2
       81920 |       98304 |           0 |      180224 | data_node_3
(3 rows)

-- Show what some queries would look like on the frontend
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT * FROM disttable;
                                                                     QUERY PLAN                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: disttable."time", disttable.device, disttable.temp
   ->  Append
         ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
               Output: disttable_1."time", disttable_1.device, disttable_1.temp
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk
               Remote SQL: SELECT "time", device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2])
         ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
               Output: disttable_2."time", disttable_2.device, disttable_2.temp
               Data node: data_node_2
               Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_5_chunk
               Remote SQL: SELECT "time", device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2])
         ->  Custom Scan (DataNodeScan) on public.disttable disttable_3
               Output: disttable_3."time", disttable_3.device, disttable_3.temp
               Data node: data_node_3
               Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_6_chunk
               Remote SQL: SELECT "time", device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2])
(18 rows)

SELECT * FROM disttable;
             time             | device | temp 
------------------------------+--------+------
 Sun Jan 01 06:01:00 2017 PST |      1 |  1.1
 Sun Jan 01 08:01:00 2017 PST |      1 |  1.2
 Sun Jan 01 06:05:00 2017 PST |      1 |  1.4
 Mon Jul 02 08:01:00 2018 PDT |     87 |  1.6
 Mon Jan 02 08:01:00 2017 PST |      2 |  1.3
 Sun Jul 01 06:01:00 2018 PDT |     13 |  1.4
 Sun Jan 01 09:11:00 2017 PST |      3 |  2.1
 Sun Jul 01 09:11:00 2018 PDT |     90 |  2.7
 Sun Jul 01 08:01:00 2018 PDT |     29 |  1.5
(9 rows)

EXPLAIN (VERBOSE, COSTS FALSE)
SELECT time_bucket('3 hours', time) AS time, device, avg(temp) AS avg_temp
FROM disttable GROUP BY 1, 2
ORDER BY 1;
                                                                                                                        QUERY PLAN                                                                                                                        
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: (time_bucket('@ 3 hours'::interval, disttable."time")), disttable.device, avg(disttable.temp)
   Group Key: (time_bucket('@ 3 hours'::interval, disttable."time")), disttable.device
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 3 hours'::interval, disttable."time")), disttable.device, disttable.temp
         ->  Merge Append
               Sort Key: (time_bucket('@ 3 hours'::interval, disttable_1."time")), disttable_1.device
               ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                     Output: time_bucket('@ 3 hours'::interval, disttable_1."time"), disttable_1.device, disttable_1.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) ORDER BY public.time_bucket('03:00:00'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                     Output: time_bucket('@ 3 hours'::interval, disttable_2."time"), disttable_2.device, disttable_2.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_5_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) ORDER BY public.time_bucket('03:00:00'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.disttable disttable_3
                     Output: time_bucket('@ 3 hours'::interval, disttable_3."time"), disttable_3.device, disttable_3.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_6_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) ORDER BY public.time_bucket('03:00:00'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(22 rows)

-- Execute some queries on the frontend and return the results
SELECT * FROM disttable;
             time             | device | temp 
------------------------------+--------+------
 Sun Jan 01 06:01:00 2017 PST |      1 |  1.1
 Sun Jan 01 08:01:00 2017 PST |      1 |  1.2
 Sun Jan 01 06:05:00 2017 PST |      1 |  1.4
 Mon Jul 02 08:01:00 2018 PDT |     87 |  1.6
 Mon Jan 02 08:01:00 2017 PST |      2 |  1.3
 Sun Jul 01 06:01:00 2018 PDT |     13 |  1.4
 Sun Jan 01 09:11:00 2017 PST |      3 |  2.1
 Sun Jul 01 09:11:00 2018 PDT |     90 |  2.7
 Sun Jul 01 08:01:00 2018 PDT |     29 |  1.5
(9 rows)

SELECT time_bucket('3 hours', time) AS time, device, avg(temp) AS avg_temp
FROM disttable
GROUP BY 1, 2
ORDER BY 1;
             time             | device | avg_temp 
------------------------------+--------+----------
 Sun Jan 01 04:00:00 2017 PST |      1 |     1.25
 Sun Jan 01 07:00:00 2017 PST |      1 |      1.2
 Sun Jan 01 07:00:00 2017 PST |      3 |      2.1
 Mon Jan 02 07:00:00 2017 PST |      2 |      1.3
 Sun Jul 01 05:00:00 2018 PDT |     13 |      1.4
 Sun Jul 01 08:00:00 2018 PDT |     29 |      1.5
 Sun Jul 01 08:00:00 2018 PDT |     90 |      2.7
 Mon Jul 02 08:00:00 2018 PDT |     87 |      1.6
(8 rows)

SELECT time_bucket('3 hours', time) AS time, device, avg(temp) AS avg_temp
FROM disttable GROUP BY 1, 2
HAVING avg(temp) > 1.2
ORDER BY 1;
             time             | device | avg_temp 
------------------------------+--------+----------
 Sun Jan 01 04:00:00 2017 PST |      1 |     1.25
 Sun Jan 01 07:00:00 2017 PST |      3 |      2.1
 Mon Jan 02 07:00:00 2017 PST |      2 |      1.3
 Sun Jul 01 05:00:00 2018 PDT |     13 |      1.4
 Sun Jul 01 08:00:00 2018 PDT |     29 |      1.5
 Sun Jul 01 08:00:00 2018 PDT |     90 |      2.7
 Mon Jul 02 08:00:00 2018 PDT |     87 |      1.6
(7 rows)

SELECT time_bucket('3 hours', time) AS time, device, avg(temp) AS avg_temp
FROM disttable
WHERE temp > 2
GROUP BY 1, 2
HAVING avg(temp) > 1.2
ORDER BY 1;
             time             | device | avg_temp 
------------------------------+--------+----------
 Sun Jan 01 07:00:00 2017 PST |      3 |      2.1
 Sun Jul 01 08:00:00 2018 PDT |     90 |      2.7
(2 rows)

-- Test AsyncAppend when using min/max aggregates
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT max(temp)
FROM disttable;
                                                                                                    QUERY PLAN                                                                                                    
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Result
   Output: $0
   InitPlan 1 (returns $0)
     ->  Limit
           Output: disttable.temp
           ->  Custom Scan (AsyncAppend)
                 Output: disttable.temp
                 ->  Merge Append
                       Sort Key: disttable_1.temp DESC
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                             Output: disttable_1.temp
                             Data node: data_node_1
                             Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                             Output: disttable_2.temp
                             Data node: data_node_2
                             Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_5_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_3
                             Output: disttable_3.temp
                             Data node: data_node_3
                             Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_6_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
(24 rows)

SELECT max(temp)
FROM disttable;
 max 
-----
 2.7
(1 row)

-- Test turning off async append
SET timescaledb.enable_async_append = OFF;
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT max(temp)
FROM disttable;
                                                                                                 QUERY PLAN                                                                                                 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Result
   Output: $0
   InitPlan 1 (returns $0)
     ->  Limit
           Output: disttable.temp
           ->  Merge Append
                 Sort Key: disttable.temp DESC
                 ->  Custom Scan (DataNodeScan) on public.disttable
                       Output: disttable.temp
                       Data node: data_node_1
                       Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk
                       Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                 ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                       Output: disttable_1.temp
                       Data node: data_node_2
                       Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_5_chunk
                       Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                 ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                       Output: disttable_2.temp
                       Data node: data_node_3
                       Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_6_chunk
                       Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
(22 rows)

SET timescaledb.enable_async_append = ON;
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT min(temp), max(temp)
FROM disttable;
                                                                QUERY PLAN                                                                
------------------------------------------------------------------------------------------------------------------------------------------
 Aggregate
   Output: min(disttable.temp), max(disttable.temp)
   ->  Custom Scan (AsyncAppend)
         Output: disttable.temp
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                     Output: disttable_1.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk
                     Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2])
               ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                     Output: disttable_2.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_5_chunk
                     Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2])
               ->  Custom Scan (DataNodeScan) on public.disttable disttable_3
                     Output: disttable_3.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_6_chunk
                     Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2])
(20 rows)

SELECT min(temp), max(temp)
FROM disttable;
 min | max 
-----+-----
 1.1 | 2.7
(1 row)

-- Test AsyncAppend when using window functions
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT device, temp, avg(temp) OVER (PARTITION BY device)
FROM disttable
ORDER BY device, temp;
                                                                                      QUERY PLAN                                                                                       
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sort
   Output: disttable.device, disttable.temp, (avg(disttable.temp) OVER (?))
   Sort Key: disttable.device, disttable.temp
   ->  WindowAgg
         Output: disttable.device, disttable.temp, avg(disttable.temp) OVER (?)
         ->  Custom Scan (AsyncAppend)
               Output: disttable.device, disttable.temp
               ->  Merge Append
                     Sort Key: disttable_1.device
                     ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                           Output: disttable_1.device, disttable_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk
                           Remote SQL: SELECT device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                           Output: disttable_2.device, disttable_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_5_chunk
                           Remote SQL: SELECT device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.disttable disttable_3
                           Output: disttable_3.device, disttable_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_6_chunk
                           Remote SQL: SELECT device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) ORDER BY device ASC NULLS LAST
(24 rows)

SELECT device, temp, avg(temp) OVER (PARTITION BY device)
FROM disttable
ORDER BY device, temp;
 device | temp |       avg        
--------+------+------------------
      1 |  1.1 | 1.23333333333333
      1 |  1.2 | 1.23333333333333
      1 |  1.4 | 1.23333333333333
      2 |  1.3 |              1.3
      3 |  2.1 |              2.1
     13 |  1.4 |              1.4
     29 |  1.5 |              1.5
     87 |  1.6 |              1.6
     90 |  2.7 |              2.7
(9 rows)

-- Test remote explain
SET timescaledb.enable_remote_explain = ON;
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT max(temp)
FROM disttable;
                                                                                                    QUERY PLAN                                                                                                    
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Result
   Output: $0
   InitPlan 1 (returns $0)
     ->  Limit
           Output: disttable.temp
           ->  Custom Scan (AsyncAppend)
                 Output: disttable.temp
                 ->  Merge Append
                       Sort Key: disttable_1.temp DESC
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                             Output: disttable_1.temp
                             Data node: data_node_1
                             Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit
                                 Output: _dist_hyper_1_1_chunk.temp
                                 ->  Sort
                                       Output: _dist_hyper_1_1_chunk.temp
                                       Sort Key: _dist_hyper_1_1_chunk.temp DESC
                                       ->  Append
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_1_chunk
                                                   Output: _dist_hyper_1_1_chunk.temp
                                                   Filter: (_dist_hyper_1_1_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_4_chunk
                                                   Output: _dist_hyper_1_4_chunk.temp
                                                   Filter: (_dist_hyper_1_4_chunk.temp IS NOT NULL)
 
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                             Output: disttable_2.temp
                             Data node: data_node_2
                             Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_5_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit
                                 Output: _dist_hyper_1_3_chunk.temp
                                 ->  Sort
                                       Output: _dist_hyper_1_3_chunk.temp
                                       Sort Key: _dist_hyper_1_3_chunk.temp DESC
                                       ->  Append
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_3_chunk
                                                   Output: _dist_hyper_1_3_chunk.temp
                                                   Filter: (_dist_hyper_1_3_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_5_chunk
                                                   Output: _dist_hyper_1_5_chunk.temp
                                                   Filter: (_dist_hyper_1_5_chunk.temp IS NOT NULL)
 
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_3
                             Output: disttable_3.temp
                             Data node: data_node_3
                             Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_6_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit
                                 Output: _dist_hyper_1_2_chunk.temp
                                 ->  Sort
                                       Output: _dist_hyper_1_2_chunk.temp
                                       Sort Key: _dist_hyper_1_2_chunk.temp DESC
                                       ->  Append
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_2_chunk
                                                   Output: _dist_hyper_1_2_chunk.temp
                                                   Filter: (_dist_hyper_1_2_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_6_chunk
                                                   Output: _dist_hyper_1_6_chunk.temp
                                                   Filter: (_dist_hyper_1_6_chunk.temp IS NOT NULL)
 
(66 rows)

-- Don't remote explain if there is no VERBOSE flag
EXPLAIN (COSTS FALSE)
SELECT max(temp)
FROM disttable;
                                  QUERY PLAN                                   
-------------------------------------------------------------------------------
 Result
   InitPlan 1 (returns $0)
     ->  Limit
           ->  Custom Scan (AsyncAppend)
                 ->  Merge Append
                       Sort Key: disttable_1.temp DESC
                       ->  Custom Scan (DataNodeScan) on disttable disttable_1
                       ->  Custom Scan (DataNodeScan) on disttable disttable_2
                       ->  Custom Scan (DataNodeScan) on disttable disttable_3
(9 rows)

-- Test additional EXPLAIN flags
EXPLAIN (ANALYZE, VERBOSE, COSTS FALSE, BUFFERS ON, TIMING OFF, SUMMARY OFF)
SELECT max(temp)
FROM disttable;
                                                                                                    QUERY PLAN                                                                                                    
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Result (actual rows=1 loops=1)
   Output: $0
   InitPlan 1 (returns $0)
     ->  Limit (actual rows=1 loops=1)
           Output: disttable.temp
           ->  Custom Scan (AsyncAppend) (actual rows=1 loops=1)
                 Output: disttable.temp
                 ->  Merge Append (actual rows=1 loops=1)
                       Sort Key: disttable_1.temp DESC
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_1 (actual rows=1 loops=1)
                             Output: disttable_1.temp
                             Data node: data_node_1
                             Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit (actual rows=1 loops=1)
                                 Output: _dist_hyper_1_1_chunk.temp
                                 Buffers: shared hit=2
                                 ->  Sort (actual rows=1 loops=1)
                                       Output: _dist_hyper_1_1_chunk.temp
                                       Sort Key: _dist_hyper_1_1_chunk.temp DESC
                                       Sort Method: top-N heapsort 
                                       Buffers: shared hit=2
                                       ->  Append (actual rows=4 loops=1)
                                             Buffers: shared hit=2
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_1_chunk (actual rows=3 loops=1)
                                                   Output: _dist_hyper_1_1_chunk.temp
                                                   Filter: (_dist_hyper_1_1_chunk.temp IS NOT NULL)
                                                   Buffers: shared hit=1
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_4_chunk (actual rows=1 loops=1)
                                                   Output: _dist_hyper_1_4_chunk.temp
                                                   Filter: (_dist_hyper_1_4_chunk.temp IS NOT NULL)
                                                   Buffers: shared hit=1
 
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_2 (actual rows=1 loops=1)
                             Output: disttable_2.temp
                             Data node: data_node_2
                             Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_5_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit (actual rows=1 loops=1)
                                 Output: _dist_hyper_1_3_chunk.temp
                                 Buffers: shared hit=2
                                 ->  Sort (actual rows=1 loops=1)
                                       Output: _dist_hyper_1_3_chunk.temp
                                       Sort Key: _dist_hyper_1_3_chunk.temp DESC
                                       Sort Method: quicksort 
                                       Buffers: shared hit=2
                                       ->  Append (actual rows=2 loops=1)
                                             Buffers: shared hit=2
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_3_chunk (actual rows=1 loops=1)
                                                   Output: _dist_hyper_1_3_chunk.temp
                                                   Filter: (_dist_hyper_1_3_chunk.temp IS NOT NULL)
                                                   Buffers: shared hit=1
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_5_chunk (actual rows=1 loops=1)
                                                   Output: _dist_hyper_1_5_chunk.temp
                                                   Filter: (_dist_hyper_1_5_chunk.temp IS NOT NULL)
                                                   Buffers: shared hit=1
 
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_3 (actual rows=1 loops=1)
                             Output: disttable_3.temp
                             Data node: data_node_3
                             Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_6_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit (actual rows=1 loops=1)
                                 Output: _dist_hyper_1_2_chunk.temp
                                 Buffers: shared hit=2
                                 ->  Sort (actual rows=1 loops=1)
                                       Output: _dist_hyper_1_2_chunk.temp
                                       Sort Key: _dist_hyper_1_2_chunk.temp DESC
                                       Sort Method: top-N heapsort 
                                       Buffers: shared hit=2
                                       ->  Append (actual rows=3 loops=1)
                                             Buffers: shared hit=2
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_2_chunk (actual rows=1 loops=1)
                                                   Output: _dist_hyper_1_2_chunk.temp
                                                   Filter: (_dist_hyper_1_2_chunk.temp IS NOT NULL)
                                                   Buffers: shared hit=1
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_6_chunk (actual rows=2 loops=1)
                                                   Output: _dist_hyper_1_6_chunk.temp
                                                   Filter: (_dist_hyper_1_6_chunk.temp IS NOT NULL)
                                                   Buffers: shared hit=1
 
(84 rows)

-- The constraints, indexes, and triggers on foreign chunks. Only
-- check constraints should recurse to foreign chunks (although they
-- aren't enforced on a foreign table)
SELECT st."Child" as chunk_relid, test.show_constraints((st)."Child")
FROM test.show_subtables('disttable') st;
                 chunk_relid                 |                                                                                   show_constraints                                                                                   
---------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 _timescaledb_internal._dist_hyper_1_1_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (constraint_2,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) < 715827882)",f,f,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (constraint_3,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) >= 1431655764)",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (constraint_4,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 715827882) AND (_timescaledb_internal.get_partition_hash(device) < 1431655764))",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (constraint_2,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) < 715827882)",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (constraint_4,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 715827882) AND (_timescaledb_internal.get_partition_hash(device) < 1431655764))",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (constraint_3,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) >= 1431655764)",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
(18 rows)

SELECT st."Child" as chunk_relid, test.show_indexes((st)."Child")
FROM test.show_subtables('disttable') st;
 chunk_relid | show_indexes 
-------------+--------------
(0 rows)

SELECT st."Child" as chunk_relid, test.show_triggers((st)."Child")
FROM test.show_subtables('disttable') st;
 chunk_relid | show_triggers 
-------------+---------------
(0 rows)

-- Check that the chunks are assigned data nodes
SELECT * FROM _timescaledb_catalog.chunk_data_node;
 chunk_id | node_chunk_id |  node_name  
----------+---------------+-------------
        1 |             1 | data_node_1
        2 |             1 | data_node_3
        3 |             1 | data_node_2
        4 |             2 | data_node_1
        5 |             2 | data_node_2
        6 |             2 | data_node_3
(6 rows)

-- Adding a new trigger should not recurse to foreign chunks
CREATE TRIGGER _1_test_trigger_insert
    AFTER INSERT ON disttable
    FOR EACH ROW EXECUTE FUNCTION test_trigger();
SELECT st."Child" as chunk_relid, test.show_triggers((st)."Child")
FROM test.show_subtables('disttable') st;
 chunk_relid | show_triggers 
-------------+---------------
(0 rows)

-- Check that we can create indexes on distributed hypertables and
-- that they don't recurse to foreign chunks
CREATE INDEX ON disttable (time, device);
SELECT * FROM test.show_indexes('disttable');
           Index           |    Columns    | Expr | Unique | Primary | Exclusion | Tablespace 
---------------------------+---------------+------+--------+---------+-----------+------------
 disttable_device_time_idx | {device,time} |      | f      | f       | f         | 
 disttable_pkey            | {time,device} |      | t      | t       | f         | 
 disttable_time_device_idx | {time,device} |      | f      | f       | f         | 
 disttable_time_idx        | {time}        |      | f      | f       | f         | 
(4 rows)

SELECT st."Child" as chunk_relid, test.show_indexes((st)."Child")
FROM test.show_subtables('disttable') st;
 chunk_relid | show_indexes 
-------------+--------------
(0 rows)

-- No index mappings should exist either
SELECT * FROM _timescaledb_catalog.chunk_index;
 chunk_id | index_name | hypertable_id | hypertable_index_name 
----------+------------+---------------+-----------------------
(0 rows)

-- Check that creating columns work
ALTER TABLE disttable ADD COLUMN "Color" int;
SELECT * FROM test.show_columns('disttable');
 Column |           Type           | NotNull 
--------+--------------------------+---------
 time   | timestamp with time zone | t
 device | integer                  | t
 temp   | double precision         | f
 Color  | integer                  | f
(4 rows)

SELECT st."Child" as chunk_relid, test.show_columns((st)."Child")
FROM test.show_subtables('disttable') st;
                 chunk_relid                 |            show_columns             
---------------------------------------------+-------------------------------------
 _timescaledb_internal._dist_hyper_1_1_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_1_chunk | (Color,integer,f)
 _timescaledb_internal._dist_hyper_1_2_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_2_chunk | (Color,integer,f)
 _timescaledb_internal._dist_hyper_1_3_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_3_chunk | (Color,integer,f)
 _timescaledb_internal._dist_hyper_1_4_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_4_chunk | (Color,integer,f)
 _timescaledb_internal._dist_hyper_1_5_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_5_chunk | (Color,integer,f)
 _timescaledb_internal._dist_hyper_1_6_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_6_chunk | (Color,integer,f)
(24 rows)

-- Adding a new unique constraint should not recurse to foreign
-- chunks, but a check constraint should
ALTER TABLE disttable ADD CONSTRAINT disttable_color_unique UNIQUE (time, device, "Color");
ALTER TABLE disttable ADD CONSTRAINT disttable_temp_non_negative CHECK (temp > 0.0);
SELECT st."Child" as chunk_relid, test.show_constraints((st)."Child")
FROM test.show_subtables('disttable') st;
                 chunk_relid                 |                                                                                   show_constraints                                                                                   
---------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 _timescaledb_internal._dist_hyper_1_1_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (constraint_2,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) < 715827882)",f,f,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (constraint_3,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) >= 1431655764)",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (constraint_4,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 715827882) AND (_timescaledb_internal.get_partition_hash(device) < 1431655764))",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (constraint_2,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) < 715827882)",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (constraint_4,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 715827882) AND (_timescaledb_internal.get_partition_hash(device) < 1431655764))",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (constraint_3,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) >= 1431655764)",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
(24 rows)

SELECT cc.*
FROM (SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
      FROM show_chunks('disttable')) c,
      _timescaledb_catalog.chunk_constraint cc
WHERE c.chunk_id = cc.chunk_id;
 chunk_id | dimension_slice_id | constraint_name | hypertable_constraint_name 
----------+--------------------+-----------------+----------------------------
        1 |                  2 | constraint_2    | 
        1 |                  1 | constraint_1    | 
        2 |                  3 | constraint_3    | 
        2 |                  1 | constraint_1    | 
        3 |                  4 | constraint_4    | 
        3 |                  1 | constraint_1    | 
        4 |                  2 | constraint_2    | 
        4 |                  5 | constraint_5    | 
        5 |                  4 | constraint_4    | 
        5 |                  5 | constraint_5    | 
        6 |                  3 | constraint_3    | 
        6 |                  5 | constraint_5    | 
(12 rows)

-- Show contents after re-adding column
SELECT * FROM disttable;
             time             | device | temp | Color 
------------------------------+--------+------+-------
 Sun Jan 01 06:01:00 2017 PST |      1 |  1.1 |      
 Sun Jan 01 08:01:00 2017 PST |      1 |  1.2 |      
 Sun Jan 01 06:05:00 2017 PST |      1 |  1.4 |      
 Mon Jul 02 08:01:00 2018 PDT |     87 |  1.6 |      
 Mon Jan 02 08:01:00 2017 PST |      2 |  1.3 |      
 Sun Jul 01 06:01:00 2018 PDT |     13 |  1.4 |      
 Sun Jan 01 09:11:00 2017 PST |      3 |  2.1 |      
 Sun Jul 01 09:11:00 2018 PDT |     90 |  2.7 |      
 Sun Jul 01 08:01:00 2018 PDT |     29 |  1.5 |      
(9 rows)

-- Test INSERTS with RETURNING. Since we previously dropped a column
-- on the hypertable, this also tests that we handle conversion of the
-- attribute numbers in the RETURNING clause, since they now differ
-- between the hypertable root relation and the chunk currently
-- RETURNING from.
INSERT INTO disttable (time, device, "Color", temp)
VALUES ('2017-09-02 06:09', 4, 1, 9.8)
RETURNING time, "Color", temp;
             time             | Color | temp 
------------------------------+-------+------
 Sat Sep 02 06:09:00 2017 PDT |     1 |  9.8
(1 row)

INSERT INTO disttable (time, device, "Color", temp)
VALUES ('2017-09-03 06:18', 9, 3, 8.7)
RETURNING 1;
 ?column? 
----------
        1
(1 row)

-- On conflict
INSERT INTO disttable (time, device, "Color", temp)
VALUES ('2017-09-02 06:09', 6, 2, 10.5)
ON CONFLICT DO NOTHING;
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable');
$$);
NOTICE:  [data_node_1]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [data_node_1]:
chunk_id|hypertable_id|schema_name          |table_name           |relkind|slices                                                                                     
--------+-------------+---------------------+---------------------+-------+-------------------------------------------------------------------------------------------
       1|            1|_timescaledb_internal|_dist_hyper_1_1_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [-9223372036854775808, 715827882]}
       2|            1|_timescaledb_internal|_dist_hyper_1_4_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [-9223372036854775808, 715827882]}
       3|            1|_timescaledb_internal|_dist_hyper_1_9_chunk|r      |{"time": [1504137600000000, 1504742400000000], "device": [-9223372036854775808, 715827882]}
(3 rows)


NOTICE:  [data_node_2]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [data_node_2]:
chunk_id|hypertable_id|schema_name          |table_name           |relkind|slices                                                                           
--------+-------------+---------------------+---------------------+-------+---------------------------------------------------------------------------------
       1|            1|_timescaledb_internal|_dist_hyper_1_3_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [715827882, 1431655764]}
       2|            1|_timescaledb_internal|_dist_hyper_1_5_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [715827882, 1431655764]}
       3|            1|_timescaledb_internal|_dist_hyper_1_7_chunk|r      |{"time": [1504137600000000, 1504742400000000], "device": [715827882, 1431655764]}
(3 rows)


NOTICE:  [data_node_3]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [data_node_3]:
chunk_id|hypertable_id|schema_name          |table_name           |relkind|slices                                                                                     
--------+-------------+---------------------+---------------------+-------+-------------------------------------------------------------------------------------------
       1|            1|_timescaledb_internal|_dist_hyper_1_2_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [1431655764, 9223372036854775807]}
       2|            1|_timescaledb_internal|_dist_hyper_1_6_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [1431655764, 9223372036854775807]}
       3|            1|_timescaledb_internal|_dist_hyper_1_8_chunk|r      |{"time": [1504137600000000, 1504742400000000], "device": [1431655764, 9223372036854775807]}
(3 rows)


 remote_exec 
-------------
 
(1 row)

-- Show new row and that conflicting row is not inserted
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT * FROM disttable;
$$);
NOTICE:  [data_node_1]: 
SELECT * FROM disttable
NOTICE:  [data_node_1]:
time                        |device|temp|Color
----------------------------+------+----+-----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1|     
Sun Jan 01 08:01:00 2017 PST|     1| 1.2|     
Sun Jan 01 06:05:00 2017 PST|     1| 1.4|     
Mon Jul 02 08:01:00 2018 PDT|    87| 1.6|     
Sat Sep 02 06:09:00 2017 PDT|     6|10.5|    2
(5 rows)


NOTICE:  [data_node_2]: 
SELECT * FROM disttable
NOTICE:  [data_node_2]:
time                        |device|temp|Color
----------------------------+------+----+-----
Mon Jan 02 08:01:00 2017 PST|     2| 1.3|     
Sun Jul 01 06:01:00 2018 PDT|    13| 1.4|     
Sat Sep 02 06:09:00 2017 PDT|     4| 9.8|    1
(3 rows)


NOTICE:  [data_node_3]: 
SELECT * FROM disttable
NOTICE:  [data_node_3]:
time                        |device|temp|Color
----------------------------+------+----+-----
Sun Jan 01 09:11:00 2017 PST|     3| 2.1|     
Sun Jul 01 09:11:00 2018 PDT|    90| 2.7|     
Sun Jul 01 08:01:00 2018 PDT|    29| 1.5|     
Sun Sep 03 06:18:00 2017 PDT|     9| 8.7|    3
(4 rows)


 remote_exec 
-------------
 
(1 row)

\set ON_ERROR_STOP 0
-- ON CONFLICT only works with DO NOTHING
INSERT INTO disttable (time, device, "Color", temp)
VALUES ('2017-09-09 08:13', 7, 3, 27.5)
ON CONFLICT (time) DO UPDATE SET temp = 3.2;
ERROR:  unexpected ON CONFLICT specification: 2
-- Test that an INSERT that would create a chunk does not work on a
-- data node
SELECT * FROM test.remote_exec('{ data_node_1 }',
$$
    INSERT INTO disttable VALUES ('2019-01-02 12:34', 1, 2, 9.3)
$$);
NOTICE:  [data_node_1]: 
    INSERT INTO disttable VALUES ('2019-01-02 12:34', 1, 2, 9.3)

ERROR:  [data_node_1]: distributed hypertable member cannot create chunk on its own
\set ON_ERROR_STOP 1
-- However, INSERTs on a data node that does not create a chunk works.
SELECT * FROM test.remote_exec('{ data_node_1 }',
$$
    INSERT INTO disttable VALUES ('2017-09-03 06:09', 1, 2, 9.3)
$$);
NOTICE:  [data_node_1]: 
    INSERT INTO disttable VALUES ('2017-09-03 06:09', 1, 2, 9.3)

 remote_exec 
-------------
 
(1 row)

-- Test updates
UPDATE disttable SET "Color" = 4 WHERE "Color" = 3;
SELECT * FROM disttable;
             time             | device | temp | Color 
------------------------------+--------+------+-------
 Sun Jan 01 06:01:00 2017 PST |      1 |  1.1 |      
 Sun Jan 01 08:01:00 2017 PST |      1 |  1.2 |      
 Sun Jan 01 06:05:00 2017 PST |      1 |  1.4 |      
 Mon Jul 02 08:01:00 2018 PDT |     87 |  1.6 |      
 Sat Sep 02 06:09:00 2017 PDT |      6 | 10.5 |     2
 Sun Sep 03 06:09:00 2017 PDT |      1 |    2 |     9
 Mon Jan 02 08:01:00 2017 PST |      2 |  1.3 |      
 Sun Jul 01 06:01:00 2018 PDT |     13 |  1.4 |      
 Sat Sep 02 06:09:00 2017 PDT |      4 |  9.8 |     1
 Sun Jan 01 09:11:00 2017 PST |      3 |  2.1 |      
 Sun Jul 01 09:11:00 2018 PDT |     90 |  2.7 |      
 Sun Jul 01 08:01:00 2018 PDT |     29 |  1.5 |      
 Sun Sep 03 06:18:00 2017 PDT |      9 |  8.7 |     4
(13 rows)

WITH devices AS (
     SELECT DISTINCT device FROM disttable ORDER BY device
)
UPDATE disttable SET "Color" = 2 WHERE device = (SELECT device FROM devices LIMIT 1);
\set ON_ERROR_STOP 0
-- Updates referencing non-existing column
UPDATE disttable SET device = 4 WHERE no_such_column = 2;
ERROR:  column "no_such_column" does not exist at character 39
UPDATE disttable SET no_such_column = 4 WHERE device = 2;
ERROR:  column "no_such_column" of relation "disttable" does not exist at character 22
-- Update to system column
UPDATE disttable SET tableoid = 4 WHERE device = 2;
ERROR:  cannot assign to system column "tableoid" at character 22
\set ON_ERROR_STOP 1
-- Test deletes (no rows deleted)
DELETE FROM disttable WHERE device = 3
RETURNING *;
             time             | device | temp | Color 
------------------------------+--------+------+-------
 Sun Jan 01 09:11:00 2017 PST |      3 |  2.1 |      
(1 row)

-- Test deletes (rows deleted)
DELETE FROM disttable WHERE device = 4
RETURNING *;
             time             | device | temp | Color 
------------------------------+--------+------+-------
 Sat Sep 02 06:09:00 2017 PDT |      4 |  9.8 |     1
(1 row)

-- Query to show that rows are deleted
SELECT * FROM disttable;
             time             | device | temp | Color 
------------------------------+--------+------+-------
 Sun Jan 01 06:01:00 2017 PST |      1 |  1.1 |     2
 Sun Jan 01 08:01:00 2017 PST |      1 |  1.2 |     2
 Sun Jan 01 06:05:00 2017 PST |      1 |  1.4 |     2
 Mon Jul 02 08:01:00 2018 PDT |     87 |  1.6 |      
 Sat Sep 02 06:09:00 2017 PDT |      6 | 10.5 |     2
 Sun Sep 03 06:09:00 2017 PDT |      1 |    2 |     2
 Mon Jan 02 08:01:00 2017 PST |      2 |  1.3 |      
 Sun Jul 01 06:01:00 2018 PDT |     13 |  1.4 |      
 Sun Jul 01 09:11:00 2018 PDT |     90 |  2.7 |      
 Sun Jul 01 08:01:00 2018 PDT |     29 |  1.5 |      
 Sun Sep 03 06:18:00 2017 PDT |      9 |  8.7 |     4
(11 rows)

-- Ensure rows are deleted on the data nodes
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT * FROM disttable;
$$);
NOTICE:  [data_node_1]: 
SELECT * FROM disttable
NOTICE:  [data_node_1]:
time                        |device|temp|Color
----------------------------+------+----+-----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1|    2
Sun Jan 01 08:01:00 2017 PST|     1| 1.2|    2
Sun Jan 01 06:05:00 2017 PST|     1| 1.4|    2
Mon Jul 02 08:01:00 2018 PDT|    87| 1.6|     
Sat Sep 02 06:09:00 2017 PDT|     6|10.5|    2
Sun Sep 03 06:09:00 2017 PDT|     1|   2|    2
(6 rows)


NOTICE:  [data_node_2]: 
SELECT * FROM disttable
NOTICE:  [data_node_2]:
time                        |device|temp|Color
----------------------------+------+----+-----
Mon Jan 02 08:01:00 2017 PST|     2| 1.3|     
Sun Jul 01 06:01:00 2018 PDT|    13| 1.4|     
(2 rows)


NOTICE:  [data_node_3]: 
SELECT * FROM disttable
NOTICE:  [data_node_3]:
time                        |device|temp|Color
----------------------------+------+----+-----
Sun Jul 01 09:11:00 2018 PDT|    90| 2.7|     
Sun Jul 01 08:01:00 2018 PDT|    29| 1.5|     
Sun Sep 03 06:18:00 2017 PDT|     9| 8.7|    4
(3 rows)


 remote_exec 
-------------
 
(1 row)

-- Test TRUNCATE
TRUNCATE disttable;
-- No data should remain
SELECT * FROM disttable;
 time | device | temp | Color 
------+--------+------+-------
(0 rows)

-- Metadata and tables cleaned up
SELECT * FROM _timescaledb_catalog.chunk;
 id | hypertable_id | schema_name | table_name | compressed_chunk_id | dropped 
----+---------------+-------------+------------+---------------------+---------
(0 rows)

SELECT * FROM show_chunks('disttable');
 show_chunks 
-------------
(0 rows)

-- Also cleaned up remotely
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT * FROM _timescaledb_catalog.chunk;
SELECT * FROM show_chunks('disttable');
SELECT * FROM disttable;
$$);
NOTICE:  [data_node_1]: 
SELECT * FROM _timescaledb_catalog.chunk
NOTICE:  [data_node_1]:
id|hypertable_id|schema_name|table_name|compressed_chunk_id|dropped
--+-------------+-----------+----------+-------------------+-------
(0 rows)


NOTICE:  [data_node_1]: 
SELECT * FROM show_chunks('disttable')
NOTICE:  [data_node_1]:
show_chunks
-----------
(0 rows)


NOTICE:  [data_node_1]: 
SELECT * FROM disttable
NOTICE:  [data_node_1]:
time|device|temp|Color
----+------+----+-----
(0 rows)


NOTICE:  [data_node_2]: 
SELECT * FROM _timescaledb_catalog.chunk
NOTICE:  [data_node_2]:
id|hypertable_id|schema_name|table_name|compressed_chunk_id|dropped
--+-------------+-----------+----------+-------------------+-------
(0 rows)


NOTICE:  [data_node_2]: 
SELECT * FROM show_chunks('disttable')
NOTICE:  [data_node_2]:
show_chunks
-----------
(0 rows)


NOTICE:  [data_node_2]: 
SELECT * FROM disttable
NOTICE:  [data_node_2]:
time|device|temp|Color
----+------+----+-----
(0 rows)


NOTICE:  [data_node_3]: 
SELECT * FROM _timescaledb_catalog.chunk
NOTICE:  [data_node_3]:
id|hypertable_id|schema_name|table_name|compressed_chunk_id|dropped
--+-------------+-----------+----------+-------------------+-------
(0 rows)


NOTICE:  [data_node_3]: 
SELECT * FROM show_chunks('disttable')
NOTICE:  [data_node_3]:
show_chunks
-----------
(0 rows)


NOTICE:  [data_node_3]: 
SELECT * FROM disttable
NOTICE:  [data_node_3]:
time|device|temp|Color
----+------+----+-----
(0 rows)


 remote_exec 
-------------
 
(1 row)

-- The hypertable view also shows no chunks and no data
SELECT * FROM timescaledb_information.hypertables
ORDER BY table_schema, table_name;
 table_schema |   table_name    |    owner    | num_dimensions | num_chunks | compression_enabled | is_distributed | replication_factor |              data_nodes               | tablespaces 
--------------+-----------------+-------------+----------------+------------+---------------------+----------------+--------------------+---------------------------------------+-------------
 public       | disttable       | test_role_1 |              2 |          0 | f                   | t              |                  1 | {data_node_1,data_node_2,data_node_3} | 
 public       | underreplicated | test_role_1 |              1 |          0 | f                   | t              |                  4 | {data_node_1,data_node_2,data_node_3} | 
(2 rows)

-- Test underreplicated chunk warning
INSERT INTO underreplicated VALUES ('2017-01-01 06:01', 1, 1.1),
                                   ('2017-01-02 07:01', 2, 3.5);
WARNING:  new chunks for hypertable "underreplicated" will be under-replicated due to insufficient available data nodes, lacks 1 data node(s)
SELECT * FROM _timescaledb_catalog.chunk_data_node;
 chunk_id | node_chunk_id |  node_name  
----------+---------------+-------------
       10 |             4 | data_node_1
       10 |             4 | data_node_2
       10 |             4 | data_node_3
(3 rows)

SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('underreplicated');
 chunk_id | hypertable_id |      schema_name      |       table_name       | relkind |                     slices                     
----------+---------------+-----------------------+------------------------+---------+------------------------------------------------
       10 |             2 | _timescaledb_internal | _dist_hyper_2_10_chunk | f       | {"time": [1482969600000000, 1483574400000000]}
(1 row)

-- Show chunk data node mappings
SELECT * FROM _timescaledb_catalog.chunk_data_node;
 chunk_id | node_chunk_id |  node_name  
----------+---------------+-------------
       10 |             4 | data_node_1
       10 |             4 | data_node_2
       10 |             4 | data_node_3
(3 rows)

-- Show that chunks are created on remote data nodes and that all
-- data nodes/chunks have the same data due to replication
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('underreplicated');
$$);
NOTICE:  [data_node_1]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('underreplicated')
NOTICE:  [data_node_1]:
chunk_id|hypertable_id|schema_name          |table_name            |relkind|slices                                        
--------+-------------+---------------------+----------------------+-------+----------------------------------------------
       4|            2|_timescaledb_internal|_dist_hyper_2_10_chunk|r      |{"time": [1482969600000000, 1483574400000000]}
(1 row)


NOTICE:  [data_node_2]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('underreplicated')
NOTICE:  [data_node_2]:
chunk_id|hypertable_id|schema_name          |table_name            |relkind|slices                                        
--------+-------------+---------------------+----------------------+-------+----------------------------------------------
       4|            2|_timescaledb_internal|_dist_hyper_2_10_chunk|r      |{"time": [1482969600000000, 1483574400000000]}
(1 row)


NOTICE:  [data_node_3]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('underreplicated')
NOTICE:  [data_node_3]:
chunk_id|hypertable_id|schema_name          |table_name            |relkind|slices                                        
--------+-------------+---------------------+----------------------+-------+----------------------------------------------
       4|            2|_timescaledb_internal|_dist_hyper_2_10_chunk|r      |{"time": [1482969600000000, 1483574400000000]}
(1 row)


 remote_exec 
-------------
 
(1 row)

SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT * FROM underreplicated;
$$);
NOTICE:  [data_node_1]: 
SELECT * FROM underreplicated
NOTICE:  [data_node_1]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
Mon Jan 02 07:01:00 2017 PST|     2| 3.5
(2 rows)


NOTICE:  [data_node_2]: 
SELECT * FROM underreplicated
NOTICE:  [data_node_2]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
Mon Jan 02 07:01:00 2017 PST|     2| 3.5
(2 rows)


NOTICE:  [data_node_3]: 
SELECT * FROM underreplicated
NOTICE:  [data_node_3]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
Mon Jan 02 07:01:00 2017 PST|     2| 3.5
(2 rows)


 remote_exec 
-------------
 
(1 row)

-- Test updates
UPDATE underreplicated SET temp = 2.0 WHERE device = 2
RETURNING time, temp, device;
             time             | temp | device 
------------------------------+------+--------
 Mon Jan 02 07:01:00 2017 PST |    2 |      2
(1 row)

SELECT * FROM underreplicated;
             time             | device | temp 
------------------------------+--------+------
 Sun Jan 01 06:01:00 2017 PST |      1 |  1.1
 Mon Jan 02 07:01:00 2017 PST |      2 |    2
(2 rows)

-- Show that all replica chunks are updated
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT * FROM underreplicated;
$$);
NOTICE:  [data_node_1]: 
SELECT * FROM underreplicated
NOTICE:  [data_node_1]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
Mon Jan 02 07:01:00 2017 PST|     2|   2
(2 rows)


NOTICE:  [data_node_2]: 
SELECT * FROM underreplicated
NOTICE:  [data_node_2]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
Mon Jan 02 07:01:00 2017 PST|     2|   2
(2 rows)


NOTICE:  [data_node_3]: 
SELECT * FROM underreplicated
NOTICE:  [data_node_3]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
Mon Jan 02 07:01:00 2017 PST|     2|   2
(2 rows)


 remote_exec 
-------------
 
(1 row)

DELETE FROM underreplicated WHERE device = 2
RETURNING *;
             time             | device | temp 
------------------------------+--------+------
 Mon Jan 02 07:01:00 2017 PST |      2 |    2
(1 row)

-- Ensure deletes across all data nodes
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT * FROM underreplicated;
$$);
NOTICE:  [data_node_1]: 
SELECT * FROM underreplicated
NOTICE:  [data_node_1]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
(1 row)


NOTICE:  [data_node_2]: 
SELECT * FROM underreplicated
NOTICE:  [data_node_2]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
(1 row)


NOTICE:  [data_node_3]: 
SELECT * FROM underreplicated
NOTICE:  [data_node_3]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
(1 row)


 remote_exec 
-------------
 
(1 row)

-- Test hypertable creation fails on distributed error
SELECT * FROM test.remote_exec('{ data_node_3 }', $$
CREATE TABLE remotetable(time timestamptz PRIMARY KEY, id int, cost float);
SELECT * FROM underreplicated;
$$);
NOTICE:  [data_node_3]: 
CREATE TABLE remotetable(time timestamptz PRIMARY KEY, id int, cost float)
NOTICE:  [data_node_3]: 
SELECT * FROM underreplicated
NOTICE:  [data_node_3]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
(1 row)


 remote_exec 
-------------
 
(1 row)

\set ON_ERROR_STOP 0
CREATE TABLE remotetable(time timestamptz PRIMARY KEY, device int CHECK (device > 0), color int, temp float);
SELECT * FROM create_hypertable('remotetable', 'time', replication_factor => 1);
ERROR:  [data_node_3]: relation "remotetable" already exists
-- Test distributed_hypertable creation fails with replication factor 0
CREATE TABLE remotetable2(time timestamptz PRIMARY KEY, device int CHECK (device > 0), color int, temp float);
SELECT * FROM create_distributed_hypertable('remotetable2', 'time', replication_factor => 0);
ERROR:  invalid replication factor
\set ON_ERROR_STOP 1
SELECT * FROM timescaledb_information.hypertables
ORDER BY table_schema, table_name;
 table_schema |   table_name    |    owner    | num_dimensions | num_chunks | compression_enabled | is_distributed | replication_factor |              data_nodes               | tablespaces 
--------------+-----------------+-------------+----------------+------------+---------------------+----------------+--------------------+---------------------------------------+-------------
 public       | disttable       | test_role_1 |              2 |          0 | f                   | t              |                  1 | {data_node_1,data_node_2,data_node_3} | 
 public       | underreplicated | test_role_1 |              1 |          1 | f                   | t              |                  4 | {data_node_1,data_node_2,data_node_3} | 
(2 rows)

-- Test distributed hypertable creation with many parameters
\c data_node_1
CREATE SCHEMA "T3sTSch";
CREATE SCHEMA "Table\\Schema";
CREATE SCHEMA "single'schema";
GRANT ALL ON SCHEMA "T3sTSch" TO :ROLE_1;
GRANT ALL ON SCHEMA "Table\\Schema" TO :ROLE_1;
GRANT ALL ON SCHEMA "single'schema" TO :ROLE_1;
\c data_node_2
CREATE SCHEMA "T3sTSch";
CREATE SCHEMA "Table\\Schema";
GRANT ALL ON SCHEMA "T3sTSch" TO :ROLE_1;
GRANT ALL ON SCHEMA "Table\\Schema" TO :ROLE_1;
\c data_node_3
CREATE SCHEMA "T3sTSch";
CREATE SCHEMA "Table\\Schema";
GRANT ALL ON SCHEMA "T3sTSch" TO :ROLE_1;
GRANT ALL ON SCHEMA "Table\\Schema" TO :ROLE_1;
SET ROLE :ROLE_1;
\c :TEST_DBNAME :ROLE_SUPERUSER
CREATE SCHEMA "T3sTSch";
CREATE SCHEMA "Table\\Schema";
CREATE SCHEMA "single'schema";
GRANT ALL ON SCHEMA "T3sTSch" TO :ROLE_1;
GRANT ALL ON SCHEMA "Table\\Schema" TO :ROLE_1;
GRANT ALL ON SCHEMA "single'schema" TO :ROLE_1;
SET ROLE :ROLE_1;
CREATE TABLE "Table\\Schema"."Param_Table"("time Col %#^#@$#" timestamptz, __region text, reading float);
SELECT * FROM create_distributed_hypertable('"Table\\Schema"."Param_Table"', 'time Col %#^#@$#', partitioning_column => '__region',
associated_schema_name => 'T3sTSch', associated_table_prefix => 'test*pre_', chunk_time_interval => interval '1 week',
create_default_indexes => FALSE, if_not_exists => TRUE, replication_factor => 2,
data_nodes => '{ "data_node_3" }');
WARNING:  only one data node was assigned to the hypertable
NOTICE:  adding not-null constraint to column "time Col %#^#@$#"
 hypertable_id |  schema_name  | table_name  | created 
---------------+---------------+-------------+---------
             4 | Table\\Schema | Param_Table | t
(1 row)

-- Test attach_data_node. First show dimensions and currently attached
-- servers.  The number of slices in the space dimension should equal
-- the number of servers since we didn't explicitly specify
-- number_partitions
SELECT h.table_name, d.column_name, d.num_slices
FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id
AND h.table_name = 'Param_Table'
ORDER BY 1, 2, 3;
 table_name  |   column_name    | num_slices 
-------------+------------------+------------
 Param_Table | __region         |          1
 Param_Table | time Col %#^#@$# |           
(2 rows)

SELECT h.table_name, hdn.node_name
FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.hypertable_data_node hdn
WHERE h.id = hdn.hypertable_id
AND h.table_name = 'Param_Table'
ORDER BY 1, 2;
 table_name  |  node_name  
-------------+-------------
 Param_Table | data_node_3
(1 row)

SELECT * FROM attach_data_node('data_node_1', '"Table\\Schema"."Param_Table"');
NOTICE:  the number of partitions in dimension "__region" was increased to 2
 hypertable_id | node_hypertable_id |  node_name  
---------------+--------------------+-------------
             4 |                  3 | data_node_1
(1 row)

-- Show updated metadata after attach
SELECT h.table_name, d.column_name, d.num_slices
FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id
AND h.table_name = 'Param_Table'
ORDER BY 1, 2, 3;
 table_name  |   column_name    | num_slices 
-------------+------------------+------------
 Param_Table | __region         |          2
 Param_Table | time Col %#^#@$# |           
(2 rows)

SELECT h.table_name, hdn.node_name
FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.hypertable_data_node hdn
WHERE h.id = hdn.hypertable_id
AND h.table_name = 'Param_Table'
ORDER BY 1, 2;
 table_name  |  node_name  
-------------+-------------
 Param_Table | data_node_1
 Param_Table | data_node_3
(2 rows)

-- Attach another data node but do not auto-repartition, i.e.,
-- increase the number of slices.
SELECT * FROM attach_data_node('data_node_2', '"Table\\Schema"."Param_Table"', repartition => false);
WARNING:  the number of partitions in dimension "__region" is too low to make use of all attached data nodes
 hypertable_id | node_hypertable_id |  node_name  
---------------+--------------------+-------------
             4 |                  3 | data_node_2
(1 row)

-- Number of slices should not be increased
SELECT h.table_name, d.column_name, d.num_slices
FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id
AND h.table_name = 'Param_Table'
ORDER BY 1, 2, 3;
 table_name  |   column_name    | num_slices 
-------------+------------------+------------
 Param_Table | __region         |          2
 Param_Table | time Col %#^#@$# |           
(2 rows)

-- Manually increase the number of partitions
SELECT * FROM set_number_partitions('"Table\\Schema"."Param_Table"', 4);
 set_number_partitions 
-----------------------
 
(1 row)

-- Verify hypertables on all data nodes
SELECT * FROM _timescaledb_catalog.hypertable;
 id |  schema_name  |   table_name    | associated_schema_name | associated_table_prefix | num_dimensions | chunk_sizing_func_schema |  chunk_sizing_func_name  | chunk_target_size | compressed | compressed_hypertable_id | replication_factor 
----+---------------+-----------------+------------------------+-------------------------+----------------+--------------------------+--------------------------+-------------------+------------+--------------------------+--------------------
  1 | public        | disttable       | _timescaledb_internal  | _dist_hyper_1           |              2 | _timescaledb_internal    | calculate_chunk_interval |                 0 | f          |                          |                  1
  2 | public        | underreplicated | _timescaledb_internal  | _dist_hyper_2           |              1 | _timescaledb_internal    | calculate_chunk_interval |                 0 | f          |                          |                  4
  4 | Table\\Schema | Param_Table     | T3sTSch                | test*pre_               |              2 | _timescaledb_internal    | calculate_chunk_interval |                 0 | f          |                          |                  2
(3 rows)

SELECT * FROM _timescaledb_catalog.dimension;
 id | hypertable_id |   column_name    |       column_type        | aligned | num_slices | partitioning_func_schema | partitioning_func  | interval_length | integer_now_func_schema | integer_now_func 
----+---------------+------------------+--------------------------+---------+------------+--------------------------+--------------------+-----------------+-------------------------+------------------
  1 |             1 | time             | timestamp with time zone | t       |            |                          |                    |    604800000000 |                         | 
  2 |             1 | device           | integer                  | f       |          3 | _timescaledb_internal    | get_partition_hash |                 |                         | 
  3 |             2 | time             | timestamp with time zone | t       |            |                          |                    |    604800000000 |                         | 
  5 |             4 | time Col %#^#@$# | timestamp with time zone | t       |            |                          |                    |    604800000000 |                         | 
  6 |             4 | __region         | text                     | f       |          4 | _timescaledb_internal    | get_partition_hash |                 |                         | 
(5 rows)

SELECT * FROM test.show_triggers('"Table\\Schema"."Param_Table"');
      Trigger      | Type |               Function               
-------------------+------+--------------------------------------
 ts_insert_blocker |    7 | _timescaledb_internal.insert_blocker
(1 row)

SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT * FROM _timescaledb_catalog.hypertable;
SELECT * FROM _timescaledb_catalog.dimension;
SELECT t.tgname, t.tgtype, t.tgfoid::regproc
FROM pg_trigger t, pg_class c WHERE c.relname = 'Param_Table' AND t.tgrelid = c.oid;
$$);
NOTICE:  [data_node_1]: 
SELECT * FROM _timescaledb_catalog.hypertable
NOTICE:  [data_node_1]:
id|schema_name  |table_name     |associated_schema_name|associated_table_prefix|num_dimensions|chunk_sizing_func_schema|chunk_sizing_func_name  |chunk_target_size|compressed|compressed_hypertable_id|replication_factor
--+-------------+---------------+----------------------+-----------------------+--------------+------------------------+------------------------+-----------------+----------+------------------------+------------------
 1|public       |disttable      |_timescaledb_internal |_dist_hyper_1          |             2|_timescaledb_internal   |calculate_chunk_interval|                0|f         |                        |                -1
 2|public       |underreplicated|_timescaledb_internal |_dist_hyper_2          |             1|_timescaledb_internal   |calculate_chunk_interval|                0|f         |                        |                -1
 3|Table\\Schema|Param_Table    |T3sTSch               |test*pre_              |             2|_timescaledb_internal   |calculate_chunk_interval|                0|f         |                        |                -1
(3 rows)


NOTICE:  [data_node_1]: 
SELECT * FROM _timescaledb_catalog.dimension
NOTICE:  [data_node_1]:
id|hypertable_id|column_name     |column_type             |aligned|num_slices|partitioning_func_schema|partitioning_func |interval_length|integer_now_func_schema|integer_now_func
--+-------------+----------------+------------------------+-------+----------+------------------------+------------------+---------------+-----------------------+----------------
 1|            1|time            |timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 2|            1|device          |integer                 |f      |         3|_timescaledb_internal   |get_partition_hash|               |                       |                
 3|            2|time            |timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 4|            3|time Col %#^#@$#|timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 5|            3|__region        |text                    |f      |         4|_timescaledb_internal   |get_partition_hash|               |                       |                
(5 rows)


NOTICE:  [data_node_1]: 
SELECT t.tgname, t.tgtype, t.tgfoid::regproc
FROM pg_trigger t, pg_class c WHERE c.relname = 'Param_Table' AND t.tgrelid = c.oid
NOTICE:  [data_node_1]:
tgname           |tgtype|tgfoid                              
-----------------+------+------------------------------------
ts_insert_blocker|     7|_timescaledb_internal.insert_blocker
(1 row)


NOTICE:  [data_node_2]: 
SELECT * FROM _timescaledb_catalog.hypertable
NOTICE:  [data_node_2]:
id|schema_name  |table_name     |associated_schema_name|associated_table_prefix|num_dimensions|chunk_sizing_func_schema|chunk_sizing_func_name  |chunk_target_size|compressed|compressed_hypertable_id|replication_factor
--+-------------+---------------+----------------------+-----------------------+--------------+------------------------+------------------------+-----------------+----------+------------------------+------------------
 1|public       |disttable      |_timescaledb_internal |_dist_hyper_1          |             2|_timescaledb_internal   |calculate_chunk_interval|                0|f         |                        |                -1
 2|public       |underreplicated|_timescaledb_internal |_dist_hyper_2          |             1|_timescaledb_internal   |calculate_chunk_interval|                0|f         |                        |                -1
 3|Table\\Schema|Param_Table    |T3sTSch               |test*pre_              |             2|_timescaledb_internal   |calculate_chunk_interval|                0|f         |                        |                -1
(3 rows)


NOTICE:  [data_node_2]: 
SELECT * FROM _timescaledb_catalog.dimension
NOTICE:  [data_node_2]:
id|hypertable_id|column_name     |column_type             |aligned|num_slices|partitioning_func_schema|partitioning_func |interval_length|integer_now_func_schema|integer_now_func
--+-------------+----------------+------------------------+-------+----------+------------------------+------------------+---------------+-----------------------+----------------
 1|            1|time            |timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 2|            1|device          |integer                 |f      |         3|_timescaledb_internal   |get_partition_hash|               |                       |                
 3|            2|time            |timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 4|            3|time Col %#^#@$#|timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 5|            3|__region        |text                    |f      |         4|_timescaledb_internal   |get_partition_hash|               |                       |                
(5 rows)


NOTICE:  [data_node_2]: 
SELECT t.tgname, t.tgtype, t.tgfoid::regproc
FROM pg_trigger t, pg_class c WHERE c.relname = 'Param_Table' AND t.tgrelid = c.oid
NOTICE:  [data_node_2]:
tgname           |tgtype|tgfoid                              
-----------------+------+------------------------------------
ts_insert_blocker|     7|_timescaledb_internal.insert_blocker
(1 row)


NOTICE:  [data_node_3]: 
SELECT * FROM _timescaledb_catalog.hypertable
NOTICE:  [data_node_3]:
id|schema_name  |table_name     |associated_schema_name|associated_table_prefix|num_dimensions|chunk_sizing_func_schema|chunk_sizing_func_name  |chunk_target_size|compressed|compressed_hypertable_id|replication_factor
--+-------------+---------------+----------------------+-----------------------+--------------+------------------------+------------------------+-----------------+----------+------------------------+------------------
 1|public       |disttable      |_timescaledb_internal |_dist_hyper_1          |             2|_timescaledb_internal   |calculate_chunk_interval|                0|f         |                        |                -1
 2|public       |underreplicated|_timescaledb_internal |_dist_hyper_2          |             1|_timescaledb_internal   |calculate_chunk_interval|                0|f         |                        |                -1
 3|Table\\Schema|Param_Table    |T3sTSch               |test*pre_              |             2|_timescaledb_internal   |calculate_chunk_interval|                0|f         |                        |                -1
(3 rows)


NOTICE:  [data_node_3]: 
SELECT * FROM _timescaledb_catalog.dimension
NOTICE:  [data_node_3]:
id|hypertable_id|column_name     |column_type             |aligned|num_slices|partitioning_func_schema|partitioning_func |interval_length|integer_now_func_schema|integer_now_func
--+-------------+----------------+------------------------+-------+----------+------------------------+------------------+---------------+-----------------------+----------------
 1|            1|time            |timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 2|            1|device          |integer                 |f      |         3|_timescaledb_internal   |get_partition_hash|               |                       |                
 3|            2|time            |timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 4|            3|time Col %#^#@$#|timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 5|            3|__region        |text                    |f      |         4|_timescaledb_internal   |get_partition_hash|               |                       |                
(5 rows)


NOTICE:  [data_node_3]: 
SELECT t.tgname, t.tgtype, t.tgfoid::regproc
FROM pg_trigger t, pg_class c WHERE c.relname = 'Param_Table' AND t.tgrelid = c.oid
NOTICE:  [data_node_3]:
tgname           |tgtype|tgfoid                              
-----------------+------+------------------------------------
ts_insert_blocker|     7|_timescaledb_internal.insert_blocker
(1 row)


 remote_exec 
-------------
 
(1 row)

-- Verify that repartitioning works as expected on detach_data_node
SELECT * FROM detach_data_node('data_node_1', '"Table\\Schema"."Param_Table"', repartition => true);
NOTICE:  the number of partitions in dimension "__region" was decreased to 2
 detach_data_node 
------------------
                1
(1 row)

SELECT h.table_name, d.column_name, d.num_slices
FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id
AND h.table_name = 'Param_Table';
 table_name  |   column_name    | num_slices 
-------------+------------------+------------
 Param_Table | __region         |          2
 Param_Table | time Col %#^#@$# |           
(2 rows)

SELECT * FROM detach_data_node('data_node_2', '"Table\\Schema"."Param_Table"', force => true, repartition => false);
WARNING:  new data for hypertable "Param_Table" will be under-replicated due to detaching data node "data_node_2"
 detach_data_node 
------------------
                1
(1 row)

SELECT h.table_name, d.column_name, d.num_slices
FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id
AND h.table_name = 'Param_Table';
 table_name  |   column_name    | num_slices 
-------------+------------------+------------
 Param_Table | __region         |          2
 Param_Table | time Col %#^#@$# |           
(2 rows)

-- Test multi-dimensional hypertable. The add_dimension() command
-- should be propagated to backends.
CREATE TABLE dimented_table (time timestamptz, column1 int, column2 timestamptz, column3 int);
SELECT * FROM create_distributed_hypertable('dimented_table', 'time', partitioning_column => 'column1', number_partitions  => 4, replication_factor => 1, data_nodes => '{ "data_node_1" }');
WARNING:  only one data node was assigned to the hypertable
NOTICE:  adding not-null constraint to column "time"
 hypertable_id | schema_name |   table_name   | created 
---------------+-------------+----------------+---------
             5 | public      | dimented_table | t
(1 row)

-- Create one chunk to block add_dimension
INSERT INTO dimented_table VALUES('2017-01-01 06:01', 1, '2017-01-01 08:01', 1);
\set ON_ERROR_STOP 0
-- add_dimension should fail when table has data and a chunk
SELECT * FROM add_dimension('dimented_table', 'column2', chunk_time_interval => interval '1 week');
ERROR:  hypertable "dimented_table" has data or empty chunks
\set ON_ERROR_STOP 1
-- Clear table
TRUNCATE dimented_table;
-- Now add_dimension should work
SELECT * FROM add_dimension('dimented_table', 'column2', chunk_time_interval => interval '1 week');
NOTICE:  adding not-null constraint to column "column2"
 dimension_id | schema_name |   table_name   | column_name | created 
--------------+-------------+----------------+-------------+---------
            9 | public      | dimented_table | column2     | t
(1 row)

SELECT * FROM add_dimension('dimented_table', 'column3', 4, partitioning_func => '_timescaledb_internal.get_partition_for_key');
 dimension_id | schema_name |   table_name   | column_name | created 
--------------+-------------+----------------+-------------+---------
           10 | public      | dimented_table | column3     | t
(1 row)

SELECT * FROM _timescaledb_catalog.dimension;
 id | hypertable_id |   column_name    |       column_type        | aligned | num_slices | partitioning_func_schema |   partitioning_func   | interval_length | integer_now_func_schema | integer_now_func 
----+---------------+------------------+--------------------------+---------+------------+--------------------------+-----------------------+-----------------+-------------------------+------------------
  1 |             1 | time             | timestamp with time zone | t       |            |                          |                       |    604800000000 |                         | 
  2 |             1 | device           | integer                  | f       |          3 | _timescaledb_internal    | get_partition_hash    |                 |                         | 
  3 |             2 | time             | timestamp with time zone | t       |            |                          |                       |    604800000000 |                         | 
  5 |             4 | time Col %#^#@$# | timestamp with time zone | t       |            |                          |                       |    604800000000 |                         | 
  6 |             4 | __region         | text                     | f       |          2 | _timescaledb_internal    | get_partition_hash    |                 |                         | 
  7 |             5 | time             | timestamp with time zone | t       |            |                          |                       |    604800000000 |                         | 
  8 |             5 | column1          | integer                  | f       |          4 | _timescaledb_internal    | get_partition_hash    |                 |                         | 
  9 |             5 | column2          | timestamp with time zone | t       |            |                          |                       |    604800000000 |                         | 
 10 |             5 | column3          | integer                  | f       |          4 | _timescaledb_internal    | get_partition_for_key |                 |                         | 
(9 rows)

SELECT * FROM attach_data_node('data_node_2', 'dimented_table');
 hypertable_id | node_hypertable_id |  node_name  
---------------+--------------------+-------------
             5 |                  4 | data_node_2
(1 row)

SELECT * FROM _timescaledb_catalog.dimension;
 id | hypertable_id |   column_name    |       column_type        | aligned | num_slices | partitioning_func_schema |   partitioning_func   | interval_length | integer_now_func_schema | integer_now_func 
----+---------------+------------------+--------------------------+---------+------------+--------------------------+-----------------------+-----------------+-------------------------+------------------
  1 |             1 | time             | timestamp with time zone | t       |            |                          |                       |    604800000000 |                         | 
  2 |             1 | device           | integer                  | f       |          3 | _timescaledb_internal    | get_partition_hash    |                 |                         | 
  3 |             2 | time             | timestamp with time zone | t       |            |                          |                       |    604800000000 |                         | 
  5 |             4 | time Col %#^#@$# | timestamp with time zone | t       |            |                          |                       |    604800000000 |                         | 
  6 |             4 | __region         | text                     | f       |          2 | _timescaledb_internal    | get_partition_hash    |                 |                         | 
  7 |             5 | time             | timestamp with time zone | t       |            |                          |                       |    604800000000 |                         | 
  8 |             5 | column1          | integer                  | f       |          4 | _timescaledb_internal    | get_partition_hash    |                 |                         | 
  9 |             5 | column2          | timestamp with time zone | t       |            |                          |                       |    604800000000 |                         | 
 10 |             5 | column3          | integer                  | f       |          4 | _timescaledb_internal    | get_partition_for_key |                 |                         | 
(9 rows)

-- Note that this didn't get the add_dimension
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT * FROM _timescaledb_catalog.dimension;
$$);
NOTICE:  [data_node_1]: 
SELECT * FROM _timescaledb_catalog.dimension
NOTICE:  [data_node_1]:
id|hypertable_id|column_name     |column_type             |aligned|num_slices|partitioning_func_schema|partitioning_func    |interval_length|integer_now_func_schema|integer_now_func
--+-------------+----------------+------------------------+-------+----------+------------------------+---------------------+---------------+-----------------------+----------------
 1|            1|time            |timestamp with time zone|t      |          |                        |                     |   604800000000|                       |                
 2|            1|device          |integer                 |f      |         3|_timescaledb_internal   |get_partition_hash   |               |                       |                
 3|            2|time            |timestamp with time zone|t      |          |                        |                     |   604800000000|                       |                
 4|            3|time Col %#^#@$#|timestamp with time zone|t      |          |                        |                     |   604800000000|                       |                
 5|            3|__region        |text                    |f      |         4|_timescaledb_internal   |get_partition_hash   |               |                       |                
 6|            4|time            |timestamp with time zone|t      |          |                        |                     |   604800000000|                       |                
 7|            4|column1         |integer                 |f      |         4|_timescaledb_internal   |get_partition_hash   |               |                       |                
 8|            4|column2         |timestamp with time zone|t      |          |                        |                     |   604800000000|                       |                
 9|            4|column3         |integer                 |f      |         4|_timescaledb_internal   |get_partition_for_key|               |                       |                
(9 rows)


NOTICE:  [data_node_2]: 
SELECT * FROM _timescaledb_catalog.dimension
NOTICE:  [data_node_2]:
id|hypertable_id|column_name     |column_type             |aligned|num_slices|partitioning_func_schema|partitioning_func    |interval_length|integer_now_func_schema|integer_now_func
--+-------------+----------------+------------------------+-------+----------+------------------------+---------------------+---------------+-----------------------+----------------
 1|            1|time            |timestamp with time zone|t      |          |                        |                     |   604800000000|                       |                
 2|            1|device          |integer                 |f      |         3|_timescaledb_internal   |get_partition_hash   |               |                       |                
 3|            2|time            |timestamp with time zone|t      |          |                        |                     |   604800000000|                       |                
 4|            3|time Col %#^#@$#|timestamp with time zone|t      |          |                        |                     |   604800000000|                       |                
 5|            3|__region        |text                    |f      |         4|_timescaledb_internal   |get_partition_hash   |               |                       |                
 6|            4|time            |timestamp with time zone|t      |          |                        |                     |   604800000000|                       |                
 7|            4|column1         |integer                 |f      |         4|_timescaledb_internal   |get_partition_hash   |               |                       |                
 8|            4|column2         |timestamp with time zone|t      |          |                        |                     |   604800000000|                       |                
 9|            4|column3         |integer                 |f      |         4|_timescaledb_internal   |get_partition_for_key|               |                       |                
(9 rows)


NOTICE:  [data_node_3]: 
SELECT * FROM _timescaledb_catalog.dimension
NOTICE:  [data_node_3]:
id|hypertable_id|column_name     |column_type             |aligned|num_slices|partitioning_func_schema|partitioning_func |interval_length|integer_now_func_schema|integer_now_func
--+-------------+----------------+------------------------+-------+----------+------------------------+------------------+---------------+-----------------------+----------------
 1|            1|time            |timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 2|            1|device          |integer                 |f      |         3|_timescaledb_internal   |get_partition_hash|               |                       |                
 3|            2|time            |timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 4|            3|time Col %#^#@$#|timestamp with time zone|t      |          |                        |                  |   604800000000|                       |                
 5|            3|__region        |text                    |f      |         4|_timescaledb_internal   |get_partition_hash|               |                       |                
(5 rows)


 remote_exec 
-------------
 
(1 row)

--test per-data node queries
-- Create some chunks through insertion
CREATE TABLE disttable_replicated(time timestamptz PRIMARY KEY, device int CHECK (device > 0), temp float, "Color" int);
SELECT * FROM create_hypertable('disttable_replicated', 'time', replication_factor => 2);
 hypertable_id | schema_name |      table_name      | created 
---------------+-------------+----------------------+---------
             6 | public      | disttable_replicated | t
(1 row)

INSERT INTO disttable_replicated VALUES
       ('2017-01-01 06:01', 1, 1.1, 1),
       ('2017-01-01 08:01', 1, 1.2, 2),
       ('2018-01-02 08:01', 2, 1.3, 3),
       ('2019-01-01 09:11', 3, 2.1, 4),
       ('2020-01-01 06:01', 5, 1.1, 10),
       ('2020-01-01 08:01', 6, 1.2, 11),
       ('2021-01-02 08:01', 7, 1.3, 12),
       ('2022-01-01 09:11', 8, 2.1, 13);
SELECT * FROM disttable_replicated;
             time             | device | temp | Color 
------------------------------+--------+------+-------
 Sun Jan 01 06:01:00 2017 PST |      1 |  1.1 |     1
 Sun Jan 01 08:01:00 2017 PST |      1 |  1.2 |     2
 Wed Jan 01 06:01:00 2020 PST |      5 |  1.1 |    10
 Wed Jan 01 08:01:00 2020 PST |      6 |  1.2 |    11
 Tue Jan 02 08:01:00 2018 PST |      2 |  1.3 |     3
 Sat Jan 02 08:01:00 2021 PST |      7 |  1.3 |    12
 Tue Jan 01 09:11:00 2019 PST |      3 |  2.1 |     4
 Sat Jan 01 09:11:00 2022 PST |      8 |  2.1 |    13
(8 rows)

EXPLAIN (VERBOSE, ANALYZE, COSTS FALSE, TIMING FALSE, SUMMARY FALSE)
SELECT * FROM disttable_replicated;
                                                                                    QUERY PLAN                                                                                     
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend) (actual rows=8 loops=1)
   Output: disttable_replicated."time", disttable_replicated.device, disttable_replicated.temp, disttable_replicated."Color"
   ->  Append (actual rows=8 loops=1)
         ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_1 (actual rows=4 loops=1)
               Output: disttable_replicated_1."time", disttable_replicated_1.device, disttable_replicated_1.temp, disttable_replicated_1."Color"
               Data node: data_node_1
               Chunks: _dist_hyper_6_12_chunk, _dist_hyper_6_15_chunk
               Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8])
         ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_2 (actual rows=2 loops=1)
               Output: disttable_replicated_2."time", disttable_replicated_2.device, disttable_replicated_2.temp, disttable_replicated_2."Color"
               Data node: data_node_2
               Chunks: _dist_hyper_6_13_chunk, _dist_hyper_6_16_chunk
               Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8])
         ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_3 (actual rows=2 loops=1)
               Output: disttable_replicated_3."time", disttable_replicated_3.device, disttable_replicated_3.temp, disttable_replicated_3."Color"
               Data node: data_node_3
               Chunks: _dist_hyper_6_14_chunk, _dist_hyper_6_17_chunk
               Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8])
(18 rows)

--guc disables the optimization
SET timescaledb.enable_per_data_node_queries = FALSE;
EXPLAIN (VERBOSE, ANALYZE, COSTS FALSE, TIMING FALSE, SUMMARY FALSE)
SELECT * FROM disttable_replicated;
                                                                QUERY PLAN                                                                 
-------------------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=8 loops=1)
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_12_chunk (actual rows=2 loops=1)
         Output: _dist_hyper_6_12_chunk."time", _dist_hyper_6_12_chunk.device, _dist_hyper_6_12_chunk.temp, _dist_hyper_6_12_chunk."Color"
         Data node: data_node_1
         Remote SQL: SELECT "time", device, temp, "Color" FROM _timescaledb_internal._dist_hyper_6_12_chunk
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_13_chunk (actual rows=1 loops=1)
         Output: _dist_hyper_6_13_chunk."time", _dist_hyper_6_13_chunk.device, _dist_hyper_6_13_chunk.temp, _dist_hyper_6_13_chunk."Color"
         Data node: data_node_2
         Remote SQL: SELECT "time", device, temp, "Color" FROM _timescaledb_internal._dist_hyper_6_13_chunk
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_14_chunk (actual rows=1 loops=1)
         Output: _dist_hyper_6_14_chunk."time", _dist_hyper_6_14_chunk.device, _dist_hyper_6_14_chunk.temp, _dist_hyper_6_14_chunk."Color"
         Data node: data_node_3
         Remote SQL: SELECT "time", device, temp, "Color" FROM _timescaledb_internal._dist_hyper_6_14_chunk
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_15_chunk (actual rows=2 loops=1)
         Output: _dist_hyper_6_15_chunk."time", _dist_hyper_6_15_chunk.device, _dist_hyper_6_15_chunk.temp, _dist_hyper_6_15_chunk."Color"
         Data node: data_node_1
         Remote SQL: SELECT "time", device, temp, "Color" FROM _timescaledb_internal._dist_hyper_6_15_chunk
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_16_chunk (actual rows=1 loops=1)
         Output: _dist_hyper_6_16_chunk."time", _dist_hyper_6_16_chunk.device, _dist_hyper_6_16_chunk.temp, _dist_hyper_6_16_chunk."Color"
         Data node: data_node_2
         Remote SQL: SELECT "time", device, temp, "Color" FROM _timescaledb_internal._dist_hyper_6_16_chunk
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_17_chunk (actual rows=1 loops=1)
         Output: _dist_hyper_6_17_chunk."time", _dist_hyper_6_17_chunk.device, _dist_hyper_6_17_chunk.temp, _dist_hyper_6_17_chunk."Color"
         Data node: data_node_3
         Remote SQL: SELECT "time", device, temp, "Color" FROM _timescaledb_internal._dist_hyper_6_17_chunk
(25 rows)

SET timescaledb.enable_per_data_node_queries = TRUE;
--test WHERE clause
EXPLAIN (VERBOSE, ANALYZE, COSTS FALSE, TIMING FALSE, SUMMARY FALSE)
SELECT * FROM disttable_replicated WHERE temp > 2.0;
                                                                                                      QUERY PLAN                                                                                                      
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend) (actual rows=2 loops=1)
   Output: disttable_replicated."time", disttable_replicated.device, disttable_replicated.temp, disttable_replicated."Color"
   ->  Append (actual rows=2 loops=1)
         ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_1 (actual rows=0 loops=1)
               Output: disttable_replicated_1."time", disttable_replicated_1.device, disttable_replicated_1.temp, disttable_replicated_1."Color"
               Data node: data_node_1
               Chunks: _dist_hyper_6_12_chunk, _dist_hyper_6_15_chunk
               Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8]) AND ((temp > 2::double precision))
         ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_2 (actual rows=0 loops=1)
               Output: disttable_replicated_2."time", disttable_replicated_2.device, disttable_replicated_2.temp, disttable_replicated_2."Color"
               Data node: data_node_2
               Chunks: _dist_hyper_6_13_chunk, _dist_hyper_6_16_chunk
               Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8]) AND ((temp > 2::double precision))
         ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_3 (actual rows=2 loops=1)
               Output: disttable_replicated_3."time", disttable_replicated_3.device, disttable_replicated_3.temp, disttable_replicated_3."Color"
               Data node: data_node_3
               Chunks: _dist_hyper_6_14_chunk, _dist_hyper_6_17_chunk
               Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8]) AND ((temp > 2::double precision))
(18 rows)

--test OR
EXPLAIN (VERBOSE, ANALYZE, COSTS FALSE, TIMING FALSE, SUMMARY FALSE)
SELECT * FROM disttable_replicated WHERE temp > 2.0 or "Color" = 11;
                                                                                                                QUERY PLAN                                                                                                                
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend) (actual rows=3 loops=1)
   Output: disttable_replicated."time", disttable_replicated.device, disttable_replicated.temp, disttable_replicated."Color"
   ->  Append (actual rows=3 loops=1)
         ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_1 (actual rows=1 loops=1)
               Output: disttable_replicated_1."time", disttable_replicated_1.device, disttable_replicated_1.temp, disttable_replicated_1."Color"
               Data node: data_node_1
               Chunks: _dist_hyper_6_12_chunk, _dist_hyper_6_15_chunk
               Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8]) AND (((temp > 2::double precision) OR ("Color" = 11)))
         ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_2 (actual rows=0 loops=1)
               Output: disttable_replicated_2."time", disttable_replicated_2.device, disttable_replicated_2.temp, disttable_replicated_2."Color"
               Data node: data_node_2
               Chunks: _dist_hyper_6_13_chunk, _dist_hyper_6_16_chunk
               Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8]) AND (((temp > 2::double precision) OR ("Color" = 11)))
         ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_3 (actual rows=2 loops=1)
               Output: disttable_replicated_3."time", disttable_replicated_3.device, disttable_replicated_3.temp, disttable_replicated_3."Color"
               Data node: data_node_3
               Chunks: _dist_hyper_6_14_chunk, _dist_hyper_6_17_chunk
               Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8]) AND (((temp > 2::double precision) OR ("Color" = 11)))
(18 rows)

--test some chunks excluded
EXPLAIN (VERBOSE, ANALYZE, COSTS FALSE,  TIMING FALSE, SUMMARY FALSE)
SELECT * FROM disttable_replicated WHERE time < '2018-01-01 09:11';
                                                                                                                     QUERY PLAN                                                                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend) (actual rows=2 loops=1)
   Output: disttable_replicated."time", disttable_replicated.device, disttable_replicated.temp, disttable_replicated."Color"
   ->  Append (actual rows=2 loops=1)
         ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_1 (actual rows=2 loops=1)
               Output: disttable_replicated_1."time", disttable_replicated_1.device, disttable_replicated_1.temp, disttable_replicated_1."Color"
               Data node: data_node_1
               Chunks: _dist_hyper_6_12_chunk
               Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6]) AND (("time" < '2018-01-01 09:11:00-08'::timestamp with time zone))
         ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_2 (actual rows=0 loops=1)
               Output: disttable_replicated_2."time", disttable_replicated_2.device, disttable_replicated_2.temp, disttable_replicated_2."Color"
               Data node: data_node_2
               Chunks: _dist_hyper_6_13_chunk
               Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6]) AND (("time" < '2018-01-01 09:11:00-08'::timestamp with time zone))
(13 rows)

--test all chunks excluded
EXPLAIN (VERBOSE, ANALYZE, COSTS FALSE,  TIMING FALSE, SUMMARY FALSE)
SELECT * FROM disttable_replicated WHERE time < '2002-01-01 09:11';
                                                         QUERY PLAN                                                          
-----------------------------------------------------------------------------------------------------------------------------
 Result (actual rows=0 loops=1)
   Output: disttable_replicated."time", disttable_replicated.device, disttable_replicated.temp, disttable_replicated."Color"
   One-Time Filter: false
(3 rows)

--test cte
EXPLAIN (VERBOSE, ANALYZE, COSTS FALSE,  TIMING FALSE, SUMMARY FALSE)
WITH cte AS (
    SELECT * FROM disttable_replicated
)
SELECT * FROM cte;
                                                                                        QUERY PLAN                                                                                         
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 CTE Scan on cte (actual rows=8 loops=1)
   Output: cte."time", cte.device, cte.temp, cte."Color"
   CTE cte
     ->  Custom Scan (AsyncAppend) (actual rows=8 loops=1)
           Output: disttable_replicated."time", disttable_replicated.device, disttable_replicated.temp, disttable_replicated."Color"
           ->  Append (actual rows=8 loops=1)
                 ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_1 (actual rows=4 loops=1)
                       Output: disttable_replicated_1."time", disttable_replicated_1.device, disttable_replicated_1.temp, disttable_replicated_1."Color"
                       Data node: data_node_1
                       Chunks: _dist_hyper_6_12_chunk, _dist_hyper_6_15_chunk
                       Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8])
                 ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_2 (actual rows=2 loops=1)
                       Output: disttable_replicated_2."time", disttable_replicated_2.device, disttable_replicated_2.temp, disttable_replicated_2."Color"
                       Data node: data_node_2
                       Chunks: _dist_hyper_6_13_chunk, _dist_hyper_6_16_chunk
                       Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8])
                 ->  Custom Scan (DataNodeScan) on public.disttable_replicated disttable_replicated_3 (actual rows=2 loops=1)
                       Output: disttable_replicated_3."time", disttable_replicated_3.device, disttable_replicated_3.temp, disttable_replicated_3."Color"
                       Data node: data_node_3
                       Chunks: _dist_hyper_6_14_chunk, _dist_hyper_6_17_chunk
                       Remote SQL: SELECT "time", device, temp, "Color" FROM public.disttable_replicated WHERE _timescaledb_internal.chunks_in(public.disttable_replicated.*, ARRAY[6, 8])
(21 rows)

--queries that involve updates/inserts are not optimized
EXPLAIN (VERBOSE, ANALYZE, COSTS FALSE,  TIMING FALSE, SUMMARY FALSE)
WITH devices AS (
     SELECT DISTINCT device FROM disttable_replicated ORDER BY device
)
UPDATE disttable_replicated SET device = 2 WHERE device = (SELECT device FROM devices LIMIT 1);
                                                                     QUERY PLAN                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------
 Update on public.disttable_replicated (actual rows=0 loops=1)
   Update on public.disttable_replicated
   Foreign Update on _timescaledb_internal._dist_hyper_6_12_chunk
     Remote SQL: UPDATE _timescaledb_internal._dist_hyper_6_12_chunk SET device = $2 WHERE ctid = $1
   Foreign Update on _timescaledb_internal._dist_hyper_6_13_chunk
     Remote SQL: UPDATE _timescaledb_internal._dist_hyper_6_13_chunk SET device = $2 WHERE ctid = $1
   Foreign Update on _timescaledb_internal._dist_hyper_6_14_chunk
     Remote SQL: UPDATE _timescaledb_internal._dist_hyper_6_14_chunk SET device = $2 WHERE ctid = $1
   Foreign Update on _timescaledb_internal._dist_hyper_6_15_chunk
     Remote SQL: UPDATE _timescaledb_internal._dist_hyper_6_15_chunk SET device = $2 WHERE ctid = $1
   Foreign Update on _timescaledb_internal._dist_hyper_6_16_chunk
     Remote SQL: UPDATE _timescaledb_internal._dist_hyper_6_16_chunk SET device = $2 WHERE ctid = $1
   Foreign Update on _timescaledb_internal._dist_hyper_6_17_chunk
     Remote SQL: UPDATE _timescaledb_internal._dist_hyper_6_17_chunk SET device = $2 WHERE ctid = $1
   CTE devices
     ->  Sort (actual rows=1 loops=1)
           Output: disttable_replicated_1.device
           Sort Key: disttable_replicated_1.device
           Sort Method: quicksort 
           ->  HashAggregate (actual rows=7 loops=1)
                 Output: disttable_replicated_1.device
                 Group Key: disttable_replicated_1.device
                 ->  Append (actual rows=8 loops=1)
                       ->  Seq Scan on public.disttable_replicated disttable_replicated_1 (actual rows=0 loops=1)
                             Output: disttable_replicated_1.device
                       ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_12_chunk _dist_hyper_6_12_chunk_1 (actual rows=2 loops=1)
                             Output: _dist_hyper_6_12_chunk_1.device
                             Data node: data_node_1
                             Remote SQL: SELECT device FROM _timescaledb_internal._dist_hyper_6_12_chunk
                       ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_13_chunk _dist_hyper_6_13_chunk_1 (actual rows=1 loops=1)
                             Output: _dist_hyper_6_13_chunk_1.device
                             Data node: data_node_2
                             Remote SQL: SELECT device FROM _timescaledb_internal._dist_hyper_6_13_chunk
                       ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_14_chunk _dist_hyper_6_14_chunk_1 (actual rows=1 loops=1)
                             Output: _dist_hyper_6_14_chunk_1.device
                             Data node: data_node_3
                             Remote SQL: SELECT device FROM _timescaledb_internal._dist_hyper_6_14_chunk
                       ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_15_chunk _dist_hyper_6_15_chunk_1 (actual rows=2 loops=1)
                             Output: _dist_hyper_6_15_chunk_1.device
                             Data node: data_node_1
                             Remote SQL: SELECT device FROM _timescaledb_internal._dist_hyper_6_15_chunk
                       ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_16_chunk _dist_hyper_6_16_chunk_1 (actual rows=1 loops=1)
                             Output: _dist_hyper_6_16_chunk_1.device
                             Data node: data_node_2
                             Remote SQL: SELECT device FROM _timescaledb_internal._dist_hyper_6_16_chunk
                       ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_17_chunk _dist_hyper_6_17_chunk_1 (actual rows=1 loops=1)
                             Output: _dist_hyper_6_17_chunk_1.device
                             Data node: data_node_3
                             Remote SQL: SELECT device FROM _timescaledb_internal._dist_hyper_6_17_chunk
   InitPlan 2 (returns $1)
     ->  Limit (actual rows=1 loops=1)
           Output: devices.device
           ->  CTE Scan on devices (actual rows=1 loops=1)
                 Output: devices.device
   ->  Seq Scan on public.disttable_replicated (actual rows=0 loops=1)
         Output: disttable_replicated."time", 2, disttable_replicated.temp, disttable_replicated."Color", disttable_replicated.ctid
         Filter: (disttable_replicated.device = $1)
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_12_chunk (actual rows=2 loops=1)
         Output: _dist_hyper_6_12_chunk."time", 2, _dist_hyper_6_12_chunk.temp, _dist_hyper_6_12_chunk."Color", _dist_hyper_6_12_chunk.ctid
         Data node: data_node_1
         Remote SQL: SELECT "time", temp, "Color", ctid FROM _timescaledb_internal._dist_hyper_6_12_chunk WHERE ((device = $1::integer)) FOR UPDATE
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_13_chunk (actual rows=0 loops=1)
         Output: _dist_hyper_6_13_chunk."time", 2, _dist_hyper_6_13_chunk.temp, _dist_hyper_6_13_chunk."Color", _dist_hyper_6_13_chunk.ctid
         Data node: data_node_2
         Remote SQL: SELECT "time", temp, "Color", ctid FROM _timescaledb_internal._dist_hyper_6_13_chunk WHERE ((device = $1::integer)) FOR UPDATE
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_14_chunk (actual rows=0 loops=1)
         Output: _dist_hyper_6_14_chunk."time", 2, _dist_hyper_6_14_chunk.temp, _dist_hyper_6_14_chunk."Color", _dist_hyper_6_14_chunk.ctid
         Data node: data_node_3
         Remote SQL: SELECT "time", temp, "Color", ctid FROM _timescaledb_internal._dist_hyper_6_14_chunk WHERE ((device = $1::integer)) FOR UPDATE
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_15_chunk (actual rows=0 loops=1)
         Output: _dist_hyper_6_15_chunk."time", 2, _dist_hyper_6_15_chunk.temp, _dist_hyper_6_15_chunk."Color", _dist_hyper_6_15_chunk.ctid
         Data node: data_node_1
         Remote SQL: SELECT "time", temp, "Color", ctid FROM _timescaledb_internal._dist_hyper_6_15_chunk WHERE ((device = $1::integer)) FOR UPDATE
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_16_chunk (actual rows=0 loops=1)
         Output: _dist_hyper_6_16_chunk."time", 2, _dist_hyper_6_16_chunk.temp, _dist_hyper_6_16_chunk."Color", _dist_hyper_6_16_chunk.ctid
         Data node: data_node_2
         Remote SQL: SELECT "time", temp, "Color", ctid FROM _timescaledb_internal._dist_hyper_6_16_chunk WHERE ((device = $1::integer)) FOR UPDATE
   ->  Foreign Scan on _timescaledb_internal._dist_hyper_6_17_chunk (actual rows=0 loops=1)
         Output: _dist_hyper_6_17_chunk."time", 2, _dist_hyper_6_17_chunk.temp, _dist_hyper_6_17_chunk."Color", _dist_hyper_6_17_chunk.ctid
         Data node: data_node_3
         Remote SQL: SELECT "time", temp, "Color", ctid FROM _timescaledb_internal._dist_hyper_6_17_chunk WHERE ((device = $1::integer)) FOR UPDATE
(81 rows)

-- Test inserts with smaller batch size and more tuples to reach full
-- batch
SET timescaledb.max_insert_batch_size=4;
CREATE TABLE twodim (time timestamptz DEFAULT '2019-02-10 10:11', "Color" int DEFAULT 11 CHECK ("Color" > 0), temp float DEFAULT 22.1);
-- Create a replicated table to ensure we handle that case correctly
-- with batching
SELECT * FROM create_hypertable('twodim', 'time', 'Color', 3, replication_factor => 2, data_nodes => '{ "data_node_1", "data_node_2", "data_node_3" }');
NOTICE:  adding not-null constraint to column "time"
 hypertable_id | schema_name | table_name | created 
---------------+-------------+------------+---------
             7 | public      | twodim     | t
(1 row)

SELECT * FROM twodim
ORDER BY time;
 time | Color | temp 
------+-------+------
(0 rows)

-- INSERT enough data to stretch across multiple batches per
-- data node. Also return a system column. Although we write tuples to
-- multiple data nodes, the returned tuple should only be the ones in the
-- original insert statement (without the replica tuples).
WITH result AS (
     INSERT INTO twodim VALUES
       ('2017-02-01 06:01', 1, 1.1),
       ('2017-02-01 08:01', 1, 1.2),
       ('2018-02-02 08:01', 2, 1.3),
       ('2019-02-01 09:11', 3, 2.1),
       ('2019-02-02 09:11', 3, 2.1),
       ('2019-02-02 10:01', 5, 1.2),
       ('2019-02-03 11:11', 6, 3.5),
       ('2019-02-04 08:21', 4, 6.6),
       ('2019-02-04 10:11', 7, 7.4),
       ('2019-02-04 12:11', 8, 2.1),
       ('2019-02-05 13:31', 8, 6.3),
       ('2019-02-06 02:11', 5, 1.8),
       ('2019-02-06 01:13', 7, 7.9),
       ('2019-02-06 19:24', 9, 5.9),
       ('2019-02-07 18:44', 5, 9.7),
       ('2019-02-07 20:24', 6, NULL),
       ('2019-02-07 09:33', 7, 9.5),
       ('2019-02-08 08:54', 1, 7.3),
       ('2019-02-08 18:14', 4, 8.2),
       ('2019-02-09 19:23', 8, 9.1)
     RETURNING tableoid = 'twodim'::regclass AS is_tableoid, time, temp, "Color"
) SELECT * FROM result ORDER BY time;
 is_tableoid |             time             | temp | Color 
-------------+------------------------------+------+-------
 t           | Wed Feb 01 06:01:00 2017 PST |  1.1 |     1
 t           | Wed Feb 01 08:01:00 2017 PST |  1.2 |     1
 t           | Fri Feb 02 08:01:00 2018 PST |  1.3 |     2
 t           | Fri Feb 01 09:11:00 2019 PST |  2.1 |     3
 t           | Sat Feb 02 09:11:00 2019 PST |  2.1 |     3
 t           | Sat Feb 02 10:01:00 2019 PST |  1.2 |     5
 t           | Sun Feb 03 11:11:00 2019 PST |  3.5 |     6
 t           | Mon Feb 04 08:21:00 2019 PST |  6.6 |     4
 t           | Mon Feb 04 10:11:00 2019 PST |  7.4 |     7
 t           | Mon Feb 04 12:11:00 2019 PST |  2.1 |     8
 t           | Tue Feb 05 13:31:00 2019 PST |  6.3 |     8
 t           | Wed Feb 06 01:13:00 2019 PST |  7.9 |     7
 t           | Wed Feb 06 02:11:00 2019 PST |  1.8 |     5
 t           | Wed Feb 06 19:24:00 2019 PST |  5.9 |     9
 t           | Thu Feb 07 09:33:00 2019 PST |  9.5 |     7
 t           | Thu Feb 07 18:44:00 2019 PST |  9.7 |     5
 t           | Thu Feb 07 20:24:00 2019 PST |      |     6
 t           | Fri Feb 08 08:54:00 2019 PST |  7.3 |     1
 t           | Fri Feb 08 18:14:00 2019 PST |  8.2 |     4
 t           | Sat Feb 09 19:23:00 2019 PST |  9.1 |     8
(20 rows)

-- Test insert with default values and a batch size of 1.
SET timescaledb.max_insert_batch_size=1;
EXPLAIN (VERBOSE, COSTS OFF, TIMING OFF, SUMMARY OFF)
INSERT INTO twodim DEFAULT VALUES;
                                                        QUERY PLAN                                                        
--------------------------------------------------------------------------------------------------------------------------
 Custom Scan (HypertableInsert)
 Insert on distributed hypertable public.twodim
   Data nodes: data_node_1, data_node_2, data_node_3
   ->  Insert on public.twodim
         ->  Custom Scan (DataNodeDispatch)
               Output: 'Sun Feb 10 10:11:00 2019 PST'::timestamp with time zone, 11, '22.1'::double precision
               Batch size: 1
               Remote SQL: INSERT INTO public.twodim("time", "Color", temp) VALUES ($1, $2, $3)
               ->  Custom Scan (ChunkDispatch)
                     Output: 'Sun Feb 10 10:11:00 2019 PST'::timestamp with time zone, 11, '22.1'::double precision
                     ->  Result
                           Output: 'Sun Feb 10 10:11:00 2019 PST'::timestamp with time zone, 11, '22.1'::double precision
(12 rows)

INSERT INTO twodim DEFAULT VALUES;
-- Reset the batch size
SET timescaledb.max_insert_batch_size=4;
-- Constraint violation error check
--
-- Execute and filter mentioned data node name in the error message.
\set ON_ERROR_STOP 0
SELECT test.execute_sql_and_filter_data_node_name_on_error($$ INSERT INTO twodim VALUES ('2019-02-10 17:54', 0, 10.2) $$);
ERROR:  [data_node_x]: new row for relation "_dist_hyper_7_23_chunk" violates check constraint "twodim_Color_check"
\set ON_ERROR_STOP 1
-- Disable batching, reverting to FDW tuple-by-tuple inserts.
-- First EXPLAIN with batching turned on.
EXPLAIN (VERBOSE, COSTS OFF, TIMING OFF, SUMMARY OFF)
INSERT INTO twodim VALUES
       ('2019-02-10 16:23', 5, 7.1),
       ('2019-02-10 17:11', 7, 3.2);
                                                      QUERY PLAN                                                      
----------------------------------------------------------------------------------------------------------------------
 Custom Scan (HypertableInsert)
 Insert on distributed hypertable public.twodim
   Data nodes: data_node_1, data_node_2, data_node_3
   ->  Insert on public.twodim
         ->  Custom Scan (DataNodeDispatch)
               Output: "*VALUES*".column1, "*VALUES*".column2, "*VALUES*".column3
               Batch size: 4
               Remote SQL: INSERT INTO public.twodim("time", "Color", temp) VALUES ($1, $2, $3), ..., ($10, $11, $12)
               ->  Custom Scan (ChunkDispatch)
                     Output: "*VALUES*".column1, "*VALUES*".column2, "*VALUES*".column3
                     ->  Values Scan on "*VALUES*"
                           Output: "*VALUES*".column1, "*VALUES*".column2, "*VALUES*".column3
(12 rows)

SET timescaledb.max_insert_batch_size=0;
-- Compare without batching
EXPLAIN (VERBOSE, COSTS OFF, TIMING OFF, SUMMARY OFF)
INSERT INTO twodim VALUES
       ('2019-02-10 16:23', 5, 7.1),
       ('2019-02-10 17:11', 7, 3.2);
                                       QUERY PLAN                                       
----------------------------------------------------------------------------------------
 Custom Scan (HypertableInsert)
 Insert on distributed hypertable public.twodim
   Data nodes: data_node_1, data_node_2, data_node_3
   Remote SQL: INSERT INTO public.twodim("time", "Color", temp) VALUES ($1, $2, $3)
   ->  Insert on public.twodim
         ->  Custom Scan (ChunkDispatch)
               Output: "*VALUES*".column1, "*VALUES*".column2, "*VALUES*".column3
               ->  Values Scan on "*VALUES*"
                     Output: "*VALUES*".column1, "*VALUES*".column2, "*VALUES*".column3
(9 rows)

-- Insert without batching
INSERT INTO twodim VALUES
       ('2019-02-10 16:23', 5, 7.1),
       ('2019-02-10 17:11', 7, 3.2);
-- Check results
SELECT * FROM twodim
ORDER BY time;
             time             | Color | temp 
------------------------------+-------+------
 Wed Feb 01 06:01:00 2017 PST |     1 |  1.1
 Wed Feb 01 08:01:00 2017 PST |     1 |  1.2
 Fri Feb 02 08:01:00 2018 PST |     2 |  1.3
 Fri Feb 01 09:11:00 2019 PST |     3 |  2.1
 Sat Feb 02 09:11:00 2019 PST |     3 |  2.1
 Sat Feb 02 10:01:00 2019 PST |     5 |  1.2
 Sun Feb 03 11:11:00 2019 PST |     6 |  3.5
 Mon Feb 04 08:21:00 2019 PST |     4 |  6.6
 Mon Feb 04 10:11:00 2019 PST |     7 |  7.4
 Mon Feb 04 12:11:00 2019 PST |     8 |  2.1
 Tue Feb 05 13:31:00 2019 PST |     8 |  6.3
 Wed Feb 06 01:13:00 2019 PST |     7 |  7.9
 Wed Feb 06 02:11:00 2019 PST |     5 |  1.8
 Wed Feb 06 19:24:00 2019 PST |     9 |  5.9
 Thu Feb 07 09:33:00 2019 PST |     7 |  9.5
 Thu Feb 07 18:44:00 2019 PST |     5 |  9.7
 Thu Feb 07 20:24:00 2019 PST |     6 |     
 Fri Feb 08 08:54:00 2019 PST |     1 |  7.3
 Fri Feb 08 18:14:00 2019 PST |     4 |  8.2
 Sat Feb 09 19:23:00 2019 PST |     8 |  9.1
 Sun Feb 10 10:11:00 2019 PST |    11 | 22.1
 Sun Feb 10 16:23:00 2019 PST |     5 |  7.1
 Sun Feb 10 17:11:00 2019 PST |     7 |  3.2
(23 rows)

SELECT count(*) FROM twodim;
 count 
-------
    23
(1 row)

-- Show distribution across data nodes
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT * FROM twodim
ORDER BY time;
SELECT count(*) FROM twodim;
$$);
NOTICE:  [data_node_1]: 
SELECT * FROM twodim
ORDER BY time
NOTICE:  [data_node_1]:
time                        |Color|temp
----------------------------+-----+----
Wed Feb 01 06:01:00 2017 PST|    1| 1.1
Wed Feb 01 08:01:00 2017 PST|    1| 1.2
Fri Feb 01 09:11:00 2019 PST|    3| 2.1
Sat Feb 02 09:11:00 2019 PST|    3| 2.1
Sun Feb 03 11:11:00 2019 PST|    6| 3.5
Mon Feb 04 12:11:00 2019 PST|    8| 2.1
Tue Feb 05 13:31:00 2019 PST|    8| 6.3
Wed Feb 06 19:24:00 2019 PST|    9| 5.9
Thu Feb 07 20:24:00 2019 PST|    6|    
Fri Feb 08 08:54:00 2019 PST|    1| 7.3
Sat Feb 09 19:23:00 2019 PST|    8| 9.1
Sun Feb 10 10:11:00 2019 PST|   11|22.1
(12 rows)


NOTICE:  [data_node_1]: 
SELECT count(*) FROM twodim
NOTICE:  [data_node_1]:
count
-----
   12
(1 row)


NOTICE:  [data_node_2]: 
SELECT * FROM twodim
ORDER BY time
NOTICE:  [data_node_2]:
time                        |Color|temp
----------------------------+-----+----
Wed Feb 01 06:01:00 2017 PST|    1| 1.1
Wed Feb 01 08:01:00 2017 PST|    1| 1.2
Fri Feb 02 08:01:00 2018 PST|    2| 1.3
Sat Feb 02 10:01:00 2019 PST|    5| 1.2
Sun Feb 03 11:11:00 2019 PST|    6| 3.5
Mon Feb 04 08:21:00 2019 PST|    4| 6.6
Mon Feb 04 10:11:00 2019 PST|    7| 7.4
Mon Feb 04 12:11:00 2019 PST|    8| 2.1
Tue Feb 05 13:31:00 2019 PST|    8| 6.3
Wed Feb 06 01:13:00 2019 PST|    7| 7.9
Wed Feb 06 02:11:00 2019 PST|    5| 1.8
Thu Feb 07 09:33:00 2019 PST|    7| 9.5
Thu Feb 07 18:44:00 2019 PST|    5| 9.7
Thu Feb 07 20:24:00 2019 PST|    6|    
Fri Feb 08 08:54:00 2019 PST|    1| 7.3
Fri Feb 08 18:14:00 2019 PST|    4| 8.2
Sat Feb 09 19:23:00 2019 PST|    8| 9.1
Sun Feb 10 16:23:00 2019 PST|    5| 7.1
Sun Feb 10 17:11:00 2019 PST|    7| 3.2
(19 rows)


NOTICE:  [data_node_2]: 
SELECT count(*) FROM twodim
NOTICE:  [data_node_2]:
count
-----
   19
(1 row)


NOTICE:  [data_node_3]: 
SELECT * FROM twodim
ORDER BY time
NOTICE:  [data_node_3]:
time                        |Color|temp
----------------------------+-----+----
Fri Feb 02 08:01:00 2018 PST|    2| 1.3
Fri Feb 01 09:11:00 2019 PST|    3| 2.1
Sat Feb 02 09:11:00 2019 PST|    3| 2.1
Sat Feb 02 10:01:00 2019 PST|    5| 1.2
Mon Feb 04 08:21:00 2019 PST|    4| 6.6
Mon Feb 04 10:11:00 2019 PST|    7| 7.4
Wed Feb 06 01:13:00 2019 PST|    7| 7.9
Wed Feb 06 02:11:00 2019 PST|    5| 1.8
Wed Feb 06 19:24:00 2019 PST|    9| 5.9
Thu Feb 07 09:33:00 2019 PST|    7| 9.5
Thu Feb 07 18:44:00 2019 PST|    5| 9.7
Fri Feb 08 18:14:00 2019 PST|    4| 8.2
Sun Feb 10 10:11:00 2019 PST|   11|22.1
Sun Feb 10 16:23:00 2019 PST|    5| 7.1
Sun Feb 10 17:11:00 2019 PST|    7| 3.2
(15 rows)


NOTICE:  [data_node_3]: 
SELECT count(*) FROM twodim
NOTICE:  [data_node_3]:
count
-----
   15
(1 row)


 remote_exec 
-------------
 
(1 row)

-- Distributed table with custom type that has no binary output
CREATE TABLE disttable_with_ct(time timestamptz, txn_id rxid, val float, info text);
SELECT * FROM create_hypertable('disttable_with_ct', 'time', replication_factor => 2);
NOTICE:  adding not-null constraint to column "time"
 hypertable_id | schema_name |    table_name     | created 
---------------+-------------+-------------------+---------
             8 | public      | disttable_with_ct | t
(1 row)

-- Insert data with custom type
INSERT INTO disttable_with_ct VALUES
    ('2019-01-01 01:01', 'ts-1-10-20-30', 1.1, 'a'),
    ('2019-01-01 01:02', 'ts-1-11-20-30', 2.0, repeat('abc', 1000000)); -- TOAST
-- Test queries on distributed table with custom type
SELECT time, txn_id, val, substring(info for 20) FROM disttable_with_ct;
             time             |    txn_id     | val |      substring       
------------------------------+---------------+-----+----------------------
 Tue Jan 01 01:01:00 2019 PST | ts-1-10-20-30 | 1.1 | a
 Tue Jan 01 01:02:00 2019 PST | ts-1-11-20-30 |   2 | abcabcabcabcabcabcab
(2 rows)

SET timescaledb.enable_connection_binary_data=false;
SELECT time, txn_id, val, substring(info for 20) FROM disttable_with_ct;
             time             |    txn_id     | val |      substring       
------------------------------+---------------+-----+----------------------
 Tue Jan 01 01:01:00 2019 PST | ts-1-10-20-30 | 1.1 | a
 Tue Jan 01 01:02:00 2019 PST | ts-1-11-20-30 |   2 | abcabcabcabcabcabcab
(2 rows)

-- Test DELETE with replication
DELETE FROM disttable_with_ct WHERE info = 'a';
-- Check if row is gone
SELECT time, txn_id, val, substring(info for 20) FROM disttable_with_ct;
             time             |    txn_id     | val |      substring       
------------------------------+---------------+-----+----------------------
 Tue Jan 01 01:02:00 2019 PST | ts-1-11-20-30 |   2 | abcabcabcabcabcabcab
(1 row)

-- Connect to data nodes to see if data is gone
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT time, txn_id, val, substring(info for 20) FROM disttable_with_ct;
$$);
NOTICE:  [data_node_1]: 
SELECT time, txn_id, val, substring(info for 20) FROM disttable_with_ct
NOTICE:  [data_node_1]:
time                        |txn_id       |val|substring           
----------------------------+-------------+---+--------------------
Tue Jan 01 01:02:00 2019 PST|ts-1-11-20-30|  2|abcabcabcabcabcabcab
(1 row)


NOTICE:  [data_node_2]: 
SELECT time, txn_id, val, substring(info for 20) FROM disttable_with_ct
NOTICE:  [data_node_2]:
time                        |txn_id       |val|substring           
----------------------------+-------------+---+--------------------
Tue Jan 01 01:02:00 2019 PST|ts-1-11-20-30|  2|abcabcabcabcabcabcab
(1 row)


NOTICE:  [data_node_3]: 
SELECT time, txn_id, val, substring(info for 20) FROM disttable_with_ct
NOTICE:  [data_node_3]:
time|txn_id|val|substring
----+------+---+---------
(0 rows)


 remote_exec 
-------------
 
(1 row)

-- Test single quote in names
SET SCHEMA 'single''schema';
CREATE TABLE "disttable'quote"(time timestamptz, "device'quote" int, val float, info text);
SELECT public.create_distributed_hypertable(
    'disttable''quote', 'time', 'device''quote', data_nodes => '{ "data_node_1" }'
);
WARNING:  only one data node was assigned to the hypertable
NOTICE:  adding not-null constraint to column "time"
    create_distributed_hypertable    
-------------------------------------
 (9,single'schema,disttable'quote,t)
(1 row)

SET SCHEMA 'public';
CREATE TABLE disttable_drop_chunks(time timestamptz, device int CHECK (device > 0), color int, PRIMARY KEY (time,device));
SELECT * FROM create_distributed_hypertable('disttable_drop_chunks', 'time', 'device', number_partitions => 3, replication_factor => 2);
 hypertable_id | schema_name |      table_name       | created 
---------------+-------------+-----------------------+---------
            10 | public      | disttable_drop_chunks | t
(1 row)

INSERT INTO disttable_drop_chunks VALUES
       ('2017-01-01 06:01', 1, 1.1),
       ('2017-01-01 09:11', 3, 2.1),
       ('2017-01-01 08:01', 1, 1.2),
       ('2017-01-02 08:01', 2, 1.3),
       ('2018-07-02 08:01', 87, 1.6),
       ('2018-07-01 06:01', 13, 1.4),
       ('2018-07-01 09:11', 90, 2.7),
       ('2018-07-01 08:01', 29, 1.5);
-- Show chunks on access node
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable_drop_chunks');
 chunk_id | hypertable_id |      schema_name      |       table_name        | relkind |                                           slices                                            
----------+---------------+-----------------------+-------------------------+---------+---------------------------------------------------------------------------------------------
       27 |            10 | _timescaledb_internal | _dist_hyper_10_27_chunk | f       | {"time": [1482969600000000, 1483574400000000], "device": [-9223372036854775808, 715827882]}
       28 |            10 | _timescaledb_internal | _dist_hyper_10_28_chunk | f       | {"time": [1482969600000000, 1483574400000000], "device": [1431655764, 9223372036854775807]}
       29 |            10 | _timescaledb_internal | _dist_hyper_10_29_chunk | f       | {"time": [1482969600000000, 1483574400000000], "device": [715827882, 1431655764]}
       30 |            10 | _timescaledb_internal | _dist_hyper_10_30_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [-9223372036854775808, 715827882]}
       31 |            10 | _timescaledb_internal | _dist_hyper_10_31_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [715827882, 1431655764]}
       32 |            10 | _timescaledb_internal | _dist_hyper_10_32_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [1431655764, 9223372036854775807]}
(6 rows)

-- Show chunks on data nodes
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable_drop_chunks');
$$);
NOTICE:  [data_node_1]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable_drop_chunks')
NOTICE:  [data_node_1]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      16|            9|_timescaledb_internal|_dist_hyper_10_27_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [-9223372036854775808, 715827882]}
      17|            9|_timescaledb_internal|_dist_hyper_10_28_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [1431655764, 9223372036854775807]}
      18|            9|_timescaledb_internal|_dist_hyper_10_30_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [-9223372036854775808, 715827882]}
      19|            9|_timescaledb_internal|_dist_hyper_10_32_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [1431655764, 9223372036854775807]}
(4 rows)


NOTICE:  [data_node_2]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable_drop_chunks')
NOTICE:  [data_node_2]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      16|            8|_timescaledb_internal|_dist_hyper_10_27_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [-9223372036854775808, 715827882]}
      17|            8|_timescaledb_internal|_dist_hyper_10_29_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [715827882, 1431655764]}          
      18|            8|_timescaledb_internal|_dist_hyper_10_30_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [-9223372036854775808, 715827882]}
      19|            8|_timescaledb_internal|_dist_hyper_10_31_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [715827882, 1431655764]}          
(4 rows)


NOTICE:  [data_node_3]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable_drop_chunks')
NOTICE:  [data_node_3]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      14|            7|_timescaledb_internal|_dist_hyper_10_28_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [1431655764, 9223372036854775807]}
      15|            7|_timescaledb_internal|_dist_hyper_10_29_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [715827882, 1431655764]}          
      16|            7|_timescaledb_internal|_dist_hyper_10_31_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [715827882, 1431655764]}          
      17|            7|_timescaledb_internal|_dist_hyper_10_32_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [1431655764, 9223372036854775807]}
(4 rows)


 remote_exec 
-------------
 
(1 row)

SELECT * FROM drop_chunks('disttable_drop_chunks', older_than => '2018-01-01'::timestamptz);
                  drop_chunks                  
-----------------------------------------------
 _timescaledb_internal._dist_hyper_10_27_chunk
 _timescaledb_internal._dist_hyper_10_28_chunk
 _timescaledb_internal._dist_hyper_10_29_chunk
(3 rows)

SELECT * FROM disttable_drop_chunks;
             time             | device | color 
------------------------------+--------+-------
 Mon Jul 02 08:01:00 2018 PDT |     87 |     2
 Sun Jul 01 06:01:00 2018 PDT |     13 |     1
 Sun Jul 01 09:11:00 2018 PDT |     90 |     3
 Sun Jul 01 08:01:00 2018 PDT |     29 |     2
(4 rows)

SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable_drop_chunks');
 chunk_id | hypertable_id |      schema_name      |       table_name        | relkind |                                           slices                                            
----------+---------------+-----------------------+-------------------------+---------+---------------------------------------------------------------------------------------------
       30 |            10 | _timescaledb_internal | _dist_hyper_10_30_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [-9223372036854775808, 715827882]}
       31 |            10 | _timescaledb_internal | _dist_hyper_10_31_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [715827882, 1431655764]}
       32 |            10 | _timescaledb_internal | _dist_hyper_10_32_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [1431655764, 9223372036854775807]}
(3 rows)

SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable_drop_chunks');
$$);
NOTICE:  [data_node_1]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable_drop_chunks')
NOTICE:  [data_node_1]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      18|            9|_timescaledb_internal|_dist_hyper_10_30_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [-9223372036854775808, 715827882]}
      19|            9|_timescaledb_internal|_dist_hyper_10_32_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [1431655764, 9223372036854775807]}
(2 rows)


NOTICE:  [data_node_2]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable_drop_chunks')
NOTICE:  [data_node_2]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      18|            8|_timescaledb_internal|_dist_hyper_10_30_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [-9223372036854775808, 715827882]}
      19|            8|_timescaledb_internal|_dist_hyper_10_31_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [715827882, 1431655764]}          
(2 rows)


NOTICE:  [data_node_3]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable_drop_chunks')
NOTICE:  [data_node_3]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      16|            7|_timescaledb_internal|_dist_hyper_10_31_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [715827882, 1431655764]}          
      17|            7|_timescaledb_internal|_dist_hyper_10_32_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [1431655764, 9223372036854775807]}
(2 rows)


 remote_exec 
-------------
 
(1 row)

-- test passing newer_than as interval
SELECT * FROM drop_chunks('disttable_drop_chunks', newer_than => interval '10 years');
                  drop_chunks                  
-----------------------------------------------
 _timescaledb_internal._dist_hyper_10_30_chunk
 _timescaledb_internal._dist_hyper_10_31_chunk
 _timescaledb_internal._dist_hyper_10_32_chunk
(3 rows)

SELECT * FROM disttable_drop_chunks;
 time | device | color 
------+--------+-------
(0 rows)

CREATE TABLE "weird nAme\\#^."(time bigint, device int CHECK (device > 0), color int, PRIMARY KEY (time,device));
SELECT * FROM create_distributed_hypertable('"weird nAme\\#^."', 'time', 'device', 3, chunk_time_interval => 100, replication_factor => 2);
 hypertable_id | schema_name |   table_name    | created 
---------------+-------------+-----------------+---------
            11 | public      | weird nAme\\#^. | t
(1 row)

INSERT INTO "weird nAme\\#^." VALUES
       (300, 1, 1.1),
       (400, 3, 2.1),
       (350, 1, 1.2);
SELECT * FROM "weird nAme\\#^.";
 time | device | color 
------+--------+-------
  300 |      1 |     1
  350 |      1 |     1
  400 |      3 |     2
(3 rows)

-- drop chunks using bigint as time
SELECT * FROM drop_chunks('"weird nAme\\#^."', older_than => 1000);
                  drop_chunks                  
-----------------------------------------------
 _timescaledb_internal._dist_hyper_11_33_chunk
 _timescaledb_internal._dist_hyper_11_34_chunk
(2 rows)

SELECT * FROM "weird nAme\\#^.";
 time | device | color 
------+--------+-------
(0 rows)

-----------------------------------------------------------------------------------------
-- Test that settings on hypertables are distributed to data nodes
-----------------------------------------------------------------------------------------
DROP TABLE disttable CASCADE;
CREATE TABLE disttable (time bigint, device int, temp float);
SELECT create_distributed_hypertable('disttable', 'time', chunk_time_interval => 1000000::bigint);
NOTICE:  adding not-null constraint to column "time"
 create_distributed_hypertable 
-------------------------------
 (12,public,disttable,t)
(1 row)

-- Show the dimension configuration on data nodes
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable';
$$);
NOTICE:  [data_node_1]: 
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable'
NOTICE:  [data_node_1]:
id|hypertable_id|column_name|column_type|aligned|num_slices|partitioning_func_schema|partitioning_func|interval_length|integer_now_func_schema|integer_now_func
--+-------------+-----------+-----------+-------+----------+------------------------+-----------------+---------------+-----------------------+----------------
20|           11|time       |bigint     |t      |          |                        |                 |        1000000|                       |                
(1 row)


NOTICE:  [data_node_2]: 
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable'
NOTICE:  [data_node_2]:
id|hypertable_id|column_name|column_type|aligned|num_slices|partitioning_func_schema|partitioning_func|interval_length|integer_now_func_schema|integer_now_func
--+-------------+-----------+-----------+-------+----------+------------------------+-----------------+---------------+-----------------------+----------------
18|           10|time       |bigint     |t      |          |                        |                 |        1000000|                       |                
(1 row)


NOTICE:  [data_node_3]: 
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable'
NOTICE:  [data_node_3]:
id|hypertable_id|column_name|column_type|aligned|num_slices|partitioning_func_schema|partitioning_func|interval_length|integer_now_func_schema|integer_now_func
--+-------------+-----------+-----------+-------+----------+------------------------+-----------------+---------------+-----------------------+----------------
14|            9|time       |bigint     |t      |          |                        |                 |        1000000|                       |                
(1 row)


 remote_exec 
-------------
 
(1 row)

-- Test adding a space dimension. Should apply to data nodes as
-- well. We're setting num_partitions lower than the number of servers
-- and expect a warning.
SELECT * FROM add_dimension('disttable', 'device', 1, partitioning_func => '_timescaledb_internal.get_partition_hash');
WARNING:  the number of partitions in dimension "device" is too low to make use of all attached data nodes
 dimension_id | schema_name | table_name | column_name | created 
--------------+-------------+------------+-------------+---------
           22 | public      | disttable  | device      | t
(1 row)

CREATE INDEX disttable_device_time_idx ON disttable (device, time);
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable';
$$);
NOTICE:  [data_node_1]: 
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable'
NOTICE:  [data_node_1]:
id|hypertable_id|column_name|column_type|aligned|num_slices|partitioning_func_schema|partitioning_func |interval_length|integer_now_func_schema|integer_now_func
--+-------------+-----------+-----------+-------+----------+------------------------+------------------+---------------+-----------------------+----------------
21|           11|device     |integer    |f      |         1|_timescaledb_internal   |get_partition_hash|               |                       |                
20|           11|time       |bigint     |t      |          |                        |                  |        1000000|                       |                
(2 rows)


NOTICE:  [data_node_2]: 
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable'
NOTICE:  [data_node_2]:
id|hypertable_id|column_name|column_type|aligned|num_slices|partitioning_func_schema|partitioning_func |interval_length|integer_now_func_schema|integer_now_func
--+-------------+-----------+-----------+-------+----------+------------------------+------------------+---------------+-----------------------+----------------
19|           10|device     |integer    |f      |         1|_timescaledb_internal   |get_partition_hash|               |                       |                
18|           10|time       |bigint     |t      |          |                        |                  |        1000000|                       |                
(2 rows)


NOTICE:  [data_node_3]: 
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable'
NOTICE:  [data_node_3]:
id|hypertable_id|column_name|column_type|aligned|num_slices|partitioning_func_schema|partitioning_func |interval_length|integer_now_func_schema|integer_now_func
--+-------------+-----------+-----------+-------+----------+------------------------+------------------+---------------+-----------------------+----------------
15|            9|device     |integer    |f      |         1|_timescaledb_internal   |get_partition_hash|               |                       |                
14|            9|time       |bigint     |t      |          |                        |                  |        1000000|                       |                
(2 rows)


 remote_exec 
-------------
 
(1 row)

-- Show that changing dimension settings apply to data nodes
SELECT * FROM set_chunk_time_interval('disttable', 2000000000::bigint);
 set_chunk_time_interval 
-------------------------
 
(1 row)

SELECT * FROM set_number_partitions('disttable', 3);
 set_number_partitions 
-----------------------
 
(1 row)

CREATE OR REPLACE FUNCTION dummy_now() RETURNS BIGINT LANGUAGE SQL IMMUTABLE as  'SELECT 2::BIGINT';
SELECT * FROM distributed_exec($$
CREATE OR REPLACE FUNCTION dummy_now() RETURNS BIGINT LANGUAGE SQL IMMUTABLE as  'SELECT 2::BIGINT'
$$);
 distributed_exec 
------------------
 
(1 row)

SELECT * FROM set_integer_now_func('disttable', 'dummy_now');
 set_integer_now_func 
----------------------
 
(1 row)

-- Show changes to dimensions
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable';
$$);
NOTICE:  [data_node_1]: 
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable'
NOTICE:  [data_node_1]:
id|hypertable_id|column_name|column_type|aligned|num_slices|partitioning_func_schema|partitioning_func |interval_length|integer_now_func_schema|integer_now_func
--+-------------+-----------+-----------+-------+----------+------------------------+------------------+---------------+-----------------------+----------------
21|           11|device     |integer    |f      |         3|_timescaledb_internal   |get_partition_hash|               |                       |                
20|           11|time       |bigint     |t      |          |                        |                  |     2000000000|public                 |dummy_now       
(2 rows)


NOTICE:  [data_node_2]: 
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable'
NOTICE:  [data_node_2]:
id|hypertable_id|column_name|column_type|aligned|num_slices|partitioning_func_schema|partitioning_func |interval_length|integer_now_func_schema|integer_now_func
--+-------------+-----------+-----------+-------+----------+------------------------+------------------+---------------+-----------------------+----------------
19|           10|device     |integer    |f      |         3|_timescaledb_internal   |get_partition_hash|               |                       |                
18|           10|time       |bigint     |t      |          |                        |                  |     2000000000|public                 |dummy_now       
(2 rows)


NOTICE:  [data_node_3]: 
SELECT d.* FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id AND h.table_name = 'disttable'
NOTICE:  [data_node_3]:
id|hypertable_id|column_name|column_type|aligned|num_slices|partitioning_func_schema|partitioning_func |interval_length|integer_now_func_schema|integer_now_func
--+-------------+-----------+-----------+-------+----------+------------------------+------------------+---------------+-----------------------+----------------
15|            9|device     |integer    |f      |         3|_timescaledb_internal   |get_partition_hash|               |                       |                
14|            9|time       |bigint     |t      |          |                        |                  |     2000000000|public                 |dummy_now       
(2 rows)


 remote_exec 
-------------
 
(1 row)

-- Tests for using tablespaces with distributed hypertables
\c :TEST_DBNAME :ROLE_CLUSTER_SUPERUSER;
CREATE TABLESPACE tablespace1 OWNER :ROLE_1 LOCATION :TEST_TABLESPACE1_PATH;
CREATE TABLESPACE tablespace2 OWNER :ROLE_1 LOCATION :TEST_TABLESPACE2_PATH;
\set ON_ERROR_STOP 0
SELECT attach_tablespace('tablespace1', 'disttable');
ERROR:  cannot attach tablespace to distributed hypertable
SELECT detach_tablespace('tablespace1', 'disttable');
ERROR:  tablespace "tablespace1" is not attached to hypertable "disttable"
\set ON_ERROR_STOP 1
SELECT detach_tablespaces('disttable');
 detach_tablespaces 
--------------------
                  0
(1 row)

-- Continue to use previously attached tablespace, but block attach/detach
CREATE TABLE disttable2(time timestamptz, device int, temp float) TABLESPACE tablespace1;
SELECT create_distributed_hypertable('disttable2', 'time', chunk_time_interval => 1000000::bigint);
NOTICE:  adding not-null constraint to column "time"
 create_distributed_hypertable 
-------------------------------
 (13,public,disttable2,t)
(1 row)

-- Ensure that table is created on the data nodes without a tablespace
SELECT * FROM distributed_exec($$
SELECT * FROM show_tablespaces('disttable2');
$$);
 distributed_exec 
------------------
 
(1 row)

INSERT INTO disttable2 VALUES ('2017-01-01 06:01', 1, 1.1);
SELECT * FROM show_chunks('disttable2');
                  show_chunks                  
-----------------------------------------------
 _timescaledb_internal._dist_hyper_13_35_chunk
(1 row)

-- Ensure tablespace oid is set to 0 for a foreign table
SELECT reltablespace
FROM pg_class cl, (SELECT show_chunks AS chunk FROM show_chunks('disttable2')) ch
WHERE cl.oid = ch.chunk::regclass;
 reltablespace 
---------------
             0
(1 row)

\set ON_ERROR_STOP 0
SELECT attach_tablespace('tablespace2', 'disttable2');
ERROR:  cannot attach tablespace to distributed hypertable
SELECT detach_tablespace('tablespace2', 'disttable2');
ERROR:  tablespace "tablespace2" is not attached to hypertable "disttable2"
\set ON_ERROR_STOP 1
SELECT detach_tablespaces('disttable2');
 detach_tablespaces 
--------------------
                  0
(1 row)

SELECT * FROM show_tablespaces('disttable2');
 show_tablespaces 
------------------
(0 rows)

-- Ensure tablespace API works for data nodes
SELECT * FROM distributed_exec($$
SELECT attach_tablespace('tablespace2', 'disttable2');
$$);
 distributed_exec 
------------------
 
(1 row)

SELECT * FROM distributed_exec($$
SELECT detach_tablespace('tablespace2', 'disttable2');
$$);
 distributed_exec 
------------------
 
(1 row)

SELECT * FROM distributed_exec($$
SELECT attach_tablespace('tablespace2', 'disttable2');
$$);
 distributed_exec 
------------------
 
(1 row)

SELECT * FROM distributed_exec($$
SELECT detach_tablespaces('disttable2');
$$);
 distributed_exec 
------------------
 
(1 row)

DROP TABLE disttable2;
CREATE TABLE disttable2(time timestamptz, device int, temp float) TABLESPACE tablespace1;
SELECT create_hypertable('disttable2', 'time', chunk_time_interval => 1000000::bigint, replication_factor => 1);
NOTICE:  adding not-null constraint to column "time"
    create_hypertable     
--------------------------
 (14,public,disttable2,t)
(1 row)

-- Ensure that table is created on the data nodes without a tablespace
SELECT * FROM distributed_exec($$
SELECT * FROM show_tablespaces('disttable2');
$$);
 distributed_exec 
------------------
 
(1 row)

INSERT INTO disttable2 VALUES ('2017-01-01 06:01', 1, 1.1);
SELECT * FROM show_chunks('disttable2');
                  show_chunks                  
-----------------------------------------------
 _timescaledb_internal._dist_hyper_14_36_chunk
(1 row)

-- Ensure tablespace oid is set to 0 for a foreign table
SELECT reltablespace
FROM pg_class cl, (SELECT show_chunks AS chunk FROM show_chunks('disttable2')) ch
WHERE cl.oid = ch.chunk::regclass;
 reltablespace 
---------------
             0
(1 row)

\set ON_ERROR_STOP 0
SELECT attach_tablespace('tablespace2', 'disttable2');
ERROR:  cannot attach tablespace to distributed hypertable
SELECT detach_tablespace('tablespace2', 'disttable2');
ERROR:  tablespace "tablespace2" is not attached to hypertable "disttable2"
\set ON_ERROR_STOP 1
SELECT * FROM show_tablespaces('disttable2');
 show_tablespaces 
------------------
(0 rows)

DROP TABLE disttable2;
DROP TABLESPACE tablespace1;
DROP TABLESPACE tablespace2;
-- Make sure table qualified name is used in chunks_in function. Otherwise having a table name same as a column name might yield an error
CREATE TABLE dist_device(time timestamptz, dist_device int, temp float);
SELECT * FROM create_distributed_hypertable('dist_device', 'time');
NOTICE:  adding not-null constraint to column "time"
 hypertable_id | schema_name | table_name  | created 
---------------+-------------+-------------+---------
            15 | public      | dist_device | t
(1 row)

INSERT INTO dist_device VALUES
       ('2017-01-01 06:01', 1, 1.1),
       ('2017-01-01 09:11', 3, 2.1),
       ('2017-01-01 08:01', 1, 1.2);
EXPLAIN (VERBOSE, COSTS OFF)
SELECT * FROM dist_device;
                                                                     QUERY PLAN                                                                      
-----------------------------------------------------------------------------------------------------------------------------------------------------
 Append
   ->  Custom Scan (DataNodeScan) on public.dist_device
         Output: dist_device."time", dist_device.dist_device, dist_device.temp
         Data node: data_node_1
         Chunks: _dist_hyper_15_37_chunk
         Remote SQL: SELECT "time", dist_device, temp FROM public.dist_device WHERE _timescaledb_internal.chunks_in(public.dist_device.*, ARRAY[24])
(6 rows)

SELECT * FROM dist_device;
             time             | dist_device | temp 
------------------------------+-------------+------
 Sun Jan 01 06:01:00 2017 PST |           1 |  1.1
 Sun Jan 01 09:11:00 2017 PST |           3 |  2.1
 Sun Jan 01 08:01:00 2017 PST |           1 |  1.2
(3 rows)

-- Test estimating relation size without stats
CREATE TABLE hyper_estimate(time timestamptz, device int, temp float);
SELECT * FROM create_distributed_hypertable('hyper_estimate', 'time', 'device', number_partitions => 3, replication_factor => 1, chunk_time_interval => INTERVAL '7 days');
NOTICE:  adding not-null constraint to column "time"
 hypertable_id | schema_name |   table_name   | created 
---------------+-------------+----------------+---------
            16 | public      | hyper_estimate | t
(1 row)

-- This will enable us to more easily see estimates per chunk
SET timescaledb.enable_per_data_node_queries = false;
-- Estimating chunk progress uses current timestamp so we override it for test purposes
SELECT test.tsl_override_current_timestamptz('2019-11-11 00:00'::timestamptz);
 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

-- Test estimates when backfilling. 3 chunks should be historical and 3 should be considered current when estimating.
-- Note that estimate numbers are way off since we are using shared buffer size as starting point. This will not be
-- an issue in 'production' like env since chunk size should be similar to shared buffer size.
INSERT INTO hyper_estimate VALUES
       ('2017-01-01 06:01', 1, 1.1),
       ('2017-01-01 09:11', 1, 2.1),
       ('2017-01-01 08:01', 1, 1.2),
       ('2017-01-02 08:01', 1, 1.3),
       ('2017-01-02 08:01', 2, 1.6),
       ('2017-01-02 06:01', 2, 1.4),
       ('2017-01-03 01:01', 3, 2),
       ('2017-01-03 01:16', 3, 3),
       ('2017-01-03 01:17', 3, 4),
       ('2018-01-13 01:01', 1, 2),
       ('2018-01-13 01:10', 1, 0.4),
       ('2018-01-13 02:10', 2, 1.4),
       ('2018-01-13 05:01', 2, 2),
       ('2018-01-13 05:50', 2, 4),
       ('2018-01-13 16:01', 3, 2);
-- Since there are no stats we use shared buffers size to estimate number of rows
EXPLAIN (COSTS ON)
SELECT *
FROM hyper_estimate;
                                         QUERY PLAN                                          
---------------------------------------------------------------------------------------------
 Append  (cost=100.00..166847.40 rows=4118040 width=20)
   ->  Foreign Scan on _dist_hyper_16_38_chunk  (cost=100.00..32468.60 rows=915120 width=20)
   ->  Foreign Scan on _dist_hyper_16_39_chunk  (cost=100.00..32468.60 rows=915120 width=20)
   ->  Foreign Scan on _dist_hyper_16_40_chunk  (cost=100.00..32468.60 rows=915120 width=20)
   ->  Foreign Scan on _dist_hyper_16_41_chunk  (cost=100.00..16283.80 rows=457560 width=20)
   ->  Foreign Scan on _dist_hyper_16_42_chunk  (cost=100.00..16283.80 rows=457560 width=20)
   ->  Foreign Scan on _dist_hyper_16_43_chunk  (cost=100.00..16283.80 rows=457560 width=20)
(7 rows)

-- This will calculate the stats
ANALYZE hyper_estimate;
EXPLAIN (COSTS ON)
SELECT *
FROM hyper_estimate;
                                      QUERY PLAN                                      
--------------------------------------------------------------------------------------
 Append  (cost=100.00..606.52 rows=15 width=20)
   ->  Foreign Scan on _dist_hyper_16_38_chunk  (cost=100.00..101.12 rows=4 width=20)
   ->  Foreign Scan on _dist_hyper_16_39_chunk  (cost=100.00..101.06 rows=2 width=20)
   ->  Foreign Scan on _dist_hyper_16_40_chunk  (cost=100.00..101.09 rows=3 width=20)
   ->  Foreign Scan on _dist_hyper_16_41_chunk  (cost=100.00..101.06 rows=2 width=20)
   ->  Foreign Scan on _dist_hyper_16_42_chunk  (cost=100.00..101.09 rows=3 width=20)
   ->  Foreign Scan on _dist_hyper_16_43_chunk  (cost=100.00..101.03 rows=1 width=20)
(7 rows)

-- Let's insert data into a new chunk. This will result in chunk creation.
INSERT INTO hyper_estimate VALUES ('2019-11-11 06:01', 1, 1.1);
-- We have stats for previous chunks so we can interpolate number of rows for the new chunk
EXPLAIN (COSTS ON)
SELECT *
FROM hyper_estimate;
                                      QUERY PLAN                                      
--------------------------------------------------------------------------------------
 Append  (cost=100.00..706.58 rows=17 width=20)
   ->  Foreign Scan on _dist_hyper_16_38_chunk  (cost=100.00..101.12 rows=4 width=20)
   ->  Foreign Scan on _dist_hyper_16_39_chunk  (cost=100.00..101.06 rows=2 width=20)
   ->  Foreign Scan on _dist_hyper_16_40_chunk  (cost=100.00..101.09 rows=3 width=20)
   ->  Foreign Scan on _dist_hyper_16_41_chunk  (cost=100.00..101.06 rows=2 width=20)
   ->  Foreign Scan on _dist_hyper_16_42_chunk  (cost=100.00..101.09 rows=3 width=20)
   ->  Foreign Scan on _dist_hyper_16_43_chunk  (cost=100.00..101.03 rows=1 width=20)
   ->  Foreign Scan on _dist_hyper_16_44_chunk  (cost=100.00..100.05 rows=2 width=20)
(8 rows)

CREATE TABLE devices (
       device_id INTEGER PRIMARY KEY,
       device_name VARCHAR(10)
);
SELECT * FROM distributed_exec($$
  CREATE TABLE devices(device_id INTEGER PRIMARY KEY, device_name VARCHAR(10))
$$);
 distributed_exec 
------------------
 
(1 row)

INSERT INTO devices VALUES
  (1, 'A001'), (2, 'B015'), (3, 'D821'), (4, 'C561'), (5, 'D765');
SELECT * FROM distributed_exec($$
  INSERT INTO devices VALUES
    (1, 'A001'), (2, 'B015'), (3, 'D821'), (4, 'C561'), (5, 'D765')
$$);
 distributed_exec 
------------------
 
(1 row)

CREATE TABLE hyper (
  time TIMESTAMPTZ NOT NULL,
  device INTEGER REFERENCES devices(device_id),
  temp FLOAT
);
SELECT * FROM create_distributed_hypertable('hyper', 'time', 'device', 3,
       chunk_time_interval => interval '18 hours'
);
WARNING:  FOREIGN KEY from distributed hypertable "hyper" requires referenced table to be consistent across all data nodes.
 hypertable_id | schema_name | table_name | created 
---------------+-------------+------------+---------
            17 | public      | hyper      | t
(1 row)

-- Inserting some values should succeed.
INSERT INTO hyper VALUES
       ('2017-01-01 06:01', 1, 1.1),
       ('2017-01-01 09:11', 1, 2.1),
       ('2017-01-01 08:01', 1, 1.2),
       ('2017-01-02 08:01', 1, 1.3),
       ('2017-01-02 08:01', 2, 1.6),
       ('2017-01-02 06:01', 2, 1.4),
       ('2017-01-03 01:01', 3, 2),
       ('2017-01-03 01:16', 3, 3),
       ('2017-01-03 01:17', 3, 4),
       ('2018-01-13 01:01', 1, 2),
       ('2018-01-13 01:10', 1, 0.4),
       ('2018-01-13 02:10', 2, 1.4),
       ('2018-01-13 05:01', 2, 2),
       ('2018-01-13 05:50', 2, 4),
       ('2018-01-13 16:01', 3, 2);
SELECT time_bucket('3 hours', time) AS time, device, avg(temp) AS avg_temp
FROM hyper
GROUP BY 1, 2
HAVING avg(temp) > 1.2
ORDER BY 1;
             time             | device | avg_temp 
------------------------------+--------+----------
 Sun Jan 01 07:00:00 2017 PST |      1 |     1.65
 Mon Jan 02 04:00:00 2017 PST |      2 |      1.4
 Mon Jan 02 07:00:00 2017 PST |      1 |      1.3
 Mon Jan 02 07:00:00 2017 PST |      2 |      1.6
 Tue Jan 03 01:00:00 2017 PST |      3 |        3
 Sat Jan 13 01:00:00 2018 PST |      2 |      1.4
 Sat Jan 13 04:00:00 2018 PST |      2 |        3
 Sat Jan 13 16:00:00 2018 PST |      3 |        2
(8 rows)

-- Add some devices on the access node only. Inserts should then fail.
INSERT INTO devices VALUES (6, 'E999');
\set ON_ERROR_STOP 0
INSERT INTO hyper VALUES ('2017-01-01 06:01', 6, 1.1);
ERROR:  [data_node_1]: insert or update on table "_dist_hyper_17_45_chunk" violates foreign key constraint "28_17_hyper_device_fkey"
\set ON_ERROR_STOP 1
-- Test alter replication factor with data
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper');
$$);
NOTICE:  [data_node_1]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_1]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      28|           16|_timescaledb_internal|_dist_hyper_17_45_chunk|r      |{"time": [1483272000000000, 1483336800000000], "device": [-9223372036854775808, 715827882]}
      29|           16|_timescaledb_internal|_dist_hyper_17_46_chunk|r      |{"time": [1483336800000000, 1483401600000000], "device": [-9223372036854775808, 715827882]}
      30|           16|_timescaledb_internal|_dist_hyper_17_49_chunk|r      |{"time": [1515801600000000, 1515866400000000], "device": [-9223372036854775808, 715827882]}
(3 rows)


NOTICE:  [data_node_2]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_2]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                           
--------+-------------+---------------------+-----------------------+-------+---------------------------------------------------------------------------------
      23|           15|_timescaledb_internal|_dist_hyper_17_47_chunk|r      |{"time": [1483336800000000, 1483401600000000], "device": [715827882, 1431655764]}
      24|           15|_timescaledb_internal|_dist_hyper_17_50_chunk|r      |{"time": [1515801600000000, 1515866400000000], "device": [715827882, 1431655764]}
(2 rows)


NOTICE:  [data_node_3]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_3]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      21|           14|_timescaledb_internal|_dist_hyper_17_48_chunk|r      |{"time": [1483401600000000, 1483466400000000], "device": [1431655764, 9223372036854775807]}
      22|           14|_timescaledb_internal|_dist_hyper_17_51_chunk|r      |{"time": [1515866400000000, 1515931200000000], "device": [1431655764, 9223372036854775807]}
(2 rows)


 remote_exec 
-------------
 
(1 row)

SELECT * FROM set_replication_factor('hyper', 3);
WARNING:  hypertable "hyper" is under-replicated
 set_replication_factor 
------------------------
 
(1 row)

INSERT INTO hyper VALUES ('2017-01-02 07:11', 1, 1.7);
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper');
$$);
NOTICE:  [data_node_1]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_1]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      28|           16|_timescaledb_internal|_dist_hyper_17_45_chunk|r      |{"time": [1483272000000000, 1483336800000000], "device": [-9223372036854775808, 715827882]}
      29|           16|_timescaledb_internal|_dist_hyper_17_46_chunk|r      |{"time": [1483336800000000, 1483401600000000], "device": [-9223372036854775808, 715827882]}
      30|           16|_timescaledb_internal|_dist_hyper_17_49_chunk|r      |{"time": [1515801600000000, 1515866400000000], "device": [-9223372036854775808, 715827882]}
(3 rows)


NOTICE:  [data_node_2]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_2]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                           
--------+-------------+---------------------+-----------------------+-------+---------------------------------------------------------------------------------
      23|           15|_timescaledb_internal|_dist_hyper_17_47_chunk|r      |{"time": [1483336800000000, 1483401600000000], "device": [715827882, 1431655764]}
      24|           15|_timescaledb_internal|_dist_hyper_17_50_chunk|r      |{"time": [1515801600000000, 1515866400000000], "device": [715827882, 1431655764]}
(2 rows)


NOTICE:  [data_node_3]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_3]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      21|           14|_timescaledb_internal|_dist_hyper_17_48_chunk|r      |{"time": [1483401600000000, 1483466400000000], "device": [1431655764, 9223372036854775807]}
      22|           14|_timescaledb_internal|_dist_hyper_17_51_chunk|r      |{"time": [1515866400000000, 1515931200000000], "device": [1431655764, 9223372036854775807]}
(2 rows)


 remote_exec 
-------------
 
(1 row)

INSERT INTO hyper VALUES ('2017-02-01 06:01', 1, 5.1);
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper');
$$);
NOTICE:  [data_node_1]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_1]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      28|           16|_timescaledb_internal|_dist_hyper_17_45_chunk|r      |{"time": [1483272000000000, 1483336800000000], "device": [-9223372036854775808, 715827882]}
      29|           16|_timescaledb_internal|_dist_hyper_17_46_chunk|r      |{"time": [1483336800000000, 1483401600000000], "device": [-9223372036854775808, 715827882]}
      30|           16|_timescaledb_internal|_dist_hyper_17_49_chunk|r      |{"time": [1515801600000000, 1515866400000000], "device": [-9223372036854775808, 715827882]}
      31|           16|_timescaledb_internal|_dist_hyper_17_52_chunk|r      |{"time": [1485928800000000, 1485993600000000], "device": [-9223372036854775808, 715827882]}
(4 rows)


NOTICE:  [data_node_2]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_2]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      23|           15|_timescaledb_internal|_dist_hyper_17_47_chunk|r      |{"time": [1483336800000000, 1483401600000000], "device": [715827882, 1431655764]}          
      24|           15|_timescaledb_internal|_dist_hyper_17_50_chunk|r      |{"time": [1515801600000000, 1515866400000000], "device": [715827882, 1431655764]}          
      25|           15|_timescaledb_internal|_dist_hyper_17_52_chunk|r      |{"time": [1485928800000000, 1485993600000000], "device": [-9223372036854775808, 715827882]}
(3 rows)


NOTICE:  [data_node_3]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_3]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      21|           14|_timescaledb_internal|_dist_hyper_17_48_chunk|r      |{"time": [1483401600000000, 1483466400000000], "device": [1431655764, 9223372036854775807]}
      22|           14|_timescaledb_internal|_dist_hyper_17_51_chunk|r      |{"time": [1515866400000000, 1515931200000000], "device": [1431655764, 9223372036854775807]}
      23|           14|_timescaledb_internal|_dist_hyper_17_52_chunk|r      |{"time": [1485928800000000, 1485993600000000], "device": [-9223372036854775808, 715827882]}
(3 rows)


 remote_exec 
-------------
 
(1 row)

SELECT * FROM set_replication_factor('hyper', 2);
WARNING:  hypertable "hyper" is under-replicated
 set_replication_factor 
------------------------
 
(1 row)

INSERT INTO hyper VALUES ('2017-03-01 06:01', 1, 15.1);
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper');
$$);
NOTICE:  [data_node_1]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_1]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      28|           16|_timescaledb_internal|_dist_hyper_17_45_chunk|r      |{"time": [1483272000000000, 1483336800000000], "device": [-9223372036854775808, 715827882]}
      29|           16|_timescaledb_internal|_dist_hyper_17_46_chunk|r      |{"time": [1483336800000000, 1483401600000000], "device": [-9223372036854775808, 715827882]}
      30|           16|_timescaledb_internal|_dist_hyper_17_49_chunk|r      |{"time": [1515801600000000, 1515866400000000], "device": [-9223372036854775808, 715827882]}
      31|           16|_timescaledb_internal|_dist_hyper_17_52_chunk|r      |{"time": [1485928800000000, 1485993600000000], "device": [-9223372036854775808, 715827882]}
      32|           16|_timescaledb_internal|_dist_hyper_17_53_chunk|r      |{"time": [1488326400000000, 1488391200000000], "device": [-9223372036854775808, 715827882]}
(5 rows)


NOTICE:  [data_node_2]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_2]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      23|           15|_timescaledb_internal|_dist_hyper_17_47_chunk|r      |{"time": [1483336800000000, 1483401600000000], "device": [715827882, 1431655764]}          
      24|           15|_timescaledb_internal|_dist_hyper_17_50_chunk|r      |{"time": [1515801600000000, 1515866400000000], "device": [715827882, 1431655764]}          
      25|           15|_timescaledb_internal|_dist_hyper_17_52_chunk|r      |{"time": [1485928800000000, 1485993600000000], "device": [-9223372036854775808, 715827882]}
      26|           15|_timescaledb_internal|_dist_hyper_17_53_chunk|r      |{"time": [1488326400000000, 1488391200000000], "device": [-9223372036854775808, 715827882]}
(4 rows)


NOTICE:  [data_node_3]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_3]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      21|           14|_timescaledb_internal|_dist_hyper_17_48_chunk|r      |{"time": [1483401600000000, 1483466400000000], "device": [1431655764, 9223372036854775807]}
      22|           14|_timescaledb_internal|_dist_hyper_17_51_chunk|r      |{"time": [1515866400000000, 1515931200000000], "device": [1431655764, 9223372036854775807]}
      23|           14|_timescaledb_internal|_dist_hyper_17_52_chunk|r      |{"time": [1485928800000000, 1485993600000000], "device": [-9223372036854775808, 715827882]}
(3 rows)


 remote_exec 
-------------
 
(1 row)

SELECT * FROM set_replication_factor('hyper', replication_factor => 2);
WARNING:  hypertable "hyper" is under-replicated
 set_replication_factor 
------------------------
 
(1 row)

INSERT INTO hyper VALUES ('2017-04-01 06:01', 2, 45.1);
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper');
$$);
NOTICE:  [data_node_1]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_1]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      28|           16|_timescaledb_internal|_dist_hyper_17_45_chunk|r      |{"time": [1483272000000000, 1483336800000000], "device": [-9223372036854775808, 715827882]}
      29|           16|_timescaledb_internal|_dist_hyper_17_46_chunk|r      |{"time": [1483336800000000, 1483401600000000], "device": [-9223372036854775808, 715827882]}
      30|           16|_timescaledb_internal|_dist_hyper_17_49_chunk|r      |{"time": [1515801600000000, 1515866400000000], "device": [-9223372036854775808, 715827882]}
      31|           16|_timescaledb_internal|_dist_hyper_17_52_chunk|r      |{"time": [1485928800000000, 1485993600000000], "device": [-9223372036854775808, 715827882]}
      32|           16|_timescaledb_internal|_dist_hyper_17_53_chunk|r      |{"time": [1488326400000000, 1488391200000000], "device": [-9223372036854775808, 715827882]}
(5 rows)


NOTICE:  [data_node_2]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_2]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      23|           15|_timescaledb_internal|_dist_hyper_17_47_chunk|r      |{"time": [1483336800000000, 1483401600000000], "device": [715827882, 1431655764]}          
      24|           15|_timescaledb_internal|_dist_hyper_17_50_chunk|r      |{"time": [1515801600000000, 1515866400000000], "device": [715827882, 1431655764]}          
      25|           15|_timescaledb_internal|_dist_hyper_17_52_chunk|r      |{"time": [1485928800000000, 1485993600000000], "device": [-9223372036854775808, 715827882]}
      26|           15|_timescaledb_internal|_dist_hyper_17_53_chunk|r      |{"time": [1488326400000000, 1488391200000000], "device": [-9223372036854775808, 715827882]}
      27|           15|_timescaledb_internal|_dist_hyper_17_54_chunk|r      |{"time": [1491048000000000, 1491112800000000], "device": [715827882, 1431655764]}          
(5 rows)


NOTICE:  [data_node_3]: 
    SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
    FROM show_chunks('hyper')
NOTICE:  [data_node_3]:
chunk_id|hypertable_id|schema_name          |table_name             |relkind|slices                                                                                     
--------+-------------+---------------------+-----------------------+-------+-------------------------------------------------------------------------------------------
      21|           14|_timescaledb_internal|_dist_hyper_17_48_chunk|r      |{"time": [1483401600000000, 1483466400000000], "device": [1431655764, 9223372036854775807]}
      22|           14|_timescaledb_internal|_dist_hyper_17_51_chunk|r      |{"time": [1515866400000000, 1515931200000000], "device": [1431655764, 9223372036854775807]}
      23|           14|_timescaledb_internal|_dist_hyper_17_52_chunk|r      |{"time": [1485928800000000, 1485993600000000], "device": [-9223372036854775808, 715827882]}
      24|           14|_timescaledb_internal|_dist_hyper_17_54_chunk|r      |{"time": [1491048000000000, 1491112800000000], "device": [715827882, 1431655764]}          
(4 rows)


 remote_exec 
-------------
 
(1 row)

\set ON_ERROR_STOP 0
SELECT * FROM set_replication_factor('hyper', replication_factor => 4);
ERROR:  too big replication factor for hypertable "hyper"
\set ON_ERROR_STOP 1
DROP TABLE hyper;
SELECT * FROM distributed_exec($$
    DROP TABLE devices;
$$);
 distributed_exec 
------------------
 
(1 row)

DROP TABLE devices;
-- Test storage options are distributed to data nodes
--
-- Make sure that options used during CREATE TABLE WITH and CREATE INDEX WITH
-- are properly distributed.
--
CREATE TABLE disttable_with_relopts_1(time timestamptz NOT NULL, device int) WITH (fillfactor=10);
CREATE TABLE disttable_with_relopts_2(time timestamptz NOT NULL, device int) WITH (fillfactor=10, parallel_workers=1);
CREATE TABLE disttable_with_relopts_3(time timestamptz NOT NULL, device int);
CREATE INDEX disttable_with_relopts_3_idx ON disttable_with_relopts_3(device) WITH (fillfactor=20);
SELECT * FROM create_distributed_hypertable('disttable_with_relopts_1', 'time');
 hypertable_id | schema_name |        table_name        | created 
---------------+-------------+--------------------------+---------
            18 | public      | disttable_with_relopts_1 | t
(1 row)

SELECT * FROM create_distributed_hypertable('disttable_with_relopts_2', 'time');
 hypertable_id | schema_name |        table_name        | created 
---------------+-------------+--------------------------+---------
            19 | public      | disttable_with_relopts_2 | t
(1 row)

SELECT * FROM create_distributed_hypertable('disttable_with_relopts_3', 'time');
 hypertable_id | schema_name |        table_name        | created 
---------------+-------------+--------------------------+---------
            20 | public      | disttable_with_relopts_3 | t
(1 row)

INSERT INTO disttable_with_relopts_1 VALUES
       ('2017-01-01 06:01', 1),
       ('2017-01-01 09:11', 3),
       ('2017-01-01 08:01', 1),
       ('2017-01-02 08:01', 2),
       ('2018-07-02 08:01', 87);
INSERT INTO disttable_with_relopts_2 VALUES
       ('2017-01-01 06:01', 1),
       ('2017-01-01 09:11', 3),
       ('2017-01-01 08:01', 1),
       ('2017-01-02 08:01', 2),
       ('2018-07-02 08:01', 87);
SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_1' ORDER BY relname;
         relname          |   reloptions    
--------------------------+-----------------
 disttable_with_relopts_1 | {fillfactor=10}
(1 row)

SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_2' ORDER BY relname;
         relname          |             reloptions             
--------------------------+------------------------------------
 disttable_with_relopts_2 | {fillfactor=10,parallel_workers=1}
(1 row)

SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_3' ORDER BY relname;
         relname          | reloptions 
--------------------------+------------
 disttable_with_relopts_3 | 
(1 row)

SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_3_idx' ORDER BY relname;
           relname            |   reloptions    
------------------------------+-----------------
 disttable_with_relopts_3_idx | {fillfactor=20}
(1 row)

-- Ensure reloptions are not set for distributed hypertable chunks on the AN
SELECT relname, reloptions FROM pg_class WHERE relname IN
(SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
ORDER BY relname;
         relname         | reloptions 
-------------------------+------------
 _dist_hyper_18_55_chunk | 
 _dist_hyper_18_56_chunk | 
(2 rows)

SELECT relname, reloptions FROM pg_class WHERE relname IN
(SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_2'))
ORDER BY relname;
         relname         | reloptions 
-------------------------+------------
 _dist_hyper_19_57_chunk | 
 _dist_hyper_19_58_chunk | 
(2 rows)

-- Ensure parent tables has proper storage options
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_1' ORDER BY relname;
$$);
NOTICE:  [data_node_1]: 
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_1' ORDER BY relname
NOTICE:  [data_node_1]:
relname                 |reloptions     
------------------------+---------------
disttable_with_relopts_1|{fillfactor=10}
(1 row)


NOTICE:  [data_node_2]: 
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_1' ORDER BY relname
NOTICE:  [data_node_2]:
relname                 |reloptions     
------------------------+---------------
disttable_with_relopts_1|{fillfactor=10}
(1 row)


NOTICE:  [data_node_3]: 
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_1' ORDER BY relname
NOTICE:  [data_node_3]:
relname                 |reloptions     
------------------------+---------------
disttable_with_relopts_1|{fillfactor=10}
(1 row)


 remote_exec 
-------------
 
(1 row)

SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_2' ORDER BY relname;
$$);
NOTICE:  [data_node_1]: 
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_2' ORDER BY relname
NOTICE:  [data_node_1]:
relname                 |reloptions                        
------------------------+----------------------------------
disttable_with_relopts_2|{fillfactor=10,parallel_workers=1}
(1 row)


NOTICE:  [data_node_2]: 
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_2' ORDER BY relname
NOTICE:  [data_node_2]:
relname                 |reloptions                        
------------------------+----------------------------------
disttable_with_relopts_2|{fillfactor=10,parallel_workers=1}
(1 row)


NOTICE:  [data_node_3]: 
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_2' ORDER BY relname
NOTICE:  [data_node_3]:
relname                 |reloptions                        
------------------------+----------------------------------
disttable_with_relopts_2|{fillfactor=10,parallel_workers=1}
(1 row)


 remote_exec 
-------------
 
(1 row)

-- Ensure index has proper storage options set
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_3_idx' ORDER BY relname;
$$);
NOTICE:  [data_node_1]: 
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_3_idx' ORDER BY relname
NOTICE:  [data_node_1]:
relname                     |reloptions     
----------------------------+---------------
disttable_with_relopts_3_idx|{fillfactor=20}
(1 row)


NOTICE:  [data_node_2]: 
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_3_idx' ORDER BY relname
NOTICE:  [data_node_2]:
relname                     |reloptions     
----------------------------+---------------
disttable_with_relopts_3_idx|{fillfactor=20}
(1 row)


NOTICE:  [data_node_3]: 
    SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_3_idx' ORDER BY relname
NOTICE:  [data_node_3]:
relname                     |reloptions     
----------------------------+---------------
disttable_with_relopts_3_idx|{fillfactor=20}
(1 row)


 remote_exec 
-------------
 
(1 row)

-- Make sure chunks derive parent reloptions
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname;
$$);
NOTICE:  [data_node_1]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname
NOTICE:  [data_node_1]:
relname                |reloptions     
-----------------------+---------------
_dist_hyper_18_55_chunk|{fillfactor=10}
(1 row)


NOTICE:  [data_node_2]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname
NOTICE:  [data_node_2]:
relname                |reloptions     
-----------------------+---------------
_dist_hyper_18_56_chunk|{fillfactor=10}
(1 row)


NOTICE:  [data_node_3]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname
NOTICE:  [data_node_3]:
relname|reloptions
-------+----------
(0 rows)


 remote_exec 
-------------
 
(1 row)

SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_2'))
    ORDER BY relname;
$$);
NOTICE:  [data_node_1]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_2'))
    ORDER BY relname
NOTICE:  [data_node_1]:
relname                |reloptions                        
-----------------------+----------------------------------
_dist_hyper_19_57_chunk|{fillfactor=10,parallel_workers=1}
(1 row)


NOTICE:  [data_node_2]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_2'))
    ORDER BY relname
NOTICE:  [data_node_2]:
relname                |reloptions                        
-----------------------+----------------------------------
_dist_hyper_19_58_chunk|{fillfactor=10,parallel_workers=1}
(1 row)


NOTICE:  [data_node_3]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_2'))
    ORDER BY relname
NOTICE:  [data_node_3]:
relname|reloptions
-------+----------
(0 rows)


 remote_exec 
-------------
 
(1 row)

-- ALTER TABLE SET/RESET support for distributed hypertable
--
-- SET
ALTER TABLE disttable_with_relopts_1 SET (fillfactor=40);
SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_1' ORDER BY relname;
         relname          |   reloptions    
--------------------------+-----------------
 disttable_with_relopts_1 | {fillfactor=40}
(1 row)

-- Ensure chunks are not affected on the AN
SELECT relname, reloptions FROM pg_class WHERE relname IN
(SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
ORDER BY relname;
         relname         | reloptions 
-------------------------+------------
 _dist_hyper_18_55_chunk | 
 _dist_hyper_18_56_chunk | 
(2 rows)

-- Ensure data node chunks has proper options set
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname;
$$);
NOTICE:  [data_node_1]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname
NOTICE:  [data_node_1]:
relname                |reloptions     
-----------------------+---------------
_dist_hyper_18_55_chunk|{fillfactor=40}
(1 row)


NOTICE:  [data_node_2]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname
NOTICE:  [data_node_2]:
relname                |reloptions     
-----------------------+---------------
_dist_hyper_18_56_chunk|{fillfactor=40}
(1 row)


NOTICE:  [data_node_3]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname
NOTICE:  [data_node_3]:
relname|reloptions
-------+----------
(0 rows)


 remote_exec 
-------------
 
(1 row)

-- RESET
ALTER TABLE disttable_with_relopts_1 RESET (fillfactor);
SELECT relname, reloptions FROM pg_class WHERE relname = 'disttable_with_relopts_1' ORDER BY relname;
         relname          | reloptions 
--------------------------+------------
 disttable_with_relopts_1 | 
(1 row)

-- Ensure chunks are not affected on the AN
SELECT relname, reloptions FROM pg_class WHERE relname IN
(SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
ORDER BY relname;
         relname         | reloptions 
-------------------------+------------
 _dist_hyper_18_55_chunk | 
 _dist_hyper_18_56_chunk | 
(2 rows)

-- Ensure data node chunks has proper options set
SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }',$$
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname;
$$);
NOTICE:  [data_node_1]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname
NOTICE:  [data_node_1]:
relname                |reloptions
-----------------------+----------
_dist_hyper_18_55_chunk|          
(1 row)


NOTICE:  [data_node_2]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname
NOTICE:  [data_node_2]:
relname                |reloptions
-----------------------+----------
_dist_hyper_18_56_chunk|          
(1 row)


NOTICE:  [data_node_3]: 
    SELECT relname, reloptions FROM pg_class WHERE relname IN
    (SELECT (_timescaledb_internal.show_chunk(show_chunks)).table_name FROM show_chunks('disttable_with_relopts_1'))
    ORDER BY relname
NOTICE:  [data_node_3]:
relname|reloptions
-------+----------
(0 rows)


 remote_exec 
-------------
 
(1 row)

-- WITH OIDS and WITHOUT OIDS are tested in a separate test since those
-- options were dropped in PG12
DROP TABLE disttable_with_relopts_1;
DROP TABLE disttable_with_relopts_2;
DROP TABLE disttable_with_relopts_3;
-- Test SERIAL type column support for distributed hypertables
--
CREATE TABLE disttable_serial(time timestamptz NOT NULL, device int, id1 SERIAL, id2 SMALLSERIAL, id3 BIGSERIAL);
SELECT create_distributed_hypertable('disttable_serial', 'time', 'device');
 create_distributed_hypertable  
--------------------------------
 (21,public,disttable_serial,t)
(1 row)

-- Show created columns (AN and DN tables must be exact)
SELECT * FROM test.show_columns('disttable_serial');
 Column |           Type           | NotNull 
--------+--------------------------+---------
 time   | timestamp with time zone | t
 device | integer                  | f
 id1    | integer                  | t
 id2    | smallint                 | t
 id3    | bigint                   | t
(5 rows)

SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
	SELECT * FROM test.show_columns('disttable_serial');
$$);
NOTICE:  [data_node_1]: 
	SELECT * FROM test.show_columns('disttable_serial')
NOTICE:  [data_node_1]:
Column|Type                    |NotNull
------+------------------------+-------
time  |timestamp with time zone|t      
device|integer                 |f      
id1   |integer                 |t      
id2   |smallint                |t      
id3   |bigint                  |t      
(5 rows)


NOTICE:  [data_node_2]: 
	SELECT * FROM test.show_columns('disttable_serial')
NOTICE:  [data_node_2]:
Column|Type                    |NotNull
------+------------------------+-------
time  |timestamp with time zone|t      
device|integer                 |f      
id1   |integer                 |t      
id2   |smallint                |t      
id3   |bigint                  |t      
(5 rows)


NOTICE:  [data_node_3]: 
	SELECT * FROM test.show_columns('disttable_serial')
NOTICE:  [data_node_3]:
Column|Type                    |NotNull
------+------------------------+-------
time  |timestamp with time zone|t      
device|integer                 |f      
id1   |integer                 |t      
id2   |smallint                |t      
id3   |bigint                  |t      
(5 rows)


 remote_exec 
-------------
 
(1 row)

-- Ensure DEFAULT expression is applied on the AN only
SELECT column_name, column_default
FROM information_schema.columns
WHERE table_name  = 'disttable_serial';
 column_name |                column_default                 
-------------+-----------------------------------------------
 time        | 
 device      | 
 id1         | nextval('disttable_serial_id1_seq'::regclass)
 id2         | nextval('disttable_serial_id2_seq'::regclass)
 id3         | nextval('disttable_serial_id3_seq'::regclass)
(5 rows)

SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
	SELECT column_name, column_default
	FROM information_schema.columns
	WHERE table_name  = 'disttable_serial';
$$);
NOTICE:  [data_node_1]: 
	SELECT column_name, column_default
	FROM information_schema.columns
	WHERE table_name  = 'disttable_serial'
NOTICE:  [data_node_1]:
column_name|column_default
-----------+--------------
time       |              
device     |              
id1        |              
id2        |              
id3        |              
(5 rows)


NOTICE:  [data_node_2]: 
	SELECT column_name, column_default
	FROM information_schema.columns
	WHERE table_name  = 'disttable_serial'
NOTICE:  [data_node_2]:
column_name|column_default
-----------+--------------
time       |              
device     |              
id1        |              
id2        |              
id3        |              
(5 rows)


NOTICE:  [data_node_3]: 
	SELECT column_name, column_default
	FROM information_schema.columns
	WHERE table_name  = 'disttable_serial'
NOTICE:  [data_node_3]:
column_name|column_default
-----------+--------------
time       |              
device     |              
id1        |              
id2        |              
id3        |              
(5 rows)


 remote_exec 
-------------
 
(1 row)

-- Ensure sequences were created on the AN only
INSERT INTO disttable_serial VALUES
       ('2017-01-01 06:01', 1),
       ('2017-01-01 09:11', 3),
       ('2017-01-01 08:01', 1),
       ('2017-01-02 08:01', 2),
       ('2018-07-02 08:01', 87);
SELECT currval('disttable_serial_id1_seq'::regclass),
       currval('disttable_serial_id2_seq'::regclass),
       currval('disttable_serial_id3_seq'::regclass);
 currval | currval | currval 
---------+---------+---------
       5 |       5 |       5
(1 row)

\set ON_ERROR_STOP 0
SELECT * FROM test.remote_exec('{ data_node_1 }',$$
	SELECT currval('disttable_serial_id1_seq'::regclass);
$$);
NOTICE:  [data_node_1]: 
	SELECT currval('disttable_serial_id1_seq'::regclass)
ERROR:  [data_node_1]: relation "disttable_serial_id1_seq" does not exist
\set ON_ERROR_STOP 1
-- Verify that the data is getting spread over multiple data nodes with the
-- serial values being set correctly
SELECT * from disttable_serial ORDER BY id1;
             time             | device | id1 | id2 | id3 
------------------------------+--------+-----+-----+-----
 Sun Jan 01 06:01:00 2017 PST |      1 |   1 |   1 |   1
 Sun Jan 01 09:11:00 2017 PST |      3 |   2 |   2 |   2
 Sun Jan 01 08:01:00 2017 PST |      1 |   3 |   3 |   3
 Mon Jan 02 08:01:00 2017 PST |      2 |   4 |   4 |   4
 Mon Jul 02 08:01:00 2018 PDT |     87 |   5 |   5 |   5
(5 rows)

SELECT * FROM test.remote_exec('{ data_node_1, data_node_2, data_node_3 }', $$
	SELECT * from disttable_serial ORDER BY id1;
$$);
NOTICE:  [data_node_1]: 
	SELECT * from disttable_serial ORDER BY id1
NOTICE:  [data_node_1]:
time                        |device|id1|id2|id3
----------------------------+------+---+---+---
Sun Jan 01 06:01:00 2017 PST|     1|  1|  1|  1
Sun Jan 01 08:01:00 2017 PST|     1|  3|  3|  3
Mon Jul 02 08:01:00 2018 PDT|    87|  5|  5|  5
(3 rows)


NOTICE:  [data_node_2]: 
	SELECT * from disttable_serial ORDER BY id1
NOTICE:  [data_node_2]:
time                        |device|id1|id2|id3
----------------------------+------+---+---+---
Mon Jan 02 08:01:00 2017 PST|     2|  4|  4|  4
(1 row)


NOTICE:  [data_node_3]: 
	SELECT * from disttable_serial ORDER BY id1
NOTICE:  [data_node_3]:
time                        |device|id1|id2|id3
----------------------------+------+---+---+---
Sun Jan 01 09:11:00 2017 PST|     3|  2|  2|  2
(1 row)


 remote_exec 
-------------
 
(1 row)

DROP TABLE disttable_serial;
-- Test insert batching case which will hit the limit of arguments for 
-- prepared statements (65k).
--
-- Issue: #1702
-- distributed hypertable insert fails when # of columns are more than 65
--
-- Use default value
SET timescaledb.max_insert_batch_size TO 1000;
CREATE TABLE test_1702 (
	id varchar(100) NOT NULL,
	time timestamp NOT NULL,
	dummy1	int	,
	dummy2	int	,
	dummy4	int	,
	dummy5	int	,
	dummy6	int	,
	dummy7	int	,
	dummy8	int	,
	dummy9	int	,
	dummy10	int	,
	dummy11	int	,
	dummy12	int	,
	dummy13	int	,
	dummy14	int	,
	dummy15	int	,
	dummy16	int	,
	dummy17	int	,
	dummy18	int	,
	dummy19	int	,
	dummy20	int	,
	dummy21	int	,
	dummy22	int	,
	dummy23	int	,
	dummy24	int	,
	dummy25	int	,
	dummy26	int	,
	dummy27	int	,
	dummy28	int	,
	dummy29	int	,
	dummy30	int	,
	dummy31	int	,
	dummy32	int	,
	dummy33	int	,
	dummy34	int	,
	dummy35	int	,
	dummy36	int	,
	dummy37	int	,
	dummy38	int	,
	dummy39	int	,
	dummy40	int	,
	dummy41	int	,
	dummy42	int	,
	dummy43	int	,
	dummy44	int	,
	dummy45	int	,
	dummy46	int	,
	dummy47	int	,
	dummy48	int	,
	dummy49	int	,
	dummy50	int	,
	dummy51	int	,
	dummy52	int	,
	dummy53	int	,
	dummy54	int	,
	dummy55	int	,
	dummy56	int	,
	dummy57	int	,
	dummy58	int	,
	dummy59	int	,
	dummy60	int	,
	dummy61	int	,
	dummy62	int	,
	dummy63	int	,
	dummy64	int	,
	dummy65	int	,
	dummy66	int	,
	dummy67	int	,
	dummy68	int	,
	dummy69	int	,
	dummy70	int	,
	dummy71	int	
);
SELECT create_distributed_hypertable('test_1702', 'time', 'id');
 create_distributed_hypertable 
-------------------------------
 (22,public,test_1702,t)
(1 row)

-- Original issue case
--
-- Expect batch size to be lower than defined max_insert_batch_size
--
EXPLAIN INSERT INTO test_1702(id, time) VALUES('1', current_timestamp);
                                    QUERY PLAN                                     
-----------------------------------------------------------------------------------
 Custom Scan (HypertableInsert)  (cost=0.00..0.01 rows=1 width=506)
 Insert on distributed hypertable test_1702
   ->  Insert on test_1702  (cost=0.00..0.01 rows=1 width=506)
         ->  Custom Scan (DataNodeDispatch)  (cost=0.00..0.01 rows=1 width=506)
               Batch size: 910
               ->  Custom Scan (ChunkDispatch)  (cost=0.00..0.01 rows=1 width=506)
                     ->  Result  (cost=0.00..0.01 rows=1 width=506)
(7 rows)

INSERT INTO test_1702(id, time) VALUES('1', current_timestamp);
EXPLAIN INSERT INTO test_1702(id, time) SELECT generate_series(2, 1500), current_timestamp;
                                         QUERY PLAN                                          
---------------------------------------------------------------------------------------------
 Custom Scan (HypertableInsert)  (cost=0.00..25.02 rows=1000 width=506)
 Insert on distributed hypertable test_1702
   ->  Insert on test_1702  (cost=0.00..25.02 rows=1000 width=506)
         ->  Custom Scan (DataNodeDispatch)  (cost=0.00..25.02 rows=1000 width=506)
               Batch size: 910
               ->  Custom Scan (ChunkDispatch)  (cost=0.00..25.02 rows=1000 width=506)
                     ->  Subquery Scan on "*SELECT*"  (cost=0.00..25.02 rows=1000 width=506)
                           ->  ProjectSet  (cost=0.00..5.02 rows=1000 width=12)
                                 ->  Result  (cost=0.00..0.01 rows=1 width=0)
(9 rows)

INSERT INTO test_1702(id, time) SELECT generate_series(2, 1500), current_timestamp;
SELECT count(*) from test_1702;
 count 
-------
  1500
(1 row)

DROP TABLE test_1702;
--
-- Expect batch size to be similair to max_insert_batch_size
--
CREATE TABLE test_1702 (
	id varchar(100) NOT NULL,
	time timestamp NOT NULL,
	dummy1	int	,
	dummy2	int	,
	dummy4	int	,
	dummy5	int
	);
SELECT create_distributed_hypertable('test_1702', 'time', 'id');
 create_distributed_hypertable 
-------------------------------
 (23,public,test_1702,t)
(1 row)

EXPLAIN INSERT INTO test_1702(id, time) VALUES('1', current_timestamp);
                                    QUERY PLAN                                     
-----------------------------------------------------------------------------------
 Custom Scan (HypertableInsert)  (cost=0.00..0.01 rows=1 width=242)
 Insert on distributed hypertable test_1702
   ->  Insert on test_1702  (cost=0.00..0.01 rows=1 width=242)
         ->  Custom Scan (DataNodeDispatch)  (cost=0.00..0.01 rows=1 width=242)
               Batch size: 1000
               ->  Custom Scan (ChunkDispatch)  (cost=0.00..0.01 rows=1 width=242)
                     ->  Result  (cost=0.00..0.01 rows=1 width=242)
(7 rows)

DROP TABLE test_1702;
--
-- Test that creating a hypertable with a space dimension and
-- if_not_exists works as expected, that is, the second call does not
-- generate an error (and does not crash).
--
CREATE TABLE whatever (
    timestamp TIMESTAMPTZ NOT NULL,
    user_id   INT         NOT NULL,
    data      JSONB
);
SELECT * FROM create_distributed_hypertable('whatever', 'timestamp', 'user_id',
                                            if_not_exists => true, chunk_time_interval => INTERVAL '1 day');
 hypertable_id | schema_name | table_name | created 
---------------+-------------+------------+---------
            24 | public      | whatever   | t
(1 row)

-- Check the hypertable sequence before and after call to ensure that
-- the hypertable sequence was not increased with the second call.
SELECT  * FROM _timescaledb_catalog.hypertable_id_seq;
 last_value | log_cnt | is_called 
------------+---------+-----------
         24 |      23 | t
(1 row)

SELECT * FROM create_distributed_hypertable('whatever', 'timestamp', 'user_id',
                                            if_not_exists => true, chunk_time_interval => INTERVAL '1 day');
NOTICE:  table "whatever" is already a hypertable, skipping
 hypertable_id | schema_name | table_name | created 
---------------+-------------+------------+---------
            24 | public      | whatever   | f
(1 row)

SELECT  * FROM _timescaledb_catalog.hypertable_id_seq;
 last_value | log_cnt | is_called 
------------+---------+-----------
         24 |      23 | t
(1 row)

-- Test that creating a distributed hypertable from a table with data
-- fails, and that migrate_data blocked.
CREATE TABLE dist_hypertable_1 (
  time TIMESTAMPTZ NOT NULL,
  device INTEGER,
  temp FLOAT
);
INSERT INTO dist_hypertable_1 VALUES
       ('2017-01-01 06:01', 1),
       ('2017-01-01 09:11', 3),
       ('2017-01-01 08:01', 1),
       ('2017-01-02 08:01', 2),
       ('2018-07-02 08:01', 87);
\set ON_ERROR_STOP 0
SELECT * FROM create_distributed_hypertable('dist_hypertable_1', 'time', 'device', 3,
       migrate_data => FALSE);
ERROR:  table "dist_hypertable_1" is not empty
SELECT * FROM create_distributed_hypertable('dist_hypertable_1', 'time', 'device', 3,
       migrate_data => TRUE);
ERROR:  cannot migrate data for distributed hypertable
\set ON_ERROR_STOP 1
-- Test creating index with transaction per chunk on a distributed hypertable
--
DROP TABLE disttable;
CREATE TABLE disttable(
    time timestamptz NOT NULL, 
    device int, 
    value float
);
SELECT * FROM create_distributed_hypertable('disttable', 'time', 'device', 3);
 hypertable_id | schema_name | table_name | created 
---------------+-------------+------------+---------
            25 | public      | disttable  | t
(1 row)

INSERT INTO disttable VALUES
       ('2017-01-01 06:01', 1, 1.2),
       ('2017-01-01 09:11', 3, 4.3),
       ('2017-01-01 08:01', 1, 7.3),
       ('2017-01-02 08:01', 2, 0.23),
       ('2018-07-02 08:01', 87, 0.0),
       ('2018-07-01 06:01', 13, 3.1),
       ('2018-07-01 09:11', 90, 10303.12),
       ('2018-07-01 08:01', 29, 64);
CREATE INDEX disttable_time_device_idx ON disttable (time, device) WITH (timescaledb.transaction_per_chunk);
ERROR:  cannot use timescaledb.transaction_per_chunk with distributed hypetable
