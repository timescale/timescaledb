-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\set ECHO errors
-- Disable incremental sort to make tests stable
set enable_incremental_sort = false;
select setseed(1);
 setseed 
---------
 
(1 row)

create table readings(
       time timestamptz not null unique,
       location int not null,
       device int not null,
       temp numeric(4,1),
       humidity float,
       jdata jsonb
);
select create_hypertable('readings', by_range('time', '1d'::interval));
 create_hypertable 
-------------------
 (1,t)
(1 row)

alter table readings
      set (timescaledb.compress_orderby = 'time',
	   timescaledb.compress_segmentby = 'device');
insert into readings (time, location, device, temp, humidity, jdata)
select t, ceil(random()*10), ceil(random()*30), random()*40, random()*100, '{"a":1,"b":2}'::jsonb
from generate_series('2022-06-01'::timestamptz, '2022-06-04'::timestamptz, '5m') t;
select compress_chunk(show_chunks('readings'), hypercore_use_access_method => true);
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_2_chunk
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_4_chunk
(4 rows)

-- Insert some extra data to get some non-compressed data as well.
insert into readings (time, location, device, temp, humidity, jdata)
select t, ceil(random()*10), ceil(random()*30), random()*40, random()*100, '{"a":1,"b":2}'::jsonb
from generate_series('2022-06-01 00:01:00'::timestamptz, '2022-06-04'::timestamptz, '5m') t;
select chunk, amname from chunk_info where hypertable = 'readings'::regclass;
                 chunk                  |  amname   
----------------------------------------+-----------
 _timescaledb_internal._hyper_1_1_chunk | hypercore
 _timescaledb_internal._hyper_1_2_chunk | hypercore
 _timescaledb_internal._hyper_1_3_chunk | hypercore
 _timescaledb_internal._hyper_1_4_chunk | hypercore
(4 rows)

-- Pick a chunk to truncate that is not the first chunk. This is
-- mostly a precaution to make sure that there is no bias towards the
-- first chunk and we could just as well pick the first chunk.
select chunk from show_chunks('readings') x(chunk) limit 1 offset 3 \gset
-- Check that the number of bytes in the table before and after the
-- truncate.
--
-- Note that a table with a toastable attribute will always have a
-- toast table assigned, so pg_table_size() shows one page allocated
-- since this includes the toast table.
select pg_table_size(chunk) as chunk_size,
       pg_table_size(compressed_chunk) as compressed_chunk_size
  from chunk_info
 where chunk = :'chunk'::regclass;
 chunk_size | compressed_chunk_size 
------------+-----------------------
      40960 |                 57344
(1 row)

truncate :chunk;
select pg_table_size(chunk) as chunk_size,
       pg_table_size(compressed_chunk) as compressed_chunk_size
  from chunk_info
 where chunk = :'chunk'::regclass;
 chunk_size | compressed_chunk_size 
------------+-----------------------
          0 |                  8192
(1 row)

-- We test TRUNCATE on a hypertable as well, but truncating a
-- hypertable is done by deleting all chunks, not by truncating each
-- chunk.
select (select count(*) from readings) tuples,
       (select count(*) from show_chunks('readings')) chunks;
 tuples | chunks 
--------+--------
   1560 |      4
(1 row)

truncate readings;
select (select count(*) from readings) tuples,
       (select count(*) from show_chunks('readings')) chunks;
 tuples | chunks 
--------+--------
      0 |      0
(1 row)

\set ON_ERROR_STOP 0
insert into readings(time,device,temp,humidity,jdata)
values ('2024-01-01 00:00:00', 1, 99.0, 99.0, '{"magic": "yes"}'::jsonb);
ERROR:  null value in column "location" of relation "_hyper_1_9_chunk" violates not-null constraint
\set ON_ERROR_STOP 1
-- Test altering column definitions
alter table readings
      alter column location drop not null;
-- This should now work.
insert into readings(time,device,temp,humidity,jdata)
values ('2024-01-01 00:00:00', 1, 99.0, 99.0, '{"magic": "yes"}'::jsonb);
select count(*) from readings where location is null;
 count 
-------
     1
(1 row)

select compress_chunk(show_chunks('readings'), hypercore_use_access_method => true);
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_1_10_chunk
(1 row)

select count(*) from readings where location is null;
 count 
-------
     1
(1 row)

