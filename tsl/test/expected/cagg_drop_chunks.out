-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\c :TEST_DBNAME :ROLE_SUPERUSER
SET timezone TO PST8PDT;
--
-- Check that drop chunks with a unique constraint works as expected.
--
CREATE TABLE clients (
       id SERIAL PRIMARY KEY,
       name TEXT NOT NULL,
       UNIQUE(name)
);
CREATE TABLE records (
    time TIMESTAMPTZ NOT NULL,
    clientId INT NOT NULL REFERENCES clients(id),
    value DOUBLE PRECISION,
    UNIQUE(time, clientId)
);
SELECT * FROM create_hypertable('records', 'time',
       chunk_time_interval => INTERVAL '1h');
 hypertable_id | schema_name | table_name | created 
---------------+-------------+------------+---------
             1 | public      | records    | t

CREATE MATERIALIZED VIEW records_monthly
    WITH (timescaledb.continuous, timescaledb.materialized_only=false)
    AS
        SELECT time_bucket('1d', time) as bucket,
            clientId,
            avg(value) as value_avg,
            max(value)-min(value) as value_spread
        FROM records GROUP BY bucket, clientId WITH NO DATA;
INSERT INTO clients(name) VALUES ('test-client');
INSERT INTO records
SELECT generate_series('2000-03-01'::timestamptz,'2000-04-01','1 day'),1,3.14;
SELECT * FROM records_monthly;
            bucket            | clientid | value_avg | value_spread 
------------------------------+----------+-----------+--------------
 Mon Mar 27 16:00:00 2000 PST |        1 |      3.14 |            0
 Fri Mar 10 16:00:00 2000 PST |        1 |      3.14 |            0
 Tue Mar 07 16:00:00 2000 PST |        1 |      3.14 |            0
 Fri Mar 24 16:00:00 2000 PST |        1 |      3.14 |            0
 Sun Mar 19 16:00:00 2000 PST |        1 |      3.14 |            0
 Wed Mar 29 16:00:00 2000 PST |        1 |      3.14 |            0
 Wed Mar 15 16:00:00 2000 PST |        1 |      3.14 |            0
 Fri Mar 31 16:00:00 2000 PST |        1 |      3.14 |            0
 Mon Mar 20 16:00:00 2000 PST |        1 |      3.14 |            0
 Thu Mar 30 16:00:00 2000 PST |        1 |      3.14 |            0
 Sat Mar 11 16:00:00 2000 PST |        1 |      3.14 |            0
 Mon Mar 13 16:00:00 2000 PST |        1 |      3.14 |            0
 Sun Mar 12 16:00:00 2000 PST |        1 |      3.14 |            0
 Tue Mar 28 16:00:00 2000 PST |        1 |      3.14 |            0
 Sun Mar 26 16:00:00 2000 PST |        1 |      3.14 |            0
 Wed Mar 22 16:00:00 2000 PST |        1 |      3.14 |            0
 Thu Mar 16 16:00:00 2000 PST |        1 |      3.14 |            0
 Sat Mar 25 16:00:00 2000 PST |        1 |      3.14 |            0
 Thu Mar 23 16:00:00 2000 PST |        1 |      3.14 |            0
 Thu Mar 02 16:00:00 2000 PST |        1 |      3.14 |            0
 Sat Mar 18 16:00:00 2000 PST |        1 |      3.14 |            0
 Mon Mar 06 16:00:00 2000 PST |        1 |      3.14 |            0
 Tue Feb 29 16:00:00 2000 PST |        1 |      3.14 |            0
 Fri Mar 17 16:00:00 2000 PST |        1 |      3.14 |            0
 Tue Mar 14 16:00:00 2000 PST |        1 |      3.14 |            0
 Wed Mar 08 16:00:00 2000 PST |        1 |      3.14 |            0
 Sat Mar 04 16:00:00 2000 PST |        1 |      3.14 |            0
 Sun Mar 05 16:00:00 2000 PST |        1 |      3.14 |            0
 Tue Mar 21 16:00:00 2000 PST |        1 |      3.14 |            0
 Wed Mar 01 16:00:00 2000 PST |        1 |      3.14 |            0
 Thu Mar 09 16:00:00 2000 PST |        1 |      3.14 |            0
 Fri Mar 03 16:00:00 2000 PST |        1 |      3.14 |            0

SELECT chunk_name, range_start, range_end
FROM timescaledb_information.chunks
WHERE hypertable_name = 'records_monthly' ORDER BY range_start;
 chunk_name | range_start | range_end 
------------+-------------+-----------

SELECT chunk_name, range_start, range_end
FROM timescaledb_information.chunks
WHERE hypertable_name = 'records' ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_1_1_chunk  | Wed Mar 01 00:00:00 2000 PST | Wed Mar 01 01:00:00 2000 PST
 _hyper_1_2_chunk  | Thu Mar 02 00:00:00 2000 PST | Thu Mar 02 01:00:00 2000 PST
 _hyper_1_3_chunk  | Fri Mar 03 00:00:00 2000 PST | Fri Mar 03 01:00:00 2000 PST
 _hyper_1_4_chunk  | Sat Mar 04 00:00:00 2000 PST | Sat Mar 04 01:00:00 2000 PST
 _hyper_1_5_chunk  | Sun Mar 05 00:00:00 2000 PST | Sun Mar 05 01:00:00 2000 PST
 _hyper_1_6_chunk  | Mon Mar 06 00:00:00 2000 PST | Mon Mar 06 01:00:00 2000 PST
 _hyper_1_7_chunk  | Tue Mar 07 00:00:00 2000 PST | Tue Mar 07 01:00:00 2000 PST
 _hyper_1_8_chunk  | Wed Mar 08 00:00:00 2000 PST | Wed Mar 08 01:00:00 2000 PST
 _hyper_1_9_chunk  | Thu Mar 09 00:00:00 2000 PST | Thu Mar 09 01:00:00 2000 PST
 _hyper_1_10_chunk | Fri Mar 10 00:00:00 2000 PST | Fri Mar 10 01:00:00 2000 PST
 _hyper_1_11_chunk | Sat Mar 11 00:00:00 2000 PST | Sat Mar 11 01:00:00 2000 PST
 _hyper_1_12_chunk | Sun Mar 12 00:00:00 2000 PST | Sun Mar 12 01:00:00 2000 PST
 _hyper_1_13_chunk | Mon Mar 13 00:00:00 2000 PST | Mon Mar 13 01:00:00 2000 PST
 _hyper_1_14_chunk | Tue Mar 14 00:00:00 2000 PST | Tue Mar 14 01:00:00 2000 PST
 _hyper_1_15_chunk | Wed Mar 15 00:00:00 2000 PST | Wed Mar 15 01:00:00 2000 PST
 _hyper_1_16_chunk | Thu Mar 16 00:00:00 2000 PST | Thu Mar 16 01:00:00 2000 PST
 _hyper_1_17_chunk | Fri Mar 17 00:00:00 2000 PST | Fri Mar 17 01:00:00 2000 PST
 _hyper_1_18_chunk | Sat Mar 18 00:00:00 2000 PST | Sat Mar 18 01:00:00 2000 PST
 _hyper_1_19_chunk | Sun Mar 19 00:00:00 2000 PST | Sun Mar 19 01:00:00 2000 PST
 _hyper_1_20_chunk | Mon Mar 20 00:00:00 2000 PST | Mon Mar 20 01:00:00 2000 PST
 _hyper_1_21_chunk | Tue Mar 21 00:00:00 2000 PST | Tue Mar 21 01:00:00 2000 PST
 _hyper_1_22_chunk | Wed Mar 22 00:00:00 2000 PST | Wed Mar 22 01:00:00 2000 PST
 _hyper_1_23_chunk | Thu Mar 23 00:00:00 2000 PST | Thu Mar 23 01:00:00 2000 PST
 _hyper_1_24_chunk | Fri Mar 24 00:00:00 2000 PST | Fri Mar 24 01:00:00 2000 PST
 _hyper_1_25_chunk | Sat Mar 25 00:00:00 2000 PST | Sat Mar 25 01:00:00 2000 PST
 _hyper_1_26_chunk | Sun Mar 26 00:00:00 2000 PST | Sun Mar 26 01:00:00 2000 PST
 _hyper_1_27_chunk | Mon Mar 27 00:00:00 2000 PST | Mon Mar 27 01:00:00 2000 PST
 _hyper_1_28_chunk | Tue Mar 28 00:00:00 2000 PST | Tue Mar 28 01:00:00 2000 PST
 _hyper_1_29_chunk | Wed Mar 29 00:00:00 2000 PST | Wed Mar 29 01:00:00 2000 PST
 _hyper_1_30_chunk | Thu Mar 30 00:00:00 2000 PST | Thu Mar 30 01:00:00 2000 PST
 _hyper_1_31_chunk | Fri Mar 31 00:00:00 2000 PST | Fri Mar 31 01:00:00 2000 PST
 _hyper_1_32_chunk | Sat Apr 01 00:00:00 2000 PST | Sat Apr 01 01:00:00 2000 PST

CALL refresh_continuous_aggregate('records_monthly', NULL, NULL);
\set VERBOSITY default
SELECT drop_chunks('records', '2000-03-16'::timestamptz);
               drop_chunks               
-----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_2_chunk
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_4_chunk
 _timescaledb_internal._hyper_1_5_chunk
 _timescaledb_internal._hyper_1_6_chunk
 _timescaledb_internal._hyper_1_7_chunk
 _timescaledb_internal._hyper_1_8_chunk
 _timescaledb_internal._hyper_1_9_chunk
 _timescaledb_internal._hyper_1_10_chunk
 _timescaledb_internal._hyper_1_11_chunk
 _timescaledb_internal._hyper_1_12_chunk
 _timescaledb_internal._hyper_1_13_chunk
 _timescaledb_internal._hyper_1_14_chunk
 _timescaledb_internal._hyper_1_15_chunk

\set VERBOSITY terse
DROP MATERIALIZED VIEW records_monthly;
NOTICE:  drop cascades to 32 other objects
DROP TABLE records;
DROP TABLE clients;
\set VERBOSITY default
CREATE PROCEDURE refresh_cagg_by_chunk_range(_cagg REGCLASS, _hypertable REGCLASS, _older_than INTEGER)
AS
$$
DECLARE
    _r RECORD;
BEGIN
    WITH _chunks AS (
        SELECT relname, nspname
        FROM show_chunks(_hypertable, _older_than) AS relid
        JOIN pg_catalog.pg_class ON pg_class.oid = relid AND pg_class.relkind = 'r'
        JOIN pg_catalog.pg_namespace ON pg_namespace.oid = pg_class.relnamespace
    )
    SELECT MIN(range_start) AS range_start, MAX(range_end) AS range_end
    INTO _r
    FROM
        _chunks
        JOIN _timescaledb_catalog.chunk ON chunk.schema_name = _chunks.nspname AND chunk.table_name = _chunks.relname
        JOIN _timescaledb_catalog.chunk_constraint ON chunk_id = chunk.id
        JOIN _timescaledb_catalog.dimension_slice ON dimension_slice.id = dimension_slice_id;

    RAISE INFO 'range_start=% range_end=%', _r.range_start::int, _r.range_end::int;
    CALL refresh_continuous_aggregate(_cagg, _r.range_start::int, _r.range_end::int + 1);
END;
$$
LANGUAGE plpgsql;
CREATE OR REPLACE FUNCTION test_int_now() returns INT LANGUAGE SQL STABLE as
    $$ SELECT 125 $$;
CREATE TABLE conditions(time_int INT NOT NULL, value FLOAT);
SELECT create_hypertable('conditions', 'time_int', chunk_time_interval => 4);
    create_hypertable    
-------------------------
 (3,public,conditions,t)

INSERT INTO conditions
SELECT time_val, 1 FROM generate_series(0, 19, 1) AS time_val;
SELECT set_integer_now_func('conditions', 'test_int_now');
 set_integer_now_func 
----------------------
 

CREATE MATERIALIZED VIEW conditions_2
    WITH (timescaledb.continuous, timescaledb.materialized_only = TRUE)
    AS
        SELECT time_bucket(2, time_int) as bucket,
            SUM(value), COUNT(value)
        FROM conditions GROUP BY bucket WITH DATA;
NOTICE:  refreshing continuous aggregate "conditions_2"
HINT:  Use WITH NO DATA if you do not want to refresh the continuous aggregate on creation.
SELECT * FROM conditions_2 ORDER BY bucket;
 bucket | sum | count 
--------+-----+-------
      0 |   2 |     2
      2 |   2 |     2
      4 |   2 |     2
      6 |   2 |     2
      8 |   2 |     2
     10 |   2 |     2
     12 |   2 |     2
     14 |   2 |     2
     16 |   2 |     2
     18 |   2 |     2

UPDATE conditions SET value = 4.00 WHERE time_int = 0;
UPDATE conditions SET value = 4.00 WHERE time_int = 6;
CALL refresh_cagg_by_chunk_range('conditions_2', 'conditions', 4);
INFO:  range_start=0 range_end=4
SELECT drop_chunks('conditions', 4);
               drop_chunks               
-----------------------------------------
 _timescaledb_internal._hyper_3_65_chunk

SELECT * FROM conditions_2 ORDER BY bucket;
 bucket | sum | count 
--------+-----+-------
      0 |   5 |     2
      2 |   2 |     2
      4 |   2 |     2
      6 |   2 |     2
      8 |   2 |     2
     10 |   2 |     2
     12 |   2 |     2
     14 |   2 |     2
     16 |   2 |     2
     18 |   2 |     2

CALL refresh_cagg_by_chunk_range('conditions_2', 'conditions', 8);
INFO:  range_start=4 range_end=8
SELECT * FROM conditions_2 ORDER BY bucket;
 bucket | sum | count 
--------+-----+-------
      0 |   5 |     2
      2 |   2 |     2
      4 |   2 |     2
      6 |   5 |     2
      8 |   2 |     2
     10 |   2 |     2
     12 |   2 |     2
     14 |   2 |     2
     16 |   2 |     2
     18 |   2 |     2

UPDATE conditions SET value = 4.00 WHERE time_int = 19;
SELECT drop_chunks('conditions', 8);
               drop_chunks               
-----------------------------------------
 _timescaledb_internal._hyper_3_66_chunk

CALL refresh_cagg_by_chunk_range('conditions_2', 'conditions', 12);
INFO:  range_start=8 range_end=12
SELECT * FROM conditions_2 ORDER BY bucket;
 bucket | sum | count 
--------+-----+-------
      0 |   5 |     2
      2 |   2 |     2
      4 |   2 |     2
      6 |   5 |     2
      8 |   2 |     2
     10 |   2 |     2
     12 |   2 |     2
     14 |   2 |     2
     16 |   2 |     2
     18 |   2 |     2

CALL refresh_cagg_by_chunk_range('conditions_2', 'conditions', NULL);
INFO:  range_start=8 range_end=20
SELECT * FROM conditions_2 ORDER BY bucket;
 bucket | sum | count 
--------+-----+-------
      0 |   5 |     2
      2 |   2 |     2
      4 |   2 |     2
      6 |   5 |     2
      8 |   2 |     2
     10 |   2 |     2
     12 |   2 |     2
     14 |   2 |     2
     16 |   2 |     2
     18 |   5 |     2

DROP PROCEDURE refresh_cagg_by_chunk_range(REGCLASS, REGCLASS, INTEGER);
--
-- Test drop_chunks with continuous aggregates and watermark protection
--
CREATE TABLE sensor_data (
    time TIMESTAMPTZ NOT NULL,
    sensor_id INTEGER NOT NULL,
    temperature DOUBLE PRECISION,
    humidity DOUBLE PRECISION,
    pressure DOUBLE PRECISION
);
SELECT create_hypertable('sensor_data', 'time',
    chunk_time_interval => INTERVAL '1 day'
);
    create_hypertable     
--------------------------
 (5,public,sensor_data,t)

INSERT INTO sensor_data
SELECT
    timestamp '2024-01-01' + (i * INTERVAL '4 hours') AS time,
    (i % 5) + 1 AS sensor_id,
    15 + 15 * random() AS temperature,
    30 + 60 * random() AS humidity,
    980 + 40 * random() AS pressure
FROM generate_series(0, 25) AS i;
CREATE MATERIALIZED VIEW sensor_hourly_avg
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS bucket,
    sensor_id,
    AVG(temperature) AS avg_temperature,
    AVG(humidity) AS avg_humidity,
    AVG(pressure) AS avg_pressure,
    COUNT(*) AS reading_count
FROM sensor_data
GROUP BY bucket, sensor_id
WITH NO DATA;
-- Checks range start and end for chunks
SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_5_71_chunk | Sun Dec 31 16:00:00 2023 PST | Mon Jan 01 16:00:00 2024 PST
 _hyper_5_72_chunk | Mon Jan 01 16:00:00 2024 PST | Tue Jan 02 16:00:00 2024 PST
 _hyper_5_73_chunk | Tue Jan 02 16:00:00 2024 PST | Wed Jan 03 16:00:00 2024 PST
 _hyper_5_74_chunk | Wed Jan 03 16:00:00 2024 PST | Thu Jan 04 16:00:00 2024 PST
 _hyper_5_75_chunk | Thu Jan 04 16:00:00 2024 PST | Fri Jan 05 16:00:00 2024 PST

-- Completely refresh the aggregate
CALL refresh_continuous_aggregate('sensor_hourly_avg', NULL, NULL);
SELECT count(*) AS ht_before FROM show_chunks('sensor_data');
 ht_before 
-----------
         5

-- Insert more data after the CAgg watermark
INSERT INTO sensor_data
SELECT
    timestamp '2024-02-01' + (i * INTERVAL '4 hours') AS time,
    (i % 5) + 1 AS sensor_id,
    15 + 15 * random() AS temperature,
    30 + 60 * random() AS humidity,
    980 + 40 * random() AS pressure
FROM generate_series(0, 25) AS i;
-- View ranges before drop chunks
SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_5_71_chunk | Sun Dec 31 16:00:00 2023 PST | Mon Jan 01 16:00:00 2024 PST
 _hyper_5_72_chunk | Mon Jan 01 16:00:00 2024 PST | Tue Jan 02 16:00:00 2024 PST
 _hyper_5_73_chunk | Tue Jan 02 16:00:00 2024 PST | Wed Jan 03 16:00:00 2024 PST
 _hyper_5_74_chunk | Wed Jan 03 16:00:00 2024 PST | Thu Jan 04 16:00:00 2024 PST
 _hyper_5_75_chunk | Thu Jan 04 16:00:00 2024 PST | Fri Jan 05 16:00:00 2024 PST
 _hyper_5_77_chunk | Wed Jan 31 16:00:00 2024 PST | Thu Feb 01 16:00:00 2024 PST
 _hyper_5_78_chunk | Thu Feb 01 16:00:00 2024 PST | Fri Feb 02 16:00:00 2024 PST
 _hyper_5_79_chunk | Fri Feb 02 16:00:00 2024 PST | Sat Feb 03 16:00:00 2024 PST
 _hyper_5_80_chunk | Sat Feb 03 16:00:00 2024 PST | Sun Feb 04 16:00:00 2024 PST
 _hyper_5_81_chunk | Sun Feb 04 16:00:00 2024 PST | Mon Feb 05 16:00:00 2024 PST

-- Verify watermark
SELECT h.id AS mat_hypertable_id
  FROM _timescaledb_catalog.continuous_agg ca
  JOIN _timescaledb_catalog.hypertable h ON h.id = ca.mat_hypertable_id
  WHERE ca.user_view_name = 'sensor_hourly_avg' \gset
SELECT _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:mat_hypertable_id));
         to_timestamp         
------------------------------
 Fri Jan 05 05:00:00 2024 PST

\set VERBOSITY terse
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data', newer_than => '2023-12-31 17:00:00-07'::timestamp with time zone);
NOTICE:  skipping _timescaledb_internal._hyper_5_75_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_77_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_78_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_79_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_80_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_81_chunk, chunk contains data required for a continuous aggregate refresh
 dropped_count 
---------------
             4

SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_5_75_chunk | Thu Jan 04 16:00:00 2024 PST | Fri Jan 05 16:00:00 2024 PST
 _hyper_5_77_chunk | Wed Jan 31 16:00:00 2024 PST | Thu Feb 01 16:00:00 2024 PST
 _hyper_5_78_chunk | Thu Feb 01 16:00:00 2024 PST | Fri Feb 02 16:00:00 2024 PST
 _hyper_5_79_chunk | Fri Feb 02 16:00:00 2024 PST | Sat Feb 03 16:00:00 2024 PST
 _hyper_5_80_chunk | Sat Feb 03 16:00:00 2024 PST | Sun Feb 04 16:00:00 2024 PST
 _hyper_5_81_chunk | Sun Feb 04 16:00:00 2024 PST | Mon Feb 05 16:00:00 2024 PST

ROLLBACK;
-- Chunk with unrefreshed data can be dropped directly using DROP TABLE ...
BEGIN;
SELECT format('%I.%I', chunk_schema, chunk_name) AS chunk_to_drop
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start LIMIT 1 \gset
SELECT :'chunk_to_drop' AS dropped_chunk;
              dropped_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_5_71_chunk

DROP TABLE :chunk_to_drop;
SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_5_72_chunk | Mon Jan 01 16:00:00 2024 PST | Tue Jan 02 16:00:00 2024 PST
 _hyper_5_73_chunk | Tue Jan 02 16:00:00 2024 PST | Wed Jan 03 16:00:00 2024 PST
 _hyper_5_74_chunk | Wed Jan 03 16:00:00 2024 PST | Thu Jan 04 16:00:00 2024 PST
 _hyper_5_75_chunk | Thu Jan 04 16:00:00 2024 PST | Fri Jan 05 16:00:00 2024 PST
 _hyper_5_77_chunk | Wed Jan 31 16:00:00 2024 PST | Thu Feb 01 16:00:00 2024 PST
 _hyper_5_78_chunk | Thu Feb 01 16:00:00 2024 PST | Fri Feb 02 16:00:00 2024 PST
 _hyper_5_79_chunk | Fri Feb 02 16:00:00 2024 PST | Sat Feb 03 16:00:00 2024 PST
 _hyper_5_80_chunk | Sat Feb 03 16:00:00 2024 PST | Sun Feb 04 16:00:00 2024 PST
 _hyper_5_81_chunk | Sun Feb 04 16:00:00 2024 PST | Mon Feb 05 16:00:00 2024 PST

ROLLBACK;
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data', older_than => '2024-02-05 17:00:00-07'::timestamp with time zone);
NOTICE:  skipping _timescaledb_internal._hyper_5_75_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_77_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_78_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_79_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_80_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_81_chunk, chunk contains data required for a continuous aggregate refresh
 dropped_count 
---------------
             4

SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_5_75_chunk | Thu Jan 04 16:00:00 2024 PST | Fri Jan 05 16:00:00 2024 PST
 _hyper_5_77_chunk | Wed Jan 31 16:00:00 2024 PST | Thu Feb 01 16:00:00 2024 PST
 _hyper_5_78_chunk | Thu Feb 01 16:00:00 2024 PST | Fri Feb 02 16:00:00 2024 PST
 _hyper_5_79_chunk | Fri Feb 02 16:00:00 2024 PST | Sat Feb 03 16:00:00 2024 PST
 _hyper_5_80_chunk | Sat Feb 03 16:00:00 2024 PST | Sun Feb 04 16:00:00 2024 PST
 _hyper_5_81_chunk | Sun Feb 04 16:00:00 2024 PST | Mon Feb 05 16:00:00 2024 PST

ROLLBACK;
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data', newer_than => '2024-01-02 17:00:00-07'::timestamp with time zone, older_than => '2024-02-02 17:00:00-07'::timestamp with time zone);
NOTICE:  skipping _timescaledb_internal._hyper_5_75_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_77_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_78_chunk, chunk contains data required for a continuous aggregate refresh
 dropped_count 
---------------
             2

SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_5_71_chunk | Sun Dec 31 16:00:00 2023 PST | Mon Jan 01 16:00:00 2024 PST
 _hyper_5_72_chunk | Mon Jan 01 16:00:00 2024 PST | Tue Jan 02 16:00:00 2024 PST
 _hyper_5_75_chunk | Thu Jan 04 16:00:00 2024 PST | Fri Jan 05 16:00:00 2024 PST
 _hyper_5_77_chunk | Wed Jan 31 16:00:00 2024 PST | Thu Feb 01 16:00:00 2024 PST
 _hyper_5_78_chunk | Thu Feb 01 16:00:00 2024 PST | Fri Feb 02 16:00:00 2024 PST
 _hyper_5_79_chunk | Fri Feb 02 16:00:00 2024 PST | Sat Feb 03 16:00:00 2024 PST
 _hyper_5_80_chunk | Sat Feb 03 16:00:00 2024 PST | Sun Feb 04 16:00:00 2024 PST
 _hyper_5_81_chunk | Sun Feb 04 16:00:00 2024 PST | Mon Feb 05 16:00:00 2024 PST

ROLLBACK;
-- Test force option
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data', newer_than => '2023-01-05 17:00:00-07'::timestamp with time zone, force => true);
WARNING:  _timescaledb_internal._hyper_5_75_chunk contained data required for continuous aggregate refresh
WARNING:  _timescaledb_internal._hyper_5_77_chunk contained data required for continuous aggregate refresh
WARNING:  _timescaledb_internal._hyper_5_78_chunk contained data required for continuous aggregate refresh
WARNING:  _timescaledb_internal._hyper_5_79_chunk contained data required for continuous aggregate refresh
WARNING:  _timescaledb_internal._hyper_5_80_chunk contained data required for continuous aggregate refresh
WARNING:  _timescaledb_internal._hyper_5_81_chunk contained data required for continuous aggregate refresh
 dropped_count 
---------------
            10

SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
 chunk_name | range_start | range_end 
------------+-------------+-----------

ROLLBACK;
\set VERBOSITY default
--
-- Test with multiple continuous aggregates to verify earliest watermark is used
--
-- Create a second continuous aggregate on the same hypertable (NOT hierarchical cagg)
CREATE MATERIALIZED VIEW sensor_daily_avg
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 day', time) AS bucket,
    sensor_id,
    AVG(temperature) AS avg_temperature,
    AVG(humidity) AS avg_humidity,
    AVG(pressure) AS avg_pressure,
    COUNT(*) AS reading_count
FROM sensor_data
GROUP BY bucket, sensor_id
WITH NO DATA;
-- Refresh the second aggregate partially to a different point
CALL refresh_continuous_aggregate('sensor_daily_avg', '2024-01-01', '2024-01-03');
SELECT h.id AS mat_hypertable_id_daily
  FROM _timescaledb_catalog.continuous_agg ca
  JOIN _timescaledb_catalog.hypertable h ON h.id = ca.mat_hypertable_id
  WHERE ca.user_view_name = 'sensor_daily_avg' \gset
SELECT _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:mat_hypertable_id)) AS hourly_watermark;
       hourly_watermark       
------------------------------
 Fri Jan 05 05:00:00 2024 PST

SELECT _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:mat_hypertable_id_daily)) AS daily_watermark;
       daily_watermark        
------------------------------
 Tue Jan 02 16:00:00 2024 PST

\set VERBOSITY terse
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data', older_than => '2024-02-05 17:00:00-07'::timestamp with time zone);
NOTICE:  skipping _timescaledb_internal._hyper_5_73_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_74_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_75_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_77_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_78_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_79_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_80_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_81_chunk, chunk contains data required for a continuous aggregate refresh
 dropped_count 
---------------
             2

SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_5_73_chunk | Tue Jan 02 16:00:00 2024 PST | Wed Jan 03 16:00:00 2024 PST
 _hyper_5_74_chunk | Wed Jan 03 16:00:00 2024 PST | Thu Jan 04 16:00:00 2024 PST
 _hyper_5_75_chunk | Thu Jan 04 16:00:00 2024 PST | Fri Jan 05 16:00:00 2024 PST
 _hyper_5_77_chunk | Wed Jan 31 16:00:00 2024 PST | Thu Feb 01 16:00:00 2024 PST
 _hyper_5_78_chunk | Thu Feb 01 16:00:00 2024 PST | Fri Feb 02 16:00:00 2024 PST
 _hyper_5_79_chunk | Fri Feb 02 16:00:00 2024 PST | Sat Feb 03 16:00:00 2024 PST
 _hyper_5_80_chunk | Sat Feb 03 16:00:00 2024 PST | Sun Feb 04 16:00:00 2024 PST
 _hyper_5_81_chunk | Sun Feb 04 16:00:00 2024 PST | Mon Feb 05 16:00:00 2024 PST

ROLLBACK;
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data', newer_than => '2024-01-01 17:00:00-07'::timestamp with time zone, older_than => '2024-02-02 17:00:00-07'::timestamp with time zone);
NOTICE:  skipping _timescaledb_internal._hyper_5_73_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_74_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_75_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_77_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_78_chunk, chunk contains data required for a continuous aggregate refresh
 dropped_count 
---------------
             1

SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_5_71_chunk | Sun Dec 31 16:00:00 2023 PST | Mon Jan 01 16:00:00 2024 PST
 _hyper_5_73_chunk | Tue Jan 02 16:00:00 2024 PST | Wed Jan 03 16:00:00 2024 PST
 _hyper_5_74_chunk | Wed Jan 03 16:00:00 2024 PST | Thu Jan 04 16:00:00 2024 PST
 _hyper_5_75_chunk | Thu Jan 04 16:00:00 2024 PST | Fri Jan 05 16:00:00 2024 PST
 _hyper_5_77_chunk | Wed Jan 31 16:00:00 2024 PST | Thu Feb 01 16:00:00 2024 PST
 _hyper_5_78_chunk | Thu Feb 01 16:00:00 2024 PST | Fri Feb 02 16:00:00 2024 PST
 _hyper_5_79_chunk | Fri Feb 02 16:00:00 2024 PST | Sat Feb 03 16:00:00 2024 PST
 _hyper_5_80_chunk | Sat Feb 03 16:00:00 2024 PST | Sun Feb 04 16:00:00 2024 PST
 _hyper_5_81_chunk | Sun Feb 04 16:00:00 2024 PST | Mon Feb 05 16:00:00 2024 PST

ROLLBACK;
\set VERBOSITY default
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data', newer_than => '2024-01-05 17:00:00-07'::timestamp with time zone, force => true);
WARNING:  _timescaledb_internal._hyper_5_77_chunk contained data required for continuous aggregate refresh
WARNING:  _timescaledb_internal._hyper_5_78_chunk contained data required for continuous aggregate refresh
WARNING:  _timescaledb_internal._hyper_5_79_chunk contained data required for continuous aggregate refresh
WARNING:  _timescaledb_internal._hyper_5_80_chunk contained data required for continuous aggregate refresh
WARNING:  _timescaledb_internal._hyper_5_81_chunk contained data required for continuous aggregate refresh
 dropped_count 
---------------
             5

SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_5_71_chunk | Sun Dec 31 16:00:00 2023 PST | Mon Jan 01 16:00:00 2024 PST
 _hyper_5_72_chunk | Mon Jan 01 16:00:00 2024 PST | Tue Jan 02 16:00:00 2024 PST
 _hyper_5_73_chunk | Tue Jan 02 16:00:00 2024 PST | Wed Jan 03 16:00:00 2024 PST
 _hyper_5_74_chunk | Wed Jan 03 16:00:00 2024 PST | Thu Jan 04 16:00:00 2024 PST
 _hyper_5_75_chunk | Thu Jan 04 16:00:00 2024 PST | Fri Jan 05 16:00:00 2024 PST

ROLLBACK;
\set VERBOSITY default
DROP MATERIALIZED VIEW sensor_daily_avg;
NOTICE:  drop cascades to table _timescaledb_internal._hyper_7_82_chunk
--
-- Test with hierarchical continuous aggregate
--
-- Create hierarchical cagg
CREATE MATERIALIZED VIEW sensor_daily_avg_hier
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 day', bucket) AS bucket,
    sensor_id,
    AVG(avg_temperature) AS avg_temperature,
    AVG(avg_humidity) AS avg_humidity,
    AVG(avg_pressure) AS avg_pressure,
    SUM(reading_count) AS reading_count
FROM sensor_hourly_avg
GROUP BY time_bucket('1 day', bucket), sensor_id
WITH NO DATA;
-- Refresh the hierarchical aggregate partially
CALL refresh_continuous_aggregate('sensor_daily_avg_hier', NULL, '2024-01-03');
-- Verify watermarks
SELECT h.id AS mat_hypertable_id_daily_hier
  FROM _timescaledb_catalog.continuous_agg ca
  JOIN _timescaledb_catalog.hypertable h ON h.id = ca.mat_hypertable_id
  WHERE ca.user_view_name = 'sensor_daily_avg_hier' \gset
SELECT _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:mat_hypertable_id)) AS hourly_watermark;
       hourly_watermark       
------------------------------
 Fri Jan 05 05:00:00 2024 PST

SELECT _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:mat_hypertable_id_daily_hier)) AS daily_hierarchical_watermark;
 daily_hierarchical_watermark 
------------------------------
 Tue Jan 02 16:00:00 2024 PST

\set VERBOSITY terse
BEGIN;
-- With hierarchical cagg, drop_chunks should still use the earliest watermark from the raw hypertable's caggs
-- The hierarchical cagg watermark should not affect raw hypertable chunk retention
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data', older_than => '2024-02-05 17:00:00-07'::timestamp with time zone);
NOTICE:  skipping _timescaledb_internal._hyper_5_75_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_77_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_78_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_79_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_80_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_81_chunk, chunk contains data required for a continuous aggregate refresh
 dropped_count 
---------------
             4

SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_5_75_chunk | Thu Jan 04 16:00:00 2024 PST | Fri Jan 05 16:00:00 2024 PST
 _hyper_5_77_chunk | Wed Jan 31 16:00:00 2024 PST | Thu Feb 01 16:00:00 2024 PST
 _hyper_5_78_chunk | Thu Feb 01 16:00:00 2024 PST | Fri Feb 02 16:00:00 2024 PST
 _hyper_5_79_chunk | Fri Feb 02 16:00:00 2024 PST | Sat Feb 03 16:00:00 2024 PST
 _hyper_5_80_chunk | Sat Feb 03 16:00:00 2024 PST | Sun Feb 04 16:00:00 2024 PST
 _hyper_5_81_chunk | Sun Feb 04 16:00:00 2024 PST | Mon Feb 05 16:00:00 2024 PST

ROLLBACK;
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data', newer_than => '2024-01-01 17:00:00-07'::timestamp with time zone, older_than => '2024-02-02 17:00:00-07'::timestamp with time zone);
NOTICE:  skipping _timescaledb_internal._hyper_5_75_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_77_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_5_78_chunk, chunk contains data required for a continuous aggregate refresh
 dropped_count 
---------------
             3

SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data'
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_5_71_chunk | Sun Dec 31 16:00:00 2023 PST | Mon Jan 01 16:00:00 2024 PST
 _hyper_5_75_chunk | Thu Jan 04 16:00:00 2024 PST | Fri Jan 05 16:00:00 2024 PST
 _hyper_5_77_chunk | Wed Jan 31 16:00:00 2024 PST | Thu Feb 01 16:00:00 2024 PST
 _hyper_5_78_chunk | Thu Feb 01 16:00:00 2024 PST | Fri Feb 02 16:00:00 2024 PST
 _hyper_5_79_chunk | Fri Feb 02 16:00:00 2024 PST | Sat Feb 03 16:00:00 2024 PST
 _hyper_5_80_chunk | Sat Feb 03 16:00:00 2024 PST | Sun Feb 04 16:00:00 2024 PST
 _hyper_5_81_chunk | Sun Feb 04 16:00:00 2024 PST | Mon Feb 05 16:00:00 2024 PST

ROLLBACK;
\set VERBOSITY default
-- Try drop_chunks on base cagg in the case of hierarchical caggs
-- Here, the watermark of the hierarchical CAgg matters but the base CAgg watermark shouldn't affect it
CALL refresh_continuous_aggregate('sensor_hourly_avg', NULL, NULL);
SELECT _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:mat_hypertable_id)) AS hourly_watermark;
       hourly_watermark       
------------------------------
 Mon Feb 05 05:00:00 2024 PST

SELECT _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:mat_hypertable_id_daily_hier)) AS daily_hierarchical_watermark;
 daily_hierarchical_watermark 
------------------------------
 Tue Jan 02 16:00:00 2024 PST

BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_hourly_avg', older_than => '2024-01-10 17:00:00-07'::timestamp with time zone);
NOTICE:  skipping _timescaledb_internal._hyper_6_76_chunk, chunk contains data required for a continuous aggregate refresh
HINT:  To drop this chunk, refresh all continuous aggregates on this hypertable till Sun Jan 07 16:00:00 2024 PST, or specify force=>true
 dropped_count 
---------------
             0

 SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = (
      SELECT h.table_name
      FROM _timescaledb_catalog.continuous_agg ca
      JOIN _timescaledb_catalog.hypertable h ON
  h.id = ca.mat_hypertable_id
      WHERE ca.user_view_name = 'sensor_hourly_avg'
  )
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_6_76_chunk | Thu Dec 28 16:00:00 2023 PST | Sun Jan 07 16:00:00 2024 PST
 _hyper_6_84_chunk | Sat Jan 27 16:00:00 2024 PST | Tue Feb 06 16:00:00 2024 PST

ROLLBACK;
-- Test force option
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_hourly_avg', older_than => '2024-01-10 17:00:00-07'::timestamp with time zone, force => true);
WARNING:  _timescaledb_internal._hyper_6_76_chunk contained data required for continuous aggregate refresh
 dropped_count 
---------------
             1

 SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = (
      SELECT h.table_name
      FROM _timescaledb_catalog.continuous_agg ca
      JOIN _timescaledb_catalog.hypertable h ON
  h.id = ca.mat_hypertable_id
      WHERE ca.user_view_name = 'sensor_hourly_avg'
  )
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_6_84_chunk | Sat Jan 27 16:00:00 2024 PST | Tue Feb 06 16:00:00 2024 PST

ROLLBACK;
-- Refresh hierarchical cagg completely
CALL refresh_continuous_aggregate('sensor_daily_avg_hier', NULL, NULL);
SELECT _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:mat_hypertable_id_daily_hier)) AS daily_hierarchical_watermark;
 daily_hierarchical_watermark 
------------------------------
 Mon Feb 05 16:00:00 2024 PST

BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_hourly_avg', older_than => '2024-01-10 17:00:00-07'::timestamp with time zone);
 dropped_count 
---------------
             1

 SELECT chunk_name, range_start, range_end
  FROM timescaledb_information.chunks
  WHERE hypertable_name = (
      SELECT h.table_name
      FROM _timescaledb_catalog.continuous_agg ca
      JOIN _timescaledb_catalog.hypertable h ON
  h.id = ca.mat_hypertable_id
      WHERE ca.user_view_name = 'sensor_hourly_avg'
  )
  ORDER BY range_start;
    chunk_name     |         range_start          |          range_end           
-------------------+------------------------------+------------------------------
 _hyper_6_84_chunk | Sat Jan 27 16:00:00 2024 PST | Tue Feb 06 16:00:00 2024 PST

ROLLBACK;
DROP MATERIALIZED VIEW sensor_daily_avg_hier;
NOTICE:  drop cascades to 2 other objects
DETAIL:  drop cascades to table _timescaledb_internal._hyper_8_83_chunk
drop cascades to table _timescaledb_internal._hyper_8_85_chunk
DROP MATERIALIZED VIEW sensor_hourly_avg;
NOTICE:  drop cascades to 2 other objects
DETAIL:  drop cascades to table _timescaledb_internal._hyper_6_76_chunk
drop cascades to table _timescaledb_internal._hyper_6_84_chunk
DROP TABLE sensor_data;
--
-- Test drop_chunks with integer time continuous aggregates
--
CREATE OR REPLACE FUNCTION integer_now_sensor_data() returns INT LANGUAGE SQL STABLE as
    $$ SELECT 150 $$;
CREATE TABLE sensor_data_int (
    time_int INT NOT NULL,
    sensor_id INTEGER NOT NULL,
    temperature DOUBLE PRECISION,
    humidity DOUBLE PRECISION,
    pressure DOUBLE PRECISION
);
SELECT create_hypertable('sensor_data_int', 'time_int',
    chunk_time_interval => 10
);
      create_hypertable       
------------------------------
 (9,public,sensor_data_int,t)

SELECT set_integer_now_func('sensor_data_int', 'integer_now_sensor_data');
 set_integer_now_func 
----------------------
 

INSERT INTO sensor_data_int
SELECT
    i AS time_int,
    (i % 5) + 1 AS sensor_id,
    15 + 15 * random() AS temperature,
    30 + 60 * random() AS humidity,
    980 + 40 * random() AS pressure
FROM generate_series(0, 99, 4) AS i;
CREATE MATERIALIZED VIEW sensor_hourly_avg_int
WITH (timescaledb.continuous) AS
SELECT
    time_bucket(5, time_int) AS bucket,
    sensor_id,
    AVG(temperature) AS avg_temperature,
    AVG(humidity) AS avg_humidity,
    AVG(pressure) AS avg_pressure,
    COUNT(*) AS reading_count
FROM sensor_data_int
GROUP BY bucket, sensor_id
WITH NO DATA;
-- Check range start and end for chunks
SELECT chunk_name, range_start_integer, range_end_integer
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data_int'
  ORDER BY range_start_integer;
    chunk_name     | range_start_integer | range_end_integer 
-------------------+---------------------+-------------------
 _hyper_9_86_chunk |                   0 |                10
 _hyper_9_87_chunk |                  10 |                20
 _hyper_9_88_chunk |                  20 |                30
 _hyper_9_89_chunk |                  30 |                40
 _hyper_9_90_chunk |                  40 |                50
 _hyper_9_91_chunk |                  50 |                60
 _hyper_9_92_chunk |                  60 |                70
 _hyper_9_93_chunk |                  70 |                80
 _hyper_9_94_chunk |                  80 |                90
 _hyper_9_95_chunk |                  90 |               100

-- Refresh the aggregate completely
CALL refresh_continuous_aggregate('sensor_hourly_avg_int', NULL, NULL);
SELECT count(*) AS ht_before FROM show_chunks('sensor_data_int');
 ht_before 
-----------
        10

-- Insert more data after the CAgg watermark
INSERT INTO sensor_data_int
SELECT
    i AS time_int,
    (i % 5) + 1 AS sensor_id,
    15 + 15 * random() AS temperature,
    30 + 60 * random() AS humidity,
    980 + 40 * random() AS pressure
FROM generate_series(100, 199, 4) AS i;
-- View ranges before drop chunks
SELECT chunk_name, range_start_integer, range_end_integer
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data_int'
  ORDER BY range_start_integer;
     chunk_name     | range_start_integer | range_end_integer 
--------------------+---------------------+-------------------
 _hyper_9_86_chunk  |                   0 |                10
 _hyper_9_87_chunk  |                  10 |                20
 _hyper_9_88_chunk  |                  20 |                30
 _hyper_9_89_chunk  |                  30 |                40
 _hyper_9_90_chunk  |                  40 |                50
 _hyper_9_91_chunk  |                  50 |                60
 _hyper_9_92_chunk  |                  60 |                70
 _hyper_9_93_chunk  |                  70 |                80
 _hyper_9_94_chunk  |                  80 |                90
 _hyper_9_95_chunk  |                  90 |               100
 _hyper_9_97_chunk  |                 100 |               110
 _hyper_9_98_chunk  |                 110 |               120
 _hyper_9_99_chunk  |                 120 |               130
 _hyper_9_100_chunk |                 130 |               140
 _hyper_9_101_chunk |                 140 |               150
 _hyper_9_102_chunk |                 150 |               160
 _hyper_9_103_chunk |                 160 |               170
 _hyper_9_104_chunk |                 170 |               180
 _hyper_9_105_chunk |                 180 |               190
 _hyper_9_106_chunk |                 190 |               200

-- Verify watermark
SELECT h.id AS mat_hypertable_id_int
  FROM _timescaledb_catalog.continuous_agg ca
  JOIN _timescaledb_catalog.hypertable h ON h.id = ca.mat_hypertable_id
  WHERE ca.user_view_name = 'sensor_hourly_avg_int' \gset
SELECT _timescaledb_functions.cagg_watermark(:mat_hypertable_id_int);
 cagg_watermark 
----------------
            100

\set VERBOSITY terse
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data_int', newer_than => 0);
NOTICE:  skipping _timescaledb_internal._hyper_9_97_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_9_98_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_9_99_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_9_100_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_9_101_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_9_102_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_9_103_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_9_104_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_9_105_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_9_106_chunk, chunk contains data required for a continuous aggregate refresh
 dropped_count 
---------------
            10

SELECT chunk_name, range_start_integer, range_end_integer
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data_int'
  ORDER BY range_start_integer;
     chunk_name     | range_start_integer | range_end_integer 
--------------------+---------------------+-------------------
 _hyper_9_97_chunk  |                 100 |               110
 _hyper_9_98_chunk  |                 110 |               120
 _hyper_9_99_chunk  |                 120 |               130
 _hyper_9_100_chunk |                 130 |               140
 _hyper_9_101_chunk |                 140 |               150
 _hyper_9_102_chunk |                 150 |               160
 _hyper_9_103_chunk |                 160 |               170
 _hyper_9_104_chunk |                 170 |               180
 _hyper_9_105_chunk |                 180 |               190
 _hyper_9_106_chunk |                 190 |               200

ROLLBACK;
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data_int', older_than => 120);
NOTICE:  skipping _timescaledb_internal._hyper_9_97_chunk, chunk contains data required for a continuous aggregate refresh
NOTICE:  skipping _timescaledb_internal._hyper_9_98_chunk, chunk contains data required for a continuous aggregate refresh
 dropped_count 
---------------
            10

SELECT chunk_name, range_start_integer, range_end_integer
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data_int'
  ORDER BY range_start_integer;
     chunk_name     | range_start_integer | range_end_integer 
--------------------+---------------------+-------------------
 _hyper_9_97_chunk  |                 100 |               110
 _hyper_9_98_chunk  |                 110 |               120
 _hyper_9_99_chunk  |                 120 |               130
 _hyper_9_100_chunk |                 130 |               140
 _hyper_9_101_chunk |                 140 |               150
 _hyper_9_102_chunk |                 150 |               160
 _hyper_9_103_chunk |                 160 |               170
 _hyper_9_104_chunk |                 170 |               180
 _hyper_9_105_chunk |                 180 |               190
 _hyper_9_106_chunk |                 190 |               200

ROLLBACK;
BEGIN;
SELECT count(*) AS dropped_count FROM drop_chunks('sensor_data_int', newer_than => 10, older_than => 110);
NOTICE:  skipping _timescaledb_internal._hyper_9_97_chunk, chunk contains data required for a continuous aggregate refresh
 dropped_count 
---------------
             9

SELECT chunk_name, range_start_integer, range_end_integer
  FROM timescaledb_information.chunks
  WHERE hypertable_name = 'sensor_data_int'
  ORDER BY range_start_integer;
     chunk_name     | range_start_integer | range_end_integer 
--------------------+---------------------+-------------------
 _hyper_9_86_chunk  |                   0 |                10
 _hyper_9_97_chunk  |                 100 |               110
 _hyper_9_98_chunk  |                 110 |               120
 _hyper_9_99_chunk  |                 120 |               130
 _hyper_9_100_chunk |                 130 |               140
 _hyper_9_101_chunk |                 140 |               150
 _hyper_9_102_chunk |                 150 |               160
 _hyper_9_103_chunk |                 160 |               170
 _hyper_9_104_chunk |                 170 |               180
 _hyper_9_105_chunk |                 180 |               190
 _hyper_9_106_chunk |                 190 |               200

ROLLBACK;
\set VERBOSITY default
DROP MATERIALIZED VIEW sensor_hourly_avg_int;
NOTICE:  drop cascades to table _timescaledb_internal._hyper_10_96_chunk
DROP TABLE sensor_data_int;
