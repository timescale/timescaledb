-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
SET timescaledb.arrow_cache_maxsize = 4;
CREATE TABLE readings(
       time timestamptz UNIQUE,
       location int,
       device int,
       temp numeric(4,1),
       humidity float
);
SELECT create_hypertable('readings', 'time');
NOTICE:  adding not-null constraint to column "time"
   create_hypertable   
-----------------------
 (1,public,readings,t)
(1 row)

-- Disable incremental sort to make tests stable
SET enable_incremental_sort = false;
SELECT setseed(1);
 setseed 
---------
 
(1 row)

INSERT INTO readings (time, location, device, temp, humidity)
SELECT t, ceil(random()*10), ceil(random()*30), random()*40, random()*100
FROM generate_series('2022-06-01'::timestamptz, '2022-07-01', '5s') t;
ALTER TABLE readings SET (
	  timescaledb.compress,
	  timescaledb.compress_orderby = 'time',
	  timescaledb.compress_segmentby = 'device'
);
-- Set some test chunks as global variables
SELECT format('%I.%I', chunk_schema, chunk_name)::regclass AS chunk
  FROM timescaledb_information.chunks
 WHERE format('%I.%I', hypertable_schema, hypertable_name)::regclass = 'readings'::regclass
 LIMIT 1 \gset
SELECT format('%I.%I', chunk_schema, chunk_name)::regclass AS chunk2
  FROM timescaledb_information.chunks
 WHERE format('%I.%I', hypertable_schema, hypertable_name)::regclass = 'readings'::regclass
 ORDER BY chunk2 DESC
 LIMIT 1 \gset
-- We do some basic checks that the compressed data is the same as the
-- uncompressed. In this case, we just count the rows for each device.
SELECT device, count(*) INTO orig FROM readings GROUP BY device;
-- Initially an index on time
SELECT * FROM test.show_indexes(:'chunk');
                     Index                     | Columns | Expr | Unique | Primary | Exclusion | Tablespace 
-----------------------------------------------+---------+------+--------+---------+-----------+------------
 _timescaledb_internal."1_1_readings_time_key" | {time}  |      | t      | f       | f         | 
(1 row)

EXPLAIN (verbose, costs off)
SELECT count(*) FROM :chunk
WHERE time = '2022-06-01'::timestamptz;
                                                QUERY PLAN                                                
----------------------------------------------------------------------------------------------------------
 Aggregate
   Output: count(*)
   ->  Index Only Scan using "1_1_readings_time_key" on _timescaledb_internal._hyper_1_1_chunk
         Output: "time"
         Index Cond: (_hyper_1_1_chunk."time" = 'Wed Jun 01 00:00:00 2022 PDT'::timestamp with time zone)
(5 rows)

SELECT count(*) FROM :chunk
WHERE time = '2022-06-01'::timestamptz;
 count 
-------
     1
(1 row)

SELECT count(*) FROM :chunk
WHERE location = 1;
 count 
-------
  1211
(1 row)

-- We should be able to set the table access method for a chunk, which
-- will automatically compress the chunk.
ALTER TABLE :chunk SET ACCESS METHOD hyperstore;
SET timescaledb.enable_transparent_decompression TO false;
vacuum analyze readings;
-- Show access method used on chunk
SELECT c.relname, a.amname FROM pg_class c
INNER JOIN pg_am a ON (c.relam = a.oid)
WHERE c.oid = :'chunk'::regclass;
     relname      |   amname   
------------------+------------
 _hyper_1_1_chunk | hyperstore
(1 row)

-- This should show the chunk as compressed
SELECT chunk_name FROM chunk_compression_stats('readings') WHERE compression_status='Compressed';
    chunk_name    
------------------
 _hyper_1_1_chunk
(1 row)

-- Should give the same result as above
SELECT device, count(*) INTO comp FROM readings GROUP BY device;
-- Row counts for each device should match, so this should be empty.
SELECT device FROM orig JOIN comp USING (device) WHERE orig.count != comp.count;
 device 
--------
(0 rows)

EXPLAIN (verbose, costs off)
SELECT count(*) FROM :chunk
WHERE time = '2022-06-01'::timestamptz;
                                                QUERY PLAN                                                
----------------------------------------------------------------------------------------------------------
 Aggregate
   Output: count(*)
   ->  Index Only Scan using "1_1_readings_time_key" on _timescaledb_internal._hyper_1_1_chunk
         Output: "time"
         Index Cond: (_hyper_1_1_chunk."time" = 'Wed Jun 01 00:00:00 2022 PDT'::timestamp with time zone)
(5 rows)

SELECT count(*) FROM :chunk
WHERE time = '2022-06-01'::timestamptz;
 count 
-------
     1
(1 row)

-- Create a new index on a compressed column
CREATE INDEX ON readings (location);
-- Index added on location
SELECT * FROM test.show_indexes(:'chunk');
                            Index                             |  Columns   | Expr | Unique | Primary | Exclusion | Tablespace 
--------------------------------------------------------------+------------+------+--------+---------+-----------+------------
 _timescaledb_internal."1_1_readings_time_key"                | {time}     |      | t      | f       | f         | 
 _timescaledb_internal._hyper_1_1_chunk_readings_location_idx | {location} |      | f      | f       | f         | 
(2 rows)

-- Query by location should be an index scan
EXPLAIN (verbose, costs off)
SELECT count(*) FROM :chunk
WHERE location = 1;
                                                  QUERY PLAN                                                  
--------------------------------------------------------------------------------------------------------------
 Aggregate
   Output: count(*)
   ->  Index Only Scan using _hyper_1_1_chunk_readings_location_idx on _timescaledb_internal._hyper_1_1_chunk
         Output: location
         Index Cond: (_hyper_1_1_chunk.location = 1)
(5 rows)

-- Count by location should be the same as non-index scan before
-- compression above
SELECT count(*) FROM :chunk
WHERE location = 1;
 count 
-------
  1211
(1 row)

SET enable_indexscan = false;
-- Columnar scan with qual on segmentby where filtering should be
-- turned into scankeys
EXPLAIN (costs off, timing off, summary off)
SELECT * FROM :chunk WHERE device < 4 ORDER BY time, device LIMIT 5;
                         QUERY PLAN                         
------------------------------------------------------------
 Limit
   ->  Sort
         Sort Key: "time", device
         ->  Custom Scan (ColumnarScan) on _hyper_1_1_chunk
               Scankey: (device < 4)
(5 rows)

SELECT * FROM :chunk WHERE device < 4 ORDER BY time, device LIMIT 5;
             time             | location | device | temp |     humidity     
------------------------------+----------+--------+------+------------------
 Wed Jun 01 00:00:55 2022 PDT |        1 |      1 | 18.1 | 93.2399098726618
 Wed Jun 01 00:02:50 2022 PDT |        6 |      2 |  3.4 | 79.4169433908854
 Wed Jun 01 00:03:15 2022 PDT |        2 |      2 | 32.4 | 43.4716481956856
 Wed Jun 01 00:03:35 2022 PDT |        9 |      3 | 37.1 | 29.4121735958255
 Wed Jun 01 00:05:05 2022 PDT |        2 |      1 | 23.9 | 29.1861844182151
(5 rows)

-- Show with indexscan
SET enable_indexscan = true;
EXPLAIN (costs off, timing off, summary off)
SELECT * FROM :chunk WHERE device < 4 ORDER BY time, device LIMIT 5;
                         QUERY PLAN                         
------------------------------------------------------------
 Limit
   ->  Sort
         Sort Key: "time", device
         ->  Custom Scan (ColumnarScan) on _hyper_1_1_chunk
               Scankey: (device < 4)
(5 rows)

SELECT * FROM :chunk WHERE device < 4 ORDER BY time, device LIMIT 5;
             time             | location | device | temp |     humidity     
------------------------------+----------+--------+------+------------------
 Wed Jun 01 00:00:55 2022 PDT |        1 |      1 | 18.1 | 93.2399098726618
 Wed Jun 01 00:02:50 2022 PDT |        6 |      2 |  3.4 | 79.4169433908854
 Wed Jun 01 00:03:15 2022 PDT |        2 |      2 | 32.4 | 43.4716481956856
 Wed Jun 01 00:03:35 2022 PDT |        9 |      3 | 37.1 | 29.4121735958255
 Wed Jun 01 00:05:05 2022 PDT |        2 |      1 | 23.9 | 29.1861844182151
(5 rows)

SET enable_indexscan = false;
-- Compare the output to transparent decompression. Heap output is
-- shown further down.
SET timescaledb.enable_transparent_decompression TO 'hyperstore';
EXPLAIN (costs off, timing off, summary off)
SELECT * FROM :chunk WHERE device < 4 ORDER BY time, device LIMIT 5;
                             QUERY PLAN                             
--------------------------------------------------------------------
 Limit
   ->  Sort
         Sort Key: _hyper_1_1_chunk."time", _hyper_1_1_chunk.device
         ->  Custom Scan (DecompressChunk) on _hyper_1_1_chunk
               ->  Seq Scan on compress_hyper_2_7_chunk
                     Filter: (device < 4)
(6 rows)

SELECT * FROM :chunk WHERE device < 4 ORDER BY time, device LIMIT 5;
             time             | location | device | temp |     humidity     
------------------------------+----------+--------+------+------------------
 Wed Jun 01 00:00:55 2022 PDT |        1 |      1 | 18.1 | 93.2399098726618
 Wed Jun 01 00:02:50 2022 PDT |        6 |      2 |  3.4 | 79.4169433908854
 Wed Jun 01 00:03:15 2022 PDT |        2 |      2 | 32.4 | 43.4716481956856
 Wed Jun 01 00:03:35 2022 PDT |        9 |      3 | 37.1 | 29.4121735958255
 Wed Jun 01 00:05:05 2022 PDT |        2 |      1 | 23.9 | 29.1861844182151
(5 rows)

SET timescaledb.enable_transparent_decompression TO false;
-- Qual on compressed column with index
EXPLAIN (costs off, timing off, summary off)
SELECT * FROM :chunk WHERE location < 4 ORDER BY time, device LIMIT 5;
                         QUERY PLAN                         
------------------------------------------------------------
 Limit
   ->  Sort
         Sort Key: "time", device
         ->  Custom Scan (ColumnarScan) on _hyper_1_1_chunk
               Vectorized Filter: (location < 4)
(5 rows)

SELECT * FROM :chunk WHERE location < 4 ORDER BY time, device LIMIT 5;
             time             | location | device | temp |     humidity     
------------------------------+----------+--------+------+------------------
 Wed Jun 01 00:00:25 2022 PDT |        3 |      5 | 23.5 |  76.360064629636
 Wed Jun 01 00:00:30 2022 PDT |        3 |     19 |  8.3 | 10.2100470173341
 Wed Jun 01 00:00:55 2022 PDT |        1 |      1 | 18.1 | 93.2399098726618
 Wed Jun 01 00:01:05 2022 PDT |        3 |      7 |  1.4 | 13.8143608776025
 Wed Jun 01 00:01:20 2022 PDT |        2 |     16 | 10.2 | 32.6534412097854
(5 rows)

-- With index scan
SET enable_indexscan = true;
EXPLAIN (costs off, timing off, summary off)
SELECT * FROM :chunk WHERE location < 4 ORDER BY time, device LIMIT 5;
                                       QUERY PLAN                                        
-----------------------------------------------------------------------------------------
 Limit
   ->  Sort
         Sort Key: "time", device
         ->  Index Scan using _hyper_1_1_chunk_readings_location_idx on _hyper_1_1_chunk
               Index Cond: (location < 4)
(5 rows)

SELECT * FROM :chunk WHERE location < 4 ORDER BY time, device LIMIT 5;
             time             | location | device | temp |     humidity     
------------------------------+----------+--------+------+------------------
 Wed Jun 01 00:00:25 2022 PDT |        3 |      5 | 23.5 |  76.360064629636
 Wed Jun 01 00:00:30 2022 PDT |        3 |     19 |  8.3 | 10.2100470173341
 Wed Jun 01 00:00:55 2022 PDT |        1 |      1 | 18.1 | 93.2399098726618
 Wed Jun 01 00:01:05 2022 PDT |        3 |      7 |  1.4 | 13.8143608776025
 Wed Jun 01 00:01:20 2022 PDT |        2 |     16 | 10.2 | 32.6534412097854
(5 rows)

SET enable_indexscan = false;
-- With transparent decompression
SET timescaledb.enable_transparent_decompression TO 'hyperstore';
SELECT * FROM :chunk WHERE location < 4 ORDER BY time, device LIMIT 5;
             time             | location | device | temp |     humidity     
------------------------------+----------+--------+------+------------------
 Wed Jun 01 00:00:25 2022 PDT |        3 |      5 | 23.5 |  76.360064629636
 Wed Jun 01 00:00:30 2022 PDT |        3 |     19 |  8.3 | 10.2100470173341
 Wed Jun 01 00:00:55 2022 PDT |        1 |      1 | 18.1 | 93.2399098726618
 Wed Jun 01 00:01:05 2022 PDT |        3 |      7 |  1.4 | 13.8143608776025
 Wed Jun 01 00:01:20 2022 PDT |        2 |     16 | 10.2 | 32.6534412097854
(5 rows)

SET timescaledb.enable_transparent_decompression TO false;
-- Ordering on compressed column that has index
SET enable_indexscan = true;
EXPLAIN (costs off, timing off, summary off)
SELECT * FROM :chunk ORDER BY location ASC LIMIT 5;
                                    QUERY PLAN                                     
-----------------------------------------------------------------------------------
 Limit
   ->  Index Scan using _hyper_1_1_chunk_readings_location_idx on _hyper_1_1_chunk
(2 rows)

SELECT * FROM :chunk ORDER BY location ASC LIMIT 5;
             time             | location | device | temp |     humidity     
------------------------------+----------+--------+------+------------------
 Wed Jun 01 00:00:55 2022 PDT |        1 |      1 | 18.1 | 93.2399098726618
 Wed Jun 01 00:12:45 2022 PDT |        1 |      1 | 13.2 | 86.7500491115748
 Wed Jun 01 01:19:50 2022 PDT |        1 |      1 | 29.5 | 2.56533840018596
 Wed Jun 01 01:44:35 2022 PDT |        1 |      1 |  1.1 | 81.9018703001777
 Wed Jun 01 02:22:45 2022 PDT |        1 |      1 | 32.3 |  46.457827923454
(5 rows)

-- Show with transparent decompression
SET timescaledb.enable_transparent_decompression TO 'hyperstore';
SELECT * FROM :chunk ORDER BY location ASC LIMIT 5;
             time             | location | device | temp |     humidity     
------------------------------+----------+--------+------+------------------
 Wed Jun 01 01:19:50 2022 PDT |        1 |      1 | 29.5 | 2.56533840018596
 Wed Jun 01 01:44:35 2022 PDT |        1 |      1 |  1.1 | 81.9018703001777
 Wed Jun 01 00:00:55 2022 PDT |        1 |      1 | 18.1 | 93.2399098726618
 Wed Jun 01 00:12:45 2022 PDT |        1 |      1 | 13.2 | 86.7500491115748
 Wed Jun 01 02:22:45 2022 PDT |        1 |      1 | 32.3 |  46.457827923454
(5 rows)

SET timescaledb.enable_transparent_decompression TO false;
--
-- Test ANALYZE.
--
-- First create a separate regular table with the chunk data as a
-- reference of accurate stats. Analyze it and compare with analyze
-- on the original chunk.
--
CREATE TABLE chunk_data (LIKE :chunk);
INSERT INTO chunk_data SELECT * FROM :chunk;
ANALYZE chunk_data;
CREATE VIEW chunk_data_relstats AS
SELECT relname, reltuples, relpages
FROM pg_class
WHERE oid = 'chunk_data'::regclass;
CREATE VIEW chunk_data_attrstats AS
SELECT attname, n_distinct, array_to_string(most_common_vals, E',') AS most_common_vals
FROM pg_stats
WHERE format('%I.%I', schemaname, tablename)::regclass = 'chunk_data'::regclass
ORDER BY attname;
SELECT * FROM chunk_data_relstats;
  relname   | reltuples | relpages 
------------+-----------+----------
 chunk_data |     12240 |       90
(1 row)

SELECT * FROM chunk_data_attrstats ORDER BY attname;
 attname  | n_distinct |                                                                                                                                                                                                                                      most_common_vals                                                                                                                                                                                                                                       
----------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 device   |         30 | 26,5,18,21,23,1,3,16,24,30,10,19,9,14,28,13,27,7,2,6,20,22,25,17,4,8,12,15,29,11
 humidity |         -1 | 
 location |         10 | 3,9,10,2,1,6,8,7,5,4
 temp     |        401 | 10.1,14.7,20.9,10.6,18.7,36.2,4.8,17.9,7.4,15.7,17.6,22.7,29.1,30.8,36.3,0.9,1.7,2.9,3.4,16.4,23.0,29.5,31.5,31.6,3.9,12.5,15.8,21.3,22.2,28.1,29.3,33.9,34.4,36.8,37.3,38.3,20.1,29.0,31.2,31.3,32.2,36.9,2.7,5.9,9.1,11.2,18.8,19.6,20.7,23.8,23.9,26.3,30.2,31.9,33.0,33.6,35.1,38.9,4.2,5.0,7.1,8.9,10.5,12.8,13.1,13.5,17.8,24.1,24.6,26.9,28.0,37.9,38.1,0.5,0.7,2.3,9.3,12.2,14.3,19.9,21.7,22.9,25.7,26.7,29.8,30.7,32.5,33.1,34.3,35.0,36.7,37.0,38.4,38.8,0.2,1.1,1.6,1.9,2.5,4.3
 time     |         -1 | 
(5 rows)

-- Stats on compressed chunk before ANALYZE. Note that this chunk is
-- partially compressed
SELECT relname, reltuples, relpages
FROM pg_class
WHERE oid = :'chunk'::regclass;
     relname      | reltuples | relpages 
------------------+-----------+----------
 _hyper_1_1_chunk |     12240 |        1
(1 row)

SELECT attname, n_distinct, array_to_string(most_common_vals, E',') AS most_common_vals
FROM pg_stats
WHERE format('%I.%I', schemaname, tablename)::regclass = :'chunk'::regclass
ORDER BY attname;
 attname  | n_distinct |                                                                                                                                                                                                                                      most_common_vals                                                                                                                                                                                                                                       
----------+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 device   |         30 | 26,5,18,21,23,1,3,16,24,30,10,19,9,14,28,13,27,7,2,6,20,22,25,17,4,8,12,15,29,11
 humidity |         -1 | 
 location |         10 | 3,9,10,2,1,6,8,7,5,4
 temp     |        401 | 10.1,14.7,20.9,10.6,18.7,36.2,4.8,17.9,7.4,15.7,17.6,22.7,29.1,30.8,36.3,0.9,1.7,2.9,3.4,16.4,23.0,29.5,31.5,31.6,3.9,12.5,15.8,21.3,22.2,28.1,29.3,33.9,34.4,36.8,37.3,38.3,20.1,29.0,31.2,31.3,32.2,36.9,2.7,5.9,9.1,11.2,18.8,19.6,20.7,23.8,23.9,26.3,30.2,31.9,33.0,33.6,35.1,38.9,4.2,5.0,7.1,8.9,10.5,12.8,13.1,13.5,17.8,24.1,24.6,26.9,28.0,37.9,38.1,0.5,0.7,2.3,9.3,12.2,14.3,19.9,21.7,22.9,25.7,26.7,29.8,30.7,32.5,33.1,34.3,35.0,36.7,37.0,38.4,38.8,0.2,1.1,1.6,1.9,2.5,4.3
 time     |         -1 | 
(5 rows)

-- ANALYZE directly on chunk
ANALYZE :chunk;
-- Stats after ANALYZE. Show rows that differ. The number of relpages
-- will differ because the chunk is compressed and uses less pages.
SELECT relname, reltuples, relpages
FROM pg_class
WHERE oid = :'chunk'::regclass;
     relname      | reltuples | relpages 
------------------+-----------+----------
 _hyper_1_1_chunk |     12240 |        1
(1 row)

-- There should be no difference in attrstats, so EXCEPT query should
-- show no results
SELECT attname, n_distinct, array_to_string(most_common_vals, E',') AS most_common_vals
FROM pg_stats
WHERE format('%I.%I', schemaname, tablename)::regclass = :'chunk'::regclass
EXCEPT
SELECT * FROM chunk_data_attrstats
ORDER BY attname;
 attname | n_distinct | most_common_vals 
---------+------------+------------------
(0 rows)

-- ANALYZE also via hypertable root and show that it will
-- recurse to another chunk
ALTER TABLE :chunk2 SET ACCESS METHOD hyperstore;
SELECT relname, reltuples, relpages
FROM pg_class
WHERE oid = :'chunk2'::regclass;
     relname      | reltuples | relpages 
------------------+-----------+----------
 _hyper_1_6_chunk |     22321 |        1
(1 row)

SELECT attname, n_distinct, array_to_string(most_common_vals, E',') AS most_common_vals
FROM pg_stats
WHERE format('%I.%I', schemaname, tablename)::regclass = :'chunk2'::regclass
ORDER BY attname;
 attname  | n_distinct |                                                                                                                                                                                                                                    most_common_vals                                                                                                                                                                                                                                     
----------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 device   |         30 | 14,11,27,4,21,12,3,19,29,24,5,1,10,22,17,7,13,8,23,18,20,28,9,2,16,26,25,6,30,15
 humidity |         -1 | 
 location |         10 | 7,4,5,10,2,3,1,6,8,9
 temp     |        401 | 4.9,31.7,1.6,28.8,5.2,2.3,6.9,11.2,26.6,5.9,37.3,36.5,32.2,14.3,26.5,37.4,16.6,18.7,12.0,12.9,16.3,19.9,24.8,27.6,27.7,28.2,30.8,1.2,8.2,11.7,17.1,23.4,2.5,2.8,15.5,19.8,23.3,25.9,27.2,38.0,1.4,3.9,7.0,11.4,12.7,13.7,15.7,23.7,29.6,30.0,35.7,36.3,37.7,38.9,0.4,15.3,26.2,4.4,9.1,9.5,10.8,16.4,16.8,23.2,25.7,25.8,26.9,36.8,39.3,3.7,8.3,9.2,10.1,14.6,19.2,23.6,23.9,29.2,0.8,3.3,3.8,4.6,8.0,10.5,11.0,12.6,13.2,15.9,20.3,21.9,22.0,22.4,28.6,29.9,31.5,34.7,35.9,0.5,3.1,5.4
 time     |         -1 | 
(5 rows)

SELECT count(*) FROM :chunk2;
 count 
-------
 22321
(1 row)

ANALYZE readings;
SELECT relname, reltuples, relpages
FROM pg_class
WHERE oid = :'chunk2'::regclass;
     relname      | reltuples | relpages 
------------------+-----------+----------
 _hyper_1_6_chunk |     22321 |        1
(1 row)

SELECT attname, n_distinct, array_to_string(most_common_vals, E',') AS most_common_vals
FROM pg_stats
WHERE format('%I.%I', schemaname, tablename)::regclass = :'chunk2'::regclass
ORDER BY attname;
 attname  | n_distinct |                                                                                                                                                                                                                                    most_common_vals                                                                                                                                                                                                                                     
----------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 device   |         30 | 14,11,27,4,21,12,3,19,29,24,5,1,10,22,17,7,13,8,23,18,20,28,9,2,16,26,25,6,30,15
 humidity |         -1 | 
 location |         10 | 7,4,5,10,2,3,1,6,8,9
 temp     |        401 | 4.9,31.7,1.6,28.8,5.2,2.3,6.9,11.2,26.6,5.9,37.3,36.5,32.2,14.3,26.5,37.4,16.6,18.7,12.0,12.9,16.3,19.9,24.8,27.6,27.7,28.2,30.8,1.2,8.2,11.7,17.1,23.4,2.5,2.8,15.5,19.8,23.3,25.9,27.2,38.0,1.4,3.9,7.0,11.4,12.7,13.7,15.7,23.7,29.6,30.0,35.7,36.3,37.7,38.9,0.4,15.3,26.2,4.4,9.1,9.5,10.8,16.4,16.8,23.2,25.7,25.8,26.9,36.8,39.3,3.7,8.3,9.2,10.1,14.6,19.2,23.6,23.9,29.2,0.8,3.3,3.8,4.6,8.0,10.5,11.0,12.6,13.2,15.9,20.3,21.9,22.0,22.4,28.6,29.9,31.5,34.7,35.9,0.5,3.1,5.4
 time     |         -1 | 
(5 rows)

ALTER TABLE :chunk2 SET ACCESS METHOD heap;
-- We should be able to change it back to heap.
-- Compression metadata should be cleaned up
SELECT count(*) FROM _timescaledb_catalog.compression_chunk_size ccs
INNER JOIN _timescaledb_catalog.chunk c ON (c.id = ccs.chunk_id)
WHERE format('%I.%I', c.schema_name, c.table_name)::regclass = :'chunk'::regclass;
 count 
-------
     1
(1 row)

SELECT device, count(*) INTO num_rows_before FROM :chunk GROUP BY device;
SELECT format('%I.%I', c2.schema_name, c2.table_name)::regclass AS cchunk
FROM _timescaledb_catalog.chunk c1
INNER JOIN _timescaledb_catalog.chunk c2
ON (c1.compressed_chunk_id = c2.id);
                     cchunk                     
------------------------------------------------
 _timescaledb_internal.compress_hyper_2_7_chunk
(1 row)

ALTER TABLE :chunk SET ACCESS METHOD heap;
SET timescaledb.enable_transparent_decompression TO 'hyperstore';
-- The compressed chunk should no longer exist
SELECT format('%I.%I', c2.schema_name, c2.table_name)::regclass AS cchunk
FROM _timescaledb_catalog.chunk c1
INNER JOIN _timescaledb_catalog.chunk c2
ON (c1.compressed_chunk_id = c2.id);
 cchunk 
--------
(0 rows)

SELECT device, count(*) INTO num_rows_after FROM :chunk GROUP BY device;
SELECT device, num_rows_after.count AS after,
	   num_rows_before.count AS before,
	   (num_rows_after.count - num_rows_before.count) AS diff
FROM num_rows_after JOIN num_rows_before USING (device)
WHERE num_rows_after.count != num_rows_before.count;
 device | after | before | diff 
--------+-------+--------+------
(0 rows)

SELECT count(*) FROM _timescaledb_catalog.compression_chunk_size ccs
INNER JOIN _timescaledb_catalog.chunk c ON (c.id = ccs.chunk_id)
WHERE format('%I.%I', c.schema_name, c.table_name)::regclass = :'chunk'::regclass;
 count 
-------
     0
(1 row)

SELECT compress_chunk(:'chunk');
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
(1 row)

-- A new compressed chunk should be created
SELECT format('%I.%I', c2.schema_name, c2.table_name)::regclass AS cchunk
FROM _timescaledb_catalog.chunk c1
INNER JOIN _timescaledb_catalog.chunk c2
ON (c1.compressed_chunk_id = c2.id);
                     cchunk                     
------------------------------------------------
 _timescaledb_internal.compress_hyper_2_9_chunk
(1 row)

-- Show same output as first query above but for heap
SELECT * FROM :chunk WHERE device < 4 ORDER BY time, device LIMIT 5;
             time             | location | device | temp |     humidity     
------------------------------+----------+--------+------+------------------
 Wed Jun 01 00:00:55 2022 PDT |        1 |      1 | 18.1 | 93.2399098726618
 Wed Jun 01 00:02:50 2022 PDT |        6 |      2 |  3.4 | 79.4169433908854
 Wed Jun 01 00:03:15 2022 PDT |        2 |      2 | 32.4 | 43.4716481956856
 Wed Jun 01 00:03:35 2022 PDT |        9 |      3 | 37.1 | 29.4121735958255
 Wed Jun 01 00:05:05 2022 PDT |        2 |      1 | 23.9 | 29.1861844182151
(5 rows)

-- Show access method used on chunk
SELECT c.relname, a.amname FROM pg_class c
INNER JOIN pg_am a ON (c.relam = a.oid)
WHERE c.oid = :'chunk'::regclass;
     relname      | amname 
------------------+--------
 _hyper_1_1_chunk | heap
(1 row)

-- Should give the same result as above
SELECT device, count(*) INTO decomp FROM readings GROUP BY device;
-- Row counts for each device should match, except for the chunk we did inserts on.
SELECT device, orig.count AS orig_count, decomp.count AS decomp_count, (decomp.count - orig.count) AS diff
FROM orig JOIN decomp USING (device) WHERE orig.count != decomp.count;
 device | orig_count | decomp_count | diff 
--------+------------+--------------+------
(0 rows)

-- Convert back to hyperstore to check that metadata was cleaned up
-- from last time this table used hyperstore
ALTER TABLE :chunk SET ACCESS METHOD hyperstore;
SET timescaledb.enable_transparent_decompression TO false;
-- Get the chunk's corresponding compressed chunk
SELECT format('%I.%I', c2.schema_name, c2.table_name)::regclass AS cchunk
FROM _timescaledb_catalog.chunk c1
INNER JOIN _timescaledb_catalog.chunk c2
ON (c1.compressed_chunk_id = c2.id) LIMIT 1 \gset
SELECT range_start, range_end
FROM timescaledb_information.chunks
WHERE format('%I.%I', chunk_schema, chunk_name)::regclass = :'chunk'::regclass;
         range_start          |          range_end           
------------------------------+------------------------------
 Wed May 25 17:00:00 2022 PDT | Wed Jun 01 17:00:00 2022 PDT
(1 row)

--
-- ADD COLUMN
--
-- Check that adding a column works across recompression.  First save
-- some sample data from the table that will be used as a comparison
-- to ensure adding a column doesn't mess up the data or column
-- mapping.
CREATE TEMP TABLE sample_readings AS
SELECT * FROM readings
WHERE time BETWEEN '2022-06-01 00:00:01' AND '2022-06-01 00:00:10'::timestamptz;
SELECT count(*) FROM sample_readings;
 count 
-------
     2
(1 row)

-- Now add the column
ALTER TABLE readings ADD COLUMN pressure float;
-- Check that the sample data remains the same in the modified
-- table. Should return the same count as above if everything is the
-- same.
SELECT count(*) FROM readings r
JOIN sample_readings s USING (time, location, device, temp, humidity);
 count 
-------
     2
(1 row)

-- insert some new (non-compressed) data into the chunk in order to
-- test recompression
INSERT INTO :chunk (time, location, device, temp, humidity, pressure)
SELECT t, ceil(random()*10), ceil(random()*30), random()*40, random()*100, random() * 30
FROM generate_series('2022-06-01 00:06:14'::timestamptz, '2022-06-01 16:59', '5s') t;
-- Check that new data is returned
SELECT * FROM :chunk WHERE time = '2022-06-01 00:06:14'::timestamptz;
             time             | location | device | temp |     humidity     |     pressure     
------------------------------+----------+--------+------+------------------+------------------
 Wed Jun 01 00:06:14 2022 PDT |        4 |     14 | 25.4 | 25.1660100601806 | 13.7277476339543
(1 row)

-- Want to check that index scans work after recompression, so the
-- query should be an index scan.
EXPLAIN (verbose, costs off)
SELECT * FROM :chunk WHERE time = '2022-06-01 00:06:14'::timestamptz;
                                             QUERY PLAN                                             
----------------------------------------------------------------------------------------------------
 Index Scan using "1_1_readings_time_key" on _timescaledb_internal._hyper_1_1_chunk
   Output: "time", location, device, temp, humidity, pressure
   Index Cond: (_hyper_1_1_chunk."time" = 'Wed Jun 01 00:06:14 2022 PDT'::timestamp with time zone)
(3 rows)

-- Show counts in compressed chunk prior to recompression
SELECT sum(_ts_meta_count) FROM :cchunk;
  sum  
-------
 12240
(1 row)

CALL recompress_chunk(:'chunk');
WARNING:  procedure public.recompress_chunk(regclass,boolean) is deprecated and the functionality is now included in public.compress_chunk. this compatibility function will be removed in a future version.
-- Data should be returned even after recompress, but now from the
-- compressed relation. Still using index scan.
EXPLAIN (verbose, costs off)
SELECT * FROM :chunk WHERE time = '2022-06-01 00:06:14'::timestamptz;
                                             QUERY PLAN                                             
----------------------------------------------------------------------------------------------------
 Index Scan using "1_1_readings_time_key" on _timescaledb_internal._hyper_1_1_chunk
   Output: "time", location, device, temp, humidity, pressure
   Index Cond: (_hyper_1_1_chunk."time" = 'Wed Jun 01 00:06:14 2022 PDT'::timestamp with time zone)
(3 rows)

SELECT * FROM :chunk WHERE time = '2022-06-01 00:06:14'::timestamptz;
             time             | location | device | temp |     humidity     |     pressure     
------------------------------+----------+--------+------+------------------+------------------
 Wed Jun 01 00:06:14 2022 PDT |        4 |     14 | 25.4 | 25.1660100601806 | 13.7277476339543
(1 row)

-- Drop column and add again
ALTER TABLE readings DROP COLUMN pressure;
EXPLAIN (verbose, costs off)
SELECT * FROM :chunk WHERE time = '2022-06-01 00:06:14'::timestamptz;
                                             QUERY PLAN                                             
----------------------------------------------------------------------------------------------------
 Index Scan using "1_1_readings_time_key" on _timescaledb_internal._hyper_1_1_chunk
   Output: "time", location, device, temp, humidity
   Index Cond: (_hyper_1_1_chunk."time" = 'Wed Jun 01 00:06:14 2022 PDT'::timestamp with time zone)
(3 rows)

SELECT * FROM :chunk WHERE time = '2022-06-01 00:06:14'::timestamptz;
             time             | location | device | temp |     humidity     
------------------------------+----------+--------+------+------------------
 Wed Jun 01 00:06:14 2022 PDT |        4 |     14 | 25.4 | 25.1660100601806
(1 row)

ALTER TABLE readings ADD COLUMN pressure float;
EXPLAIN (verbose, costs off)
SELECT * FROM :chunk WHERE time = '2022-06-01 00:06:14'::timestamptz;
                                             QUERY PLAN                                             
----------------------------------------------------------------------------------------------------
 Index Scan using "1_1_readings_time_key" on _timescaledb_internal._hyper_1_1_chunk
   Output: "time", location, device, temp, humidity, pressure
   Index Cond: (_hyper_1_1_chunk."time" = 'Wed Jun 01 00:06:14 2022 PDT'::timestamp with time zone)
(3 rows)

SELECT * FROM :chunk WHERE time = '2022-06-01 00:06:14'::timestamptz;
             time             | location | device | temp |     humidity     | pressure 
------------------------------+----------+--------+------+------------------+----------
 Wed Jun 01 00:06:14 2022 PDT |        4 |     14 | 25.4 | 25.1660100601806 |         
(1 row)

\set ON_ERROR_STOP 0
-- Can't recompress twice without new non-compressed rows
CALL recompress_chunk(:'chunk');
WARNING:  procedure public.recompress_chunk(regclass,boolean) is deprecated and the functionality is now included in public.compress_chunk. this compatibility function will be removed in a future version.
NOTICE:  chunk "_hyper_1_1_chunk" is already compressed
\set ON_ERROR_STOP 1
-- Compressed count after recompression
SELECT sum(_ts_meta_count) FROM :cchunk;
  sum  
-------
 24394
(1 row)

-- A count on the chunk should return the same count
SELECT count(*) FROM :chunk;
 count 
-------
 24394
(1 row)

drop table readings;
