-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\c :TEST_DBNAME :ROLE_SUPERUSER
set role :ROLE_1; -- Run test with role_1 because it has CREATEROLE
                  -- privileges that is needed further down
\ir include/hypercore_helpers.sql
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- Function to run an explain analyze with and do replacements on the
-- emitted plan. This is intended to be used when the structure of the
-- plan is important, but not the specific chunks scanned nor the
-- number of heap fetches, rows, loops, etc.
create function anonymize(ln text) returns text language plpgsql as
$$
begin
    ln := regexp_replace(ln, '_hyper_\d+_\d+_chunk', '_hyper_I_N_chunk', 1, 0);
    ln := regexp_replace(ln, 'Heap Fetches: \d+', 'Heap Fetches: N');
    ln := regexp_replace(ln, 'Workers Launched: \d+', 'Workers Launched: N');
    ln := regexp_replace(ln, 'actual rows=\d+ loops=\d+', 'actual rows=N loops=N');

    if trim(both from ln) like 'Array: %' then
       ln := regexp_replace(ln, 'hits=\d+', 'hits=N');
       ln := regexp_replace(ln, 'misses=\d+', 'misses=N');
       ln := regexp_replace(ln, 'count=\d+', 'count=N');
       ln := regexp_replace(ln, 'calls=\d+', 'calls=N');
    end if;
    return ln;
end
$$;
create function explain_analyze_anonymize(text) returns setof text
language plpgsql as
$$
declare
    ln text;
begin
    for ln in
        execute format('explain (analyze, costs off, summary off, timing off, decompress_cache_stats) %s', $1)
    loop
        -- Group keys are shown for plans in PG15 but not others, so
        -- we remove these lines to avoid having to have
        -- version-sensible tests.
	if trim(both from ln) like 'Group Key:%' then
	   continue;
	end if;
        return next anonymize(ln);
    end loop;
end;
$$;
create function explain_anonymize(text) returns setof text
language plpgsql as
$$
declare
    ln text;
begin
    for ln in
        execute format('explain (costs off, summary off, timing off) %s', $1)
    loop
        return next anonymize(ln);
    end loop;
end;
$$;
select setseed(0.3);
 setseed 
---------
 
(1 row)

-- View to get information about chunks and associated compressed
-- chunks.
create or replace view test_chunk_info as
with
  ht_and_chunk as (
    select format('%I.%I', ht.schema_name, ht.table_name)::regclass as hypertable,
           format('%I.%I', ch.schema_name, ch.table_name)::regclass as chunk,
           case when cc.table_name is not null then
                format('%I.%I', cc.schema_name, cc.table_name)::regclass
                else null
           end as compressed_chunk
      from _timescaledb_catalog.chunk ch
      left join _timescaledb_catalog.chunk cc on ch.compressed_chunk_id = cc.id
      join _timescaledb_catalog.hypertable ht on ch.hypertable_id = ht.id
     where ht.compression_state != 2
  )
select hypertable,
       chunk,
       (select reloptions from pg_class where oid = chunk) as chunk_reloptions,
       compressed_chunk,
       (select reloptions from pg_class where oid = compressed_chunk) as compressed_reloptions
  from ht_and_chunk;
-- Testing the basic API for creating a hypercore
-- This should just fail because you cannot create a plain table with
-- hypercore (yet).
\set ON_ERROR_STOP 0
\set VERBOSITY default
create table test2(
       created_at timestamp with time zone not null,
       location_id int
) using hypercore;
ERROR:  hypercore access method not supported on "test2"
DETAIL:  The hypercore access method is only supported for hypertables.
HINT:  Create a hypertable from a table using another access method (e.g., heap), then use "ALTER TABLE" to set the access method to hypercore.
set default_table_access_method to 'hypercore';
create table test2(
       created_at timestamp with time zone not null,
       location_id int
);
ERROR:  hypercore access method not supported on "test2"
DETAIL:  The hypercore access method is only supported for hypertables.
HINT:  It does not make sense to set the default access method for all tables to "hypercore" since it is only supported for hypertables.
reset default_table_access_method;
\set VERBOSITY terse
\set ON_ERROR_STOP 1
CREATE TABLE test2(
	   created_at timestamptz not null,
	   location_id int,
	   device_id int,
	   temp float,
	   humidity float
);
create index on test2(device_id, created_at);
\set ON_ERROR_STOP 0
alter table test2 set access method hypercore;
ERROR:  hypercore access method not supported on "test2"
\set ON_ERROR_STOP 1
select create_hypertable('test2', 'created_at');
 create_hypertable  
--------------------
 (1,public,test2,t)
(1 row)

\set ON_ERROR_STOP 0
-- Should show error since there is no namespace.
alter table test2
	  set access method hypercore,
	  set (compress_segmentby = 'location_id');
WARNING:  the hypercore access method is marked as deprecated with the 2.21.0 release and will be fully removed in the 2.22.0 release.
WARNING:  there was some uncertainty picking the default segment by for the hypertable: Please make sure device_id is not a unique column and appropriate for a segment by
NOTICE:  default segment by for hypertable "test2" is set to "device_id"
NOTICE:  default order by for hypertable "test2" is set to "created_at DESC"
ERROR:  unrecognized parameter "compress_segmentby"
\set ON_ERROR_STOP 1
alter table test2
	  set access method hypercore,
	  set (timescaledb.compress_segmentby = 'location_id');
WARNING:  the hypercore access method is marked as deprecated with the 2.21.0 release and will be fully removed in the 2.22.0 release.
NOTICE:  default order by for hypertable "test2" is set to "created_at DESC, device_id"
-- Test altering hypertable to hypercore again. It should be allowed
-- and be a no-op.
alter table test2 set access method hypercore;
WARNING:  the hypercore access method is marked as deprecated with the 2.21.0 release and will be fully removed in the 2.22.0 release.
\set ON_ERROR_STOP 0
-- This shows an error but the error is weird, we should probably get
-- a better one.
alter table test2
	  set access method hypercore,
	  set (compress_segmentby = 'location_id');
WARNING:  the hypercore access method is marked as deprecated with the 2.21.0 release and will be fully removed in the 2.22.0 release.
ERROR:  unrecognized parameter "compress_segmentby"
\set ON_ERROR_STOP 1
-- Create view for hypercore rels
create view amrels as
select cl.oid::regclass as rel, am.amname, inh.inhparent::regclass as relparent
  from pg_class cl
  inner join pg_am am on (cl.relam = am.oid)
  left join pg_inherits inh on (inh.inhrelid = cl.oid);
-- Show that test2 is a hypercore
select rel, amname
from amrels
where rel='test2'::regclass;
  rel  |  amname   
-------+-----------
 test2 | hypercore
(1 row)

-- This will create new chunks for the hypertable
insert into test2 (created_at, location_id, device_id, temp, humidity)
select t, ceil(random()*10), ceil(random()*30), random()*40, random()*100
from generate_series('2022-06-01'::timestamptz, '2022-07-01', '5m') t;
-- Save the count for test2 for later comparison
select count(*) as orig_test2_count from test2 \gset
-- All chunks should use the hypercore access method
select * from amrels
where relparent='test2'::regclass;
                   rel                   |  amname   | relparent 
-----------------------------------------+-----------+-----------
 _timescaledb_internal._hyper_1_1_chunk  | hypercore | test2
 _timescaledb_internal._hyper_1_3_chunk  | hypercore | test2
 _timescaledb_internal._hyper_1_5_chunk  | hypercore | test2
 _timescaledb_internal._hyper_1_7_chunk  | hypercore | test2
 _timescaledb_internal._hyper_1_9_chunk  | hypercore | test2
 _timescaledb_internal._hyper_1_11_chunk | hypercore | test2
(6 rows)

-- Show compression settings for hypercore across catalog and views
select * from _timescaledb_catalog.compression_settings;
                  relid                  |                 compress_relid                  |   segmentby   |        orderby         | orderby_desc | orderby_nullsfirst 
-----------------------------------------+-------------------------------------------------+---------------+------------------------+--------------+--------------------
 test2                                   |                                                 | {location_id} | {created_at,device_id} | {t,f}        | {t,f}
 _timescaledb_internal._hyper_1_1_chunk  | _timescaledb_internal.compress_hyper_3_2_chunk  | {location_id} | {created_at,device_id} | {t,f}        | {t,f}
 _timescaledb_internal._hyper_1_3_chunk  | _timescaledb_internal.compress_hyper_3_4_chunk  | {location_id} | {created_at,device_id} | {t,f}        | {t,f}
 _timescaledb_internal._hyper_1_5_chunk  | _timescaledb_internal.compress_hyper_3_6_chunk  | {location_id} | {created_at,device_id} | {t,f}        | {t,f}
 _timescaledb_internal._hyper_1_7_chunk  | _timescaledb_internal.compress_hyper_3_8_chunk  | {location_id} | {created_at,device_id} | {t,f}        | {t,f}
 _timescaledb_internal._hyper_1_9_chunk  | _timescaledb_internal.compress_hyper_3_10_chunk | {location_id} | {created_at,device_id} | {t,f}        | {t,f}
 _timescaledb_internal._hyper_1_11_chunk | _timescaledb_internal.compress_hyper_3_12_chunk | {location_id} | {created_at,device_id} | {t,f}        | {t,f}
(7 rows)

select * from timescaledb_information.compression_settings;
 hypertable_schema | hypertable_name |   attname   | segmentby_column_index | orderby_column_index | orderby_asc | orderby_nullsfirst 
-------------------+-----------------+-------------+------------------------+----------------------+-------------+--------------------
 public            | test2           | location_id |                      1 |                      |             | 
 public            | test2           | created_at  |                        |                    1 | f           | t
 public            | test2           | device_id   |                        |                    2 | t           | f
(3 rows)

select * from timescaledb_information.chunk_compression_settings;
 hypertable |                  chunk                  |  segmentby  |          orderby          
------------+-----------------------------------------+-------------+---------------------------
 test2      | _timescaledb_internal._hyper_1_1_chunk  | location_id | created_at DESC,device_id
 test2      | _timescaledb_internal._hyper_1_3_chunk  | location_id | created_at DESC,device_id
 test2      | _timescaledb_internal._hyper_1_5_chunk  | location_id | created_at DESC,device_id
 test2      | _timescaledb_internal._hyper_1_7_chunk  | location_id | created_at DESC,device_id
 test2      | _timescaledb_internal._hyper_1_9_chunk  | location_id | created_at DESC,device_id
 test2      | _timescaledb_internal._hyper_1_11_chunk | location_id | created_at DESC,device_id
(6 rows)

--------------------------
-- Test alter on chunks --
--------------------------
create table test3 (time timestamptz not null, device int, temp float);
select create_hypertable('test3', 'time');
 create_hypertable  
--------------------
 (4,public,test3,t)
(1 row)

-- create one chunk
insert into test3 values ('2022-06-01', 1, 1.0);
-- save chunk as variable
select ch as chunk from show_chunks('test3') ch limit 1 \gset
-- Check that chunk is NOT using hypercore
select rel, amname
from amrels
where relparent='test3'::regclass;
                   rel                   | amname 
-----------------------------------------+--------
 _timescaledb_internal._hyper_4_13_chunk | heap
(1 row)

\set ON_ERROR_STOP 0
-- Cannot create hypercore if missing compression settings
alter table :chunk set access method hypercore;
ERROR:  hypertable "test3" is missing compression settings
\set ON_ERROR_STOP 1
-- Add compression settings
alter table test3 set (timescaledb.compress, timescaledb.compress_orderby='time desc', timescaledb.compress_segmentby='');
-- Show that there is no dependency on TAM initially
select count(*) from pg_depend
where classid = 'pg_class'::regclass
and objid = :'chunk'::regclass
and refclassid = 'pg_am'::regclass;
 count 
-------
     0
(1 row)

\x on
select * from test_chunk_info where chunk = :'chunk'::regclass;
-[ RECORD 1 ]---------+----------------------------------------
hypertable            | test3
chunk                 | _timescaledb_internal._hyper_4_13_chunk
chunk_reloptions      | 
compressed_chunk      | 
compressed_reloptions | 

alter table :chunk set access method hypercore;
select * from test_chunk_info where chunk = :'chunk'::regclass;
-[ RECORD 1 ]---------+------------------------------------------------
hypertable            | test3
chunk                 | _timescaledb_internal._hyper_4_13_chunk
chunk_reloptions      | 
compressed_chunk      | _timescaledb_internal.compress_hyper_5_14_chunk
compressed_reloptions | {toast_tuple_target=128,autovacuum_enabled=0}

\x off
-- TAM dependency should exist now
select count(*) from pg_depend
where classid = 'pg_class'::regclass
and objid = :'chunk'::regclass
and refclassid = 'pg_am'::regclass;
 count 
-------
     1
(1 row)

-- Check that chunk is using hypercore
select * from amrels where rel=:'chunk'::regclass;
                   rel                   |  amname   | relparent 
-----------------------------------------+-----------+-----------
 _timescaledb_internal._hyper_4_13_chunk | hypercore | test3
(1 row)

-- Try same thing with compress_chunk(), and check the reloptions
-- before and after
\x on
select * from test_chunk_info where chunk = :'chunk'::regclass;
-[ RECORD 1 ]---------+------------------------------------------------
hypertable            | test3
chunk                 | _timescaledb_internal._hyper_4_13_chunk
chunk_reloptions      | 
compressed_chunk      | _timescaledb_internal.compress_hyper_5_14_chunk
compressed_reloptions | {toast_tuple_target=128,autovacuum_enabled=0}

alter table :chunk set access method heap;
select * from test_chunk_info where chunk = :'chunk'::regclass;
-[ RECORD 1 ]---------+------------------------------------------------
hypertable            | test3
chunk                 | _timescaledb_internal._hyper_4_13_chunk
chunk_reloptions      | 
compressed_chunk      | _timescaledb_internal.compress_hyper_5_14_chunk
compressed_reloptions | {toast_tuple_target=128,autovacuum_enabled=1}

\x off
-- TAM dependency should be removed
select count(*) from pg_depend
where classid = 'pg_class'::regclass
and objid = :'chunk'::regclass
and refclassid = 'pg_am'::regclass;
 count 
-------
     0
(1 row)

select compress_chunk(:'chunk', hypercore_use_access_method => true);
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_4_13_chunk
(1 row)

-- Check that chunk is using hypercore
select relname, amname
  from show_chunks('test3') as chunk
  join pg_class on (pg_class.oid = chunk)
  join pg_am on (relam = pg_am.oid);
      relname      |  amname   
-------------------+-----------
 _hyper_4_13_chunk | hypercore
(1 row)

-- Test setting same access method again
alter table :chunk set access method hypercore;
-- Test recompression after changing compression settings
alter table test3 set (timescaledb.compress_segmentby='device');
select compress_chunk(:'chunk', hypercore_use_access_method => true, recompress => true);
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_4_13_chunk
(1 row)

-- Create a second chunk
insert into test3 values ('2022-08-01', 1, 1.0);
-- The second chunk should not be a hypercore chunk
select * from amrels where relparent='test3'::regclass;
                   rel                   |  amname   | relparent 
-----------------------------------------+-----------+-----------
 _timescaledb_internal._hyper_4_13_chunk | hypercore | test3
 _timescaledb_internal._hyper_4_16_chunk | heap      | test3
(2 rows)

-- Set hypercore on hypertable
alter table test3 set access method hypercore;
WARNING:  the hypercore access method is marked as deprecated with the 2.21.0 release and will be fully removed in the 2.22.0 release.
-- Create a third chunk
insert into test3 values ('2022-10-01', 1, 1.0);
-- The third chunk should be a hypercore chunk
select * from amrels where relparent='test3'::regclass;
                   rel                   |  amname   | relparent 
-----------------------------------------+-----------+-----------
 _timescaledb_internal._hyper_4_13_chunk | hypercore | test3
 _timescaledb_internal._hyper_4_16_chunk | heap      | test3
 _timescaledb_internal._hyper_4_17_chunk | hypercore | test3
(3 rows)

-- Test that we can DDL on a hypertable that is not a Hypercore but
-- has one chunk that is a Hypercore works.
create table test4 (time timestamptz not null, device int, temp float);
select created from create_hypertable('test4', 'time');
 created 
---------
 t
(1 row)

insert into test4 values ('2022-06-01', 1, 1.0), ('2022-08-01', 1, 1.0);
-- should be at least two chunks
select count(ch) from show_chunks('test4') ch;
 count 
-------
     2
(1 row)

select ch as chunk from show_chunks('test4') ch limit 1 \gset
alter table test4 set (timescaledb.compress);
WARNING:  there was some uncertainty picking the default segment by for the hypertable: You do not have any indexes on columns that can be used for segment_by and thus we are not using segment_by for converting to columnstore. Please make sure you are not missing any indexes
NOTICE:  default segment by for hypertable "test4" is set to ""
NOTICE:  default order by for hypertable "test4" is set to ""time" DESC"
\x on
select * from test_chunk_info where chunk = :'chunk'::regclass;
-[ RECORD 1 ]---------+----------------------------------------
hypertable            | test4
chunk                 | _timescaledb_internal._hyper_6_19_chunk
chunk_reloptions      | 
compressed_chunk      | 
compressed_reloptions | 

alter table :chunk set access method hypercore;
select * from test_chunk_info where chunk = :'chunk'::regclass;
-[ RECORD 1 ]---------+------------------------------------------------
hypertable            | test4
chunk                 | _timescaledb_internal._hyper_6_19_chunk
chunk_reloptions      | 
compressed_chunk      | _timescaledb_internal.compress_hyper_7_21_chunk
compressed_reloptions | {toast_tuple_target=128,autovacuum_enabled=0}

select * from amrels where relparent='test4'::regclass;
-[ RECORD 1 ]--------------------------------------
rel       | _timescaledb_internal._hyper_6_19_chunk
amname    | hypercore
relparent | test4
-[ RECORD 2 ]--------------------------------------
rel       | _timescaledb_internal._hyper_6_20_chunk
amname    | heap
relparent | test4

\x off
-- test that alter table on the hypertable works
alter table test4 add column magic int;
\d :chunk
          Table "_timescaledb_internal._hyper_6_19_chunk"
 Column |           Type           | Collation | Nullable | Default 
--------+--------------------------+-----------+----------+---------
 time   | timestamp with time zone |           | not null | 
 device | integer                  |           |          | 
 temp   | double precision         |           |          | 
 magic  | integer                  |           |          | 
Indexes:
    "_hyper_6_19_chunk_test4_time_idx" btree ("time" DESC)
Check constraints:
    "constraint_10" CHECK ("time" >= 'Wed May 25 17:00:00 2022 PDT'::timestamp with time zone AND "time" < 'Wed Jun 01 17:00:00 2022 PDT'::timestamp with time zone)
Inherits: test4

-- Test that dropping a table with one chunk being a hypercore works.
drop table test4;
-- Create view to see compression stats. Left join chunks with stats
-- to detect missing stats. Only show row counts because size stats
-- seem to vary in tests
create view compressed_rel_size_stats as
select
	cl.oid::regclass as rel,
	am.amname,
	inh.inhparent::regclass as relparent,
	numrows_pre_compression,
	numrows_post_compression,
	numrows_frozen_immediately
from  _timescaledb_catalog.chunk c
left join _timescaledb_catalog.compression_chunk_size ccs
	  on (c.id = ccs.chunk_id)
inner join pg_class cl
	  on (cl.oid = format('%I.%I', c.schema_name, c.table_name)::regclass)
inner join pg_am am
	  on (am.oid = cl.relam)
inner join pg_inherits inh
	  on (inh.inhrelid = cl.oid)
where c.compressed_chunk_id is not null;
-- There should be no hypercore chunks that lack compression size stats
select count(*) as num_stats_missing from compressed_rel_size_stats
where amname = 'hypercore' and numrows_pre_compression is null;
 num_stats_missing 
-------------------
                 0
(1 row)

-- Show stats for hypercore chunks. Note that many stats are 0 since
-- chunks were created as a result of inserts and not really
-- compressed
select * from compressed_rel_size_stats order by rel;
                   rel                   |  amname   | relparent | numrows_pre_compression | numrows_post_compression | numrows_frozen_immediately 
-----------------------------------------+-----------+-----------+-------------------------+--------------------------+----------------------------
 _timescaledb_internal._hyper_1_1_chunk  | hypercore | test2     |                       0 |                        0 |                          0
 _timescaledb_internal._hyper_1_3_chunk  | hypercore | test2     |                       0 |                        0 |                          0
 _timescaledb_internal._hyper_1_5_chunk  | hypercore | test2     |                       0 |                        0 |                          0
 _timescaledb_internal._hyper_1_7_chunk  | hypercore | test2     |                       0 |                        0 |                          0
 _timescaledb_internal._hyper_1_9_chunk  | hypercore | test2     |                       0 |                        0 |                          0
 _timescaledb_internal._hyper_1_11_chunk | hypercore | test2     |                       0 |                        0 |                          0
 _timescaledb_internal._hyper_4_13_chunk | hypercore | test3     |                       1 |                        1 |                          1
 _timescaledb_internal._hyper_4_17_chunk | hypercore | test3     |                       0 |                        0 |                          0
(8 rows)

-- Decompress hypercores to check that stats are removed
select decompress_chunk(rel)
  from compressed_rel_size_stats
  where amname = 'hypercore';
            decompress_chunk             
-----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_5_chunk
 _timescaledb_internal._hyper_1_7_chunk
 _timescaledb_internal._hyper_1_9_chunk
 _timescaledb_internal._hyper_1_11_chunk
 _timescaledb_internal._hyper_4_13_chunk
 _timescaledb_internal._hyper_4_17_chunk
(8 rows)

-- All stats should be removed
select count(*) as orphaned_stats
from compressed_rel_size_stats;
 orphaned_stats 
----------------
              0
(1 row)

-- Compression settings should be removed except for parent
-- hypertables
select cs.relid, cl.relname
from _timescaledb_catalog.compression_settings cs
left join pg_class cl on (cs.relid = cl.oid);
 relid | relname 
-------+---------
 test2 | test2
 test3 | test3
(2 rows)

-- Create hypercores again and check that compression size stats are
-- updated showing compressed data
select compress_chunk(ch, hypercore_use_access_method => true)
from show_chunks('test2') ch;
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_5_chunk
 _timescaledb_internal._hyper_1_7_chunk
 _timescaledb_internal._hyper_1_9_chunk
 _timescaledb_internal._hyper_1_11_chunk
(6 rows)

select compress_chunk(ch, hypercore_use_access_method => true)
from show_chunks('test3') ch;
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_4_13_chunk
 _timescaledb_internal._hyper_4_16_chunk
 _timescaledb_internal._hyper_4_17_chunk
(3 rows)

-- Save the stats for later comparison. Exclude the amname column
-- since it will differ.
create table saved_stats as
select
	rel,
	relparent,
	numrows_pre_compression,
	numrows_post_compression,
	numrows_frozen_immediately
from compressed_rel_size_stats;
select * from compressed_rel_size_stats order by rel;
                   rel                   |  amname   | relparent | numrows_pre_compression | numrows_post_compression | numrows_frozen_immediately 
-----------------------------------------+-----------+-----------+-------------------------+--------------------------+----------------------------
 _timescaledb_internal._hyper_1_1_chunk  | hypercore | test2     |                     204 |                       10 |                         10
 _timescaledb_internal._hyper_1_3_chunk  | hypercore | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_5_chunk  | hypercore | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_7_chunk  | hypercore | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_9_chunk  | hypercore | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_11_chunk | hypercore | test2     |                     373 |                       10 |                         10
 _timescaledb_internal._hyper_4_13_chunk | hypercore | test3     |                       1 |                        1 |                          1
 _timescaledb_internal._hyper_4_16_chunk | hypercore | test3     |                       1 |                        1 |                          1
 _timescaledb_internal._hyper_4_17_chunk | hypercore | test3     |                       1 |                        1 |                          1
(9 rows)

-- Convert back to heap and compress the old way to compare
-- compression size stats
select compress_chunk(decompress_chunk(ch))
from show_chunks('test2') ch;
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_5_chunk
 _timescaledb_internal._hyper_1_7_chunk
 _timescaledb_internal._hyper_1_9_chunk
 _timescaledb_internal._hyper_1_11_chunk
(6 rows)

--- Using hypercore_use_access_method => NULL should be the same as "heap"
select compress_chunk(decompress_chunk(ch), hypercore_use_access_method => NULL)
from show_chunks('test3') ch;
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_4_13_chunk
 _timescaledb_internal._hyper_4_16_chunk
 _timescaledb_internal._hyper_4_17_chunk
(3 rows)

select * from compressed_rel_size_stats order by rel;
                   rel                   | amname | relparent | numrows_pre_compression | numrows_post_compression | numrows_frozen_immediately 
-----------------------------------------+--------+-----------+-------------------------+--------------------------+----------------------------
 _timescaledb_internal._hyper_1_1_chunk  | heap   | test2     |                     204 |                       10 |                         10
 _timescaledb_internal._hyper_1_3_chunk  | heap   | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_5_chunk  | heap   | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_7_chunk  | heap   | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_9_chunk  | heap   | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_11_chunk | heap   | test2     |                     373 |                       10 |                         10
 _timescaledb_internal._hyper_4_13_chunk | heap   | test3     |                       1 |                        1 |                          1
 _timescaledb_internal._hyper_4_16_chunk | heap   | test3     |                       1 |                        1 |                          1
 _timescaledb_internal._hyper_4_17_chunk | heap   | test3     |                       1 |                        1 |                          1
(9 rows)

-- Check that stats are the same for hypercore and now with
-- compression. Should return zero rows if they are the same.
select
	rel,
	relparent,
	numrows_pre_compression,
	numrows_post_compression,
	numrows_frozen_immediately
from compressed_rel_size_stats
except
select * from saved_stats;
 rel | relparent | numrows_pre_compression | numrows_post_compression | numrows_frozen_immediately 
-----+-----------+-------------------------+--------------------------+----------------------------
(0 rows)

-- Try migration to hypercore directly from compressed heap. Run in a
-- transaction block to make sure changes are visible to following
-- commands.
begin;
-- Check pg_am dependencies for the chunks. Since they are using heap
-- AM, there should be no dependencies as heap AM is always present.
select dep.objid::regclass, am.amname
from show_chunks('test2') ch
join pg_depend dep on (ch = dep.objid)
join pg_am am on (dep.refobjid = am.oid);
 objid | amname 
-------+--------
(0 rows)

-- Use DEBUG2 to show that migration path is invoked
set client_min_messages=DEBUG1;
with chunks as (
	 select ch from show_chunks('test2') ch offset 1
)
select compress_chunk(ch, hypercore_use_access_method => true) from chunks;
LOG:  statement: with chunks as (
	 select ch from show_chunks('test2') ch offset 1
)
select compress_chunk(ch, hypercore_use_access_method => true) from chunks;
DEBUG:  migrating table "_hyper_1_3_chunk" to hypercore
DEBUG:  building index "_hyper_1_3_chunk_test2_device_id_created_at_idx" on table "_hyper_1_3_chunk" serially
DEBUG:  index "_hyper_1_3_chunk_test2_device_id_created_at_idx" can safely use deduplication
DEBUG:  building index "_hyper_1_3_chunk_test2_created_at_idx" on table "_hyper_1_3_chunk" serially
DEBUG:  index "_hyper_1_3_chunk_test2_created_at_idx" can safely use deduplication
DEBUG:  migrating table "_hyper_1_5_chunk" to hypercore
DEBUG:  building index "_hyper_1_5_chunk_test2_device_id_created_at_idx" on table "_hyper_1_5_chunk" serially
DEBUG:  index "_hyper_1_5_chunk_test2_device_id_created_at_idx" can safely use deduplication
DEBUG:  building index "_hyper_1_5_chunk_test2_created_at_idx" on table "_hyper_1_5_chunk" serially
DEBUG:  index "_hyper_1_5_chunk_test2_created_at_idx" can safely use deduplication
DEBUG:  migrating table "_hyper_1_7_chunk" to hypercore
DEBUG:  building index "_hyper_1_7_chunk_test2_device_id_created_at_idx" on table "_hyper_1_7_chunk" serially
DEBUG:  index "_hyper_1_7_chunk_test2_device_id_created_at_idx" can safely use deduplication
DEBUG:  building index "_hyper_1_7_chunk_test2_created_at_idx" on table "_hyper_1_7_chunk" serially
DEBUG:  index "_hyper_1_7_chunk_test2_created_at_idx" can safely use deduplication
DEBUG:  migrating table "_hyper_1_9_chunk" to hypercore
DEBUG:  building index "_hyper_1_9_chunk_test2_device_id_created_at_idx" on table "_hyper_1_9_chunk" serially
DEBUG:  index "_hyper_1_9_chunk_test2_device_id_created_at_idx" can safely use deduplication
DEBUG:  building index "_hyper_1_9_chunk_test2_created_at_idx" on table "_hyper_1_9_chunk" serially
DEBUG:  index "_hyper_1_9_chunk_test2_created_at_idx" can safely use deduplication
DEBUG:  migrating table "_hyper_1_11_chunk" to hypercore
DEBUG:  building index "_hyper_1_11_chunk_test2_device_id_created_at_idx" on table "_hyper_1_11_chunk" serially
DEBUG:  index "_hyper_1_11_chunk_test2_device_id_created_at_idx" can safely use deduplication
DEBUG:  building index "_hyper_1_11_chunk_test2_created_at_idx" on table "_hyper_1_11_chunk" serially
DEBUG:  index "_hyper_1_11_chunk_test2_created_at_idx" can safely use deduplication
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_5_chunk
 _timescaledb_internal._hyper_1_7_chunk
 _timescaledb_internal._hyper_1_9_chunk
 _timescaledb_internal._hyper_1_11_chunk
(5 rows)

-- Test direct migration of the remaining chunk via SET ACCESS
-- METHOD. Add some uncompressed data to test migration with partially
-- compressed chunks.
select ch as alter_chunk from show_chunks('test2') ch limit 1 \gset
LOG:  statement: select ch as alter_chunk from show_chunks('test2') ch limit 1 
insert into :alter_chunk values ('2022-06-01 10:00', 4, 4, 4.0, 4.0);
LOG:  statement: insert into _timescaledb_internal._hyper_1_1_chunk values ('2022-06-01 10:00', 4, 4, 4.0, 4.0);
\x on
select * from test_chunk_info where chunk = :'alter_chunk'::regclass;
LOG:  statement: select * from test_chunk_info where chunk = '_timescaledb_internal._hyper_1_1_chunk'::regclass;
-[ RECORD 1 ]---------+------------------------------------------------
hypertable            | test2
chunk                 | _timescaledb_internal._hyper_1_1_chunk
chunk_reloptions      | 
compressed_chunk      | _timescaledb_internal.compress_hyper_3_31_chunk
compressed_reloptions | {toast_tuple_target=128}

alter table :alter_chunk set access method hypercore;
LOG:  statement: alter table _timescaledb_internal._hyper_1_1_chunk set access method hypercore;
DEBUG:  migrating table "_hyper_1_1_chunk" to hypercore
DEBUG:  building index "_hyper_1_1_chunk_test2_device_id_created_at_idx" on table "_hyper_1_1_chunk" serially
DEBUG:  index "_hyper_1_1_chunk_test2_device_id_created_at_idx" can safely use deduplication
DEBUG:  building index "_hyper_1_1_chunk_test2_created_at_idx" on table "_hyper_1_1_chunk" serially
DEBUG:  index "_hyper_1_1_chunk_test2_created_at_idx" can safely use deduplication
select * from test_chunk_info where chunk = :'alter_chunk'::regclass;
LOG:  statement: select * from test_chunk_info where chunk = '_timescaledb_internal._hyper_1_1_chunk'::regclass;
-[ RECORD 1 ]---------+------------------------------------------------
hypertable            | test2
chunk                 | _timescaledb_internal._hyper_1_1_chunk
chunk_reloptions      | 
compressed_chunk      | _timescaledb_internal.compress_hyper_3_31_chunk
compressed_reloptions | {toast_tuple_target=128,autovacuum_enabled=0}

\x off
reset client_min_messages;
LOG:  statement: reset client_min_messages;
-- Check pg_am dependencies for the chunks. Since they are using heap
-- AM, there should be no dependencies as heap AM is always present.
select dep.objid::regclass, am.amname
from show_chunks('test2') ch
join pg_depend dep on (ch = dep.objid)
join pg_am am on (dep.refobjid = am.oid);
                  objid                  |  amname   
-----------------------------------------+-----------
 _timescaledb_internal._hyper_1_1_chunk  | hypercore
 _timescaledb_internal._hyper_1_3_chunk  | hypercore
 _timescaledb_internal._hyper_1_5_chunk  | hypercore
 _timescaledb_internal._hyper_1_7_chunk  | hypercore
 _timescaledb_internal._hyper_1_9_chunk  | hypercore
 _timescaledb_internal._hyper_1_11_chunk | hypercore
(6 rows)

-- All chunks should use hypercore and have rel_size_stats
select * from compressed_rel_size_stats
where amname = 'hypercore' order by rel;
                   rel                   |  amname   | relparent | numrows_pre_compression | numrows_post_compression | numrows_frozen_immediately 
-----------------------------------------+-----------+-----------+-------------------------+--------------------------+----------------------------
 _timescaledb_internal._hyper_1_1_chunk  | hypercore | test2     |                     204 |                       10 |                         10
 _timescaledb_internal._hyper_1_3_chunk  | hypercore | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_5_chunk  | hypercore | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_7_chunk  | hypercore | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_9_chunk  | hypercore | test2     |                    2016 |                       10 |                         10
 _timescaledb_internal._hyper_1_11_chunk | hypercore | test2     |                     373 |                       10 |                         10
(6 rows)

-- Check that query plan is now ColumnarScan and that all data, except
-- the one uncompressed row, is still compressed after migration
explain (costs off)
select _timescaledb_debug.is_compressed_tid(ctid) from test2
where not _timescaledb_debug.is_compressed_tid(ctid);
                               QUERY PLAN                               
------------------------------------------------------------------------
 Result
   ->  Custom Scan (ChunkAppend) on test2
         Chunks excluded during startup: 0
         ->  Custom Scan (ColumnarScan) on _hyper_1_1_chunk
               Filter: (NOT _timescaledb_debug.is_compressed_tid(ctid))
         ->  Custom Scan (ColumnarScan) on _hyper_1_3_chunk
               Filter: (NOT _timescaledb_debug.is_compressed_tid(ctid))
         ->  Custom Scan (ColumnarScan) on _hyper_1_5_chunk
               Filter: (NOT _timescaledb_debug.is_compressed_tid(ctid))
         ->  Custom Scan (ColumnarScan) on _hyper_1_7_chunk
               Filter: (NOT _timescaledb_debug.is_compressed_tid(ctid))
         ->  Custom Scan (ColumnarScan) on _hyper_1_9_chunk
               Filter: (NOT _timescaledb_debug.is_compressed_tid(ctid))
         ->  Custom Scan (ColumnarScan) on _hyper_1_11_chunk
               Filter: (NOT _timescaledb_debug.is_compressed_tid(ctid))
(15 rows)

select _timescaledb_debug.is_compressed_tid(ctid) from test2
where not _timescaledb_debug.is_compressed_tid(ctid);
 is_compressed_tid 
-------------------
 f
(1 row)

-- Check that the table still returns the correct count. Account for
-- the one uncompressed row inserted.
select count(*)=(:orig_test2_count + 1) as count_as_expected from test2;
 count_as_expected 
-------------------
 t
(1 row)

commit;
\set ON_ERROR_STOP 0
-- Trying to convert a hypercore to a hypercore should be an error
-- if if_not_compressed is false and the hypercore is fully
-- compressed.
select compress_chunk(ch, hypercore_use_access_method => true, if_not_compressed => false)
from show_chunks('test2') ch;
ERROR:  chunk "_hyper_1_1_chunk" is already converted to columnstore
-- Compressing from hypercore and not using access method should lead
-- to an error since it is not supported.
select compress_chunk(ch, hypercore_use_access_method => false)
from show_chunks('test2') ch;
ERROR:  cannot converting to columnstore "_hyper_1_1_chunk" without using Hypercore access method
\set ON_ERROR_STOP 1
-- Compressing a hypercore should by default lead to
-- recompression. First check that :chunk is a hypercore.
select ch as chunk from show_chunks('test2') ch limit 1 \gset
select * from compressed_rel_size_stats
where amname = 'hypercore' and rel = :'chunk'::regclass;
                  rel                   |  amname   | relparent | numrows_pre_compression | numrows_post_compression | numrows_frozen_immediately 
----------------------------------------+-----------+-----------+-------------------------+--------------------------+----------------------------
 _timescaledb_internal._hyper_1_1_chunk | hypercore | test2     |                     204 |                       10 |                         10
(1 row)

insert into :chunk values ('2022-06-01 10:01', 6, 6, 6.0, 6.0);
select ctid from :chunk where created_at = '2022-06-01 10:01' and device_id = 6;
 ctid  
-------
 (0,2)
(1 row)

select compress_chunk(:'chunk');
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
(1 row)

select ctid from :chunk where created_at = '2022-06-01 10:01' and device_id = 6;
      ctid       
-----------------
 (2147484675,14)
(1 row)

-- Compressing a hypercore using the access method should also lead to
-- recompression
insert into :chunk values ('2022-06-01 11:02', 7, 7, 7.0, 7.0);
select ctid from :chunk where created_at = '2022-06-01 11:02' and device_id = 7;
 ctid  
-------
 (0,3)
(1 row)

select compress_chunk(:'chunk', hypercore_use_access_method => true);
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
(1 row)

select ctid from :chunk where created_at = '2022-06-01 11:02' and device_id = 7;
      ctid       
-----------------
 (2147484676,12)
(1 row)

-- Convert all hypercores back to heap
select decompress_chunk(rel) ch
  from compressed_rel_size_stats
  where amname = 'hypercore'
  order by ch;
                   ch                    
-----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_5_chunk
 _timescaledb_internal._hyper_1_7_chunk
 _timescaledb_internal._hyper_1_9_chunk
 _timescaledb_internal._hyper_1_11_chunk
(6 rows)

-- Test that it is possible to convert multiple hypercores in the
-- same transaction. The goal is to check that all the state is
-- cleaned up between two or more commands in same transaction.
select ch as chunk2 from show_chunks('test2') ch offset 1 limit 1 \gset
start transaction;
select compress_chunk(:'chunk', hypercore_use_access_method => true);
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
(1 row)

select compress_chunk(:'chunk2', hypercore_use_access_method => true);
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_3_chunk
(1 row)

commit;
select * from compressed_rel_size_stats
where amname = 'hypercore' and relparent = 'test2'::regclass
order by rel;
                  rel                   |  amname   | relparent | numrows_pre_compression | numrows_post_compression | numrows_frozen_immediately 
----------------------------------------+-----------+-----------+-------------------------+--------------------------+----------------------------
 _timescaledb_internal._hyper_1_1_chunk | hypercore | test2     |                     207 |                       10 |                         10
 _timescaledb_internal._hyper_1_3_chunk | hypercore | test2     |                    2016 |                       10 |                         10
(2 rows)

-- Test that we can compress old way by not using the access method
select ch as chunk3 from show_chunks('test2') ch offset 2 limit 1 \gset
select compress_chunk(:'chunk3', hypercore_use_access_method => false);
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_5_chunk
(1 row)

select * from compressed_rel_size_stats
where amname = 'heap' and relparent = 'test2'::regclass
order by rel;
                  rel                   | amname | relparent | numrows_pre_compression | numrows_post_compression | numrows_frozen_immediately 
----------------------------------------+--------+-----------+-------------------------+--------------------------+----------------------------
 _timescaledb_internal._hyper_1_5_chunk | heap   | test2     |                    2016 |                       10 |                         10
(1 row)

\set ON_ERROR_STOP 0
-- If we call compress_chunk using the table access method on a
-- heap-compressed chunk, it should lead to an error if
-- if_not_compressed is false. The commands below are all equivalent
-- in this case.
select compress_chunk(:'chunk3', hypercore_use_access_method => false, if_not_compressed=>false);
ERROR:  chunk "_hyper_1_5_chunk" is already converted to columnstore
select compress_chunk(:'chunk3', hypercore_use_access_method => NULL, if_not_compressed=>false);
ERROR:  chunk "_hyper_1_5_chunk" is already converted to columnstore
select compress_chunk(:'chunk3', if_not_compressed=>false);
ERROR:  chunk "_hyper_1_5_chunk" is already converted to columnstore
\set ON_ERROR_STOP 1
-- For a heap-compressed chunk, these should all be equivalent and
-- should not do anything when there is nothing to recompress. A
-- notice should be raised instead of an error.
select compress_chunk(:'chunk3', hypercore_use_access_method => false);
NOTICE:  chunk "_hyper_1_5_chunk" is already converted to columnstore
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_5_chunk
(1 row)

select compress_chunk(:'chunk3', hypercore_use_access_method => NULL);
NOTICE:  chunk "_hyper_1_5_chunk" is already converted to columnstore
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_5_chunk
(1 row)

select compress_chunk(:'chunk3');
NOTICE:  chunk "_hyper_1_5_chunk" is already converted to columnstore
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_5_chunk
(1 row)

-- Insert new data to create a "partially compressed" chunk. Note that
-- it is not possible to insert directly into the chunk because that
-- doesn't properly update the partially compressed state.
insert into test2 values ('2022-06-15 16:00', 8, 8, 8.0, 8.0);
select * from only :chunk3;
          created_at          | location_id | device_id | temp | humidity 
------------------------------+-------------+-----------+------+----------
 Wed Jun 15 16:00:00 2022 PDT |           8 |         8 |    8 |        8
(1 row)

select compress_chunk(:'chunk3', hypercore_use_access_method => false);
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_5_chunk
(1 row)

-- The tuple should no longer be in the non-compressed chunk
select * from only :chunk3;
 created_at | location_id | device_id | temp | humidity 
------------+-------------+-----------+------+----------
(0 rows)

-- But the tuple is returned in a query without ONLY
select * from :chunk3 where created_at = '2022-06-15 16:00' and device_id = 8;
          created_at          | location_id | device_id | temp | humidity 
------------------------------+-------------+-----------+------+----------
 Wed Jun 15 16:00:00 2022 PDT |           8 |         8 |    8 |        8
(1 row)

-- Test a more complicated schema from the NYC Taxi data set. This is
-- to test that compression using hypercore works, since there was an
-- issue with setting up the tuple sort state during compression.
create table rides (
    vendor_id text,
    pickup_datetime timestamptz not null,
    dropoff_datetime timestamptz not null,
    passenger_count numeric,
    trip_distance numeric,
    pickup_longitude numeric,
    pickup_latitude numeric,
    rate_code int,
    dropoff_longitude numeric,
    dropoff_latitude numeric,
    payment_type int,
    fare_amount numeric,
    extra numeric,
    mta_tax numeric,
    tip_amount numeric,
    tolls_amount numeric,
    improvement_surcharge numeric,
    total_amount numeric
);
select create_hypertable('rides', 'pickup_datetime', 'payment_type', 2, create_default_indexes=>false);
 create_hypertable  
--------------------
 (8,public,rides,t)
(1 row)

create index on rides (vendor_id, pickup_datetime desc);
create index on rides (pickup_datetime desc, vendor_id);
create index on rides (rate_code, pickup_datetime desc);
create index on rides (passenger_count, pickup_datetime desc);
alter table rides set (timescaledb.compress_segmentby='payment_type');
NOTICE:  default order by for hypertable "rides" is set to "pickup_datetime DESC, vendor_id, passenger_count, rate_code"
-- Insert some values. Particularly interested in testing text type handling.
insert into rides values
(745233436676,'2016-01-01 00:00:03','2016-01-01 00:11:14',1,6.00,-73.947151184082031,40.791046142578125,1,-73.920768737792969,40.865577697753906,2,9,0.5,0.5,0,0,0.3,19.3),
(6,'2016-01-01 00:00:02','2016-01-01 00:11:55',1,1.20,-73.979423522949219,40.744613647460938,1,-73.992034912109375,40.753944396972656,2,9,0.5,0.5,0,0,0.3,10.3),
(356,'2016-01-01 00:00:01','2016-01-01 00:11:55',1,1.20,-73.979423522949219,40.744613647460938,1,-73.992034912109375,40.753944396972656,2,9,0.5,0.5,0,0,0.3,10.3);
-- Check that it is possible to compress
select compress_chunk(ch, hypercore_use_access_method => true) from show_chunks('rides') ch;
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_8_43_chunk
(1 row)

select rel, amname from compressed_rel_size_stats
where relparent::regclass = 'rides'::regclass;
                   rel                   |  amname   
-----------------------------------------+-----------
 _timescaledb_internal._hyper_8_43_chunk | hypercore
(1 row)

-- Query to check everything is OK
analyze rides;
-- This should decompress and create text datums (column 1) in an
-- order that exercises datum caching in the arrow array
explain (costs off)
select * from rides order by pickup_datetime;
                      QUERY PLAN                       
-------------------------------------------------------
 Sort
   Sort Key: _hyper_8_43_chunk.pickup_datetime
   ->  Custom Scan (ColumnarScan) on _hyper_8_43_chunk
(3 rows)

select * from rides order by pickup_datetime;
  vendor_id   |       pickup_datetime        |       dropoff_datetime       | passenger_count | trip_distance |  pickup_longitude   |  pickup_latitude   | rate_code |  dropoff_longitude  |  dropoff_latitude  | payment_type | fare_amount | extra | mta_tax | tip_amount | tolls_amount | improvement_surcharge | total_amount 
--------------+------------------------------+------------------------------+-----------------+---------------+---------------------+--------------------+-----------+---------------------+--------------------+--------------+-------------+-------+---------+------------+--------------+-----------------------+--------------
 356          | Fri Jan 01 00:00:01 2016 PST | Fri Jan 01 00:11:55 2016 PST |               1 |          1.20 | -73.979423522949219 | 40.744613647460938 |         1 | -73.992034912109375 | 40.753944396972656 |            2 |           9 |   0.5 |     0.5 |          0 |            0 |                   0.3 |         10.3
 6            | Fri Jan 01 00:00:02 2016 PST | Fri Jan 01 00:11:55 2016 PST |               1 |          1.20 | -73.979423522949219 | 40.744613647460938 |         1 | -73.992034912109375 | 40.753944396972656 |            2 |           9 |   0.5 |     0.5 |          0 |            0 |                   0.3 |         10.3
 745233436676 | Fri Jan 01 00:00:03 2016 PST | Fri Jan 01 00:11:14 2016 PST |               1 |          6.00 | -73.947151184082031 | 40.791046142578125 |         1 | -73.920768737792969 | 40.865577697753906 |            2 |           9 |   0.5 |     0.5 |          0 |            0 |                   0.3 |         19.3
(3 rows)

-- All these are valid methods to set the default
show timescaledb.default_hypercore_use_access_method;
 timescaledb.default_hypercore_use_access_method 
-------------------------------------------------
 off
(1 row)

set timescaledb.default_hypercore_use_access_method to on;
set timescaledb.default_hypercore_use_access_method to off;
set timescaledb.default_hypercore_use_access_method to true;
set timescaledb.default_hypercore_use_access_method to false;
set timescaledb.default_hypercore_use_access_method to yes;
set timescaledb.default_hypercore_use_access_method to no;
set timescaledb.default_hypercore_use_access_method to 0;
set timescaledb.default_hypercore_use_access_method to 1;
show timescaledb.default_hypercore_use_access_method;
 timescaledb.default_hypercore_use_access_method 
-------------------------------------------------
 on
(1 row)

-- This should unset the value
reset timescaledb.default_hypercore_use_access_method;
show timescaledb.default_hypercore_use_access_method;
 timescaledb.default_hypercore_use_access_method 
-------------------------------------------------
 off
(1 row)

-- Using GUC should compress using the hyperstore
set timescaledb.default_hypercore_use_access_method to on;
create table test5 (time timestamptz not null, device int, temp float);
select created from create_hypertable('test5', 'time');
 created 
---------
 t
(1 row)

insert into test5 values ('2022-06-01', 1, 1.0), ('2022-08-01', 1, 1.0);
select ch as chunk from show_chunks('test5') ch limit 1 \gset
alter table test5 set (timescaledb.compress);
WARNING:  there was some uncertainty picking the default segment by for the hypertable: You do not have any indexes on columns that can be used for segment_by and thus we are not using segment_by for converting to columnstore. Please make sure you are not missing any indexes
NOTICE:  default segment by for hypertable "test5" is set to ""
NOTICE:  default order by for hypertable "test5" is set to ""time" DESC"
select compress_chunk(:'chunk');
              compress_chunk              
------------------------------------------
 _timescaledb_internal._hyper_10_45_chunk
(1 row)

select * from amrels where relparent = 'test5'::regclass;
                   rel                    |  amname   | relparent 
------------------------------------------+-----------+-----------
 _timescaledb_internal._hyper_10_45_chunk | hypercore | test5
 _timescaledb_internal._hyper_10_46_chunk | heap      | test5
(2 rows)

-- Check that operations that rewrite the relation are blocked with
-- invalid setting of transparent decompression GUC
\set ON_ERROR_STOP 0
select count(*) from :chunk;
 count 
-------
     1
(1 row)

set timescaledb.enable_transparent_decompression='hypercore';
select decompress_chunk(:'chunk');
ERROR:  operation not compatible with current setting of timescaledb.enable_transparent_decompression
alter table :chunk set access method heap;
vacuum full :chunk;
select count(*) from :chunk;
 count 
-------
     1
(1 row)

\set ON_ERROR_STOP 1
set timescaledb.enable_transparent_decompression=true;
-- Test chunk creation with non-owner user
CREATE TABLE conditions (	-- create a regular table
    time        timestamptz not null,
    location    text not null,
    temperature double precision null
);
select create_hypertable('conditions', 'time');	-- turn it into a hypertable
    create_hypertable     
--------------------------
 (12,public,conditions,t)
(1 row)

alter table conditions set (
  timescaledb.compress,
  timescaledb.compress_segmentby = 'location,temperature',
  timescaledb.compress_orderby = 'time'
);
-------------------------------------------------------------------------------
-- Set hypercore access method on the hypertable
-------------------------------------------------------------------------------
alter table conditions set access method hypercore;
WARNING:  the hypercore access method is marked as deprecated with the 2.21.0 release and will be fully removed in the 2.22.0 release.
-----------------------
-- Create a new user
-----------------------
create role testuser;
-- Switch to testuser and show that it can't insert into conditions
set role testuser;
\set ON_ERROR_STOP 0
insert into conditions values ('2024-01-02', 'school', 99.5);
ERROR:  permission denied for table conditions
\set ON_ERROR_STOP 1
--
-- Now grant privileges to work on conditions
--
reset role;
grant select,insert,update,delete on conditions to testuser;
set role testuser;
select current_user;
 current_user 
--------------
 testuser
(1 row)

select * from show_chunks('conditions') ch
join _timescaledb_catalog.compression_settings cs on (cs.relid = ch);
 ch | relid | compress_relid | segmentby | orderby | orderby_desc | orderby_nullsfirst 
----+-------+----------------+-----------+---------+--------------+--------------------
(0 rows)

-- An insert should create a new hypercore chunk, including the compressed chunk
insert into conditions values ('2024-01-02', 'school', 99.5);
-- Show hypertable owner
select relname, relowner::regrole
from pg_class
where relname = 'conditions';
  relname   |  relowner   
------------+-------------
 conditions | test_role_1
(1 row)

-- Show that the new chunk has same owner as hypertable, although
-- testuser did the insert.
select chunk, am.amname, cs.compress_relid, cl.relowner::regrole as chunk_owner, ccl.relowner::regrole as compress_chunk_owner
  from show_chunks('conditions') as chunk
  join _timescaledb_catalog.compression_settings cs on (cs.relid = chunk)
  join pg_class cl on (cl.oid = chunk)
  join pg_class ccl on (ccl.oid = cs.compress_relid)
  join pg_am am on (cl.relam = am.oid);
                  chunk                   |  amname   |                  compress_relid                  | chunk_owner | compress_chunk_owner 
------------------------------------------+-----------+--------------------------------------------------+-------------+----------------------
 _timescaledb_internal._hyper_12_48_chunk | hypercore | _timescaledb_internal.compress_hyper_13_49_chunk | test_role_1 | test_role_1
(1 row)

-- Data is not compressed
select _timescaledb_debug.is_compressed_tid(ctid), * from conditions;
 is_compressed_tid |             time             | location | temperature 
-------------------+------------------------------+----------+-------------
 f                 | Tue Jan 02 00:00:00 2024 PST | school   |        99.5
(1 row)

select compress_chunk(ch) from show_chunks('conditions') ch;
              compress_chunk              
------------------------------------------
 _timescaledb_internal._hyper_12_48_chunk
(1 row)

-- Now the data is compressed
select _timescaledb_debug.is_compressed_tid(ctid), * from conditions;
 is_compressed_tid |             time             | location | temperature 
-------------------+------------------------------+----------+-------------
 t                 | Tue Jan 02 00:00:00 2024 PST | school   |        99.5
(1 row)

reset role;
-- Need to revoke privileges to drop user
revoke all on conditions from testuser;
drop role testuser;
