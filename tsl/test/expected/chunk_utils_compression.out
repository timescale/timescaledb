-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
--------------------------------------------------------------------------
-- show_chunks and drop_chunks functions on a compressed table
-- (issue https://github.com/timescale/timescaledb/issues/1535)
-- create a table that will not be compressed
CREATE TABLE public.uncompressed_table(time date NOT NULL, temp float8, device_id text);
CREATE INDEX ON public.uncompressed_table(time DESC);
SELECT create_hypertable('public.uncompressed_table', 'time', chunk_time_interval => interval '1 day');
        create_hypertable        
---------------------------------
 (1,public,uncompressed_table,t)
(1 row)

INSERT INTO public.uncompressed_table VALUES('2020-03-01', 1.0, 'dev1');
INSERT INTO public.uncompressed_table VALUES('2020-03-05', 2.0, 'dev1');
INSERT INTO public.uncompressed_table VALUES('2020-03-07', 3.0, 'dev1');
INSERT INTO public.uncompressed_table VALUES('2020-03-08', 4.0, 'dev7');
INSERT INTO public.uncompressed_table VALUES('2020-03-09', 5.0, 'dev7');
INSERT INTO public.uncompressed_table VALUES('2020-03-10', 6.0, 'dev7');
-- create next table that is going to be compressed:
CREATE TABLE public.table_to_compress (time date NOT NULL, acq_id bigint, value bigint);
CREATE INDEX idx_table_to_compress_acq_id ON public.table_to_compress(acq_id);
SELECT create_hypertable('public.table_to_compress', 'time', chunk_time_interval => interval '1 day');
       create_hypertable        
--------------------------------
 (2,public,table_to_compress,t)
(1 row)

ALTER TABLE public.table_to_compress SET (timescaledb.compress, timescaledb.compress_segmentby = 'acq_id');
INSERT INTO public.table_to_compress VALUES ('2020-01-01', 1234567, 777888);
INSERT INTO public.table_to_compress VALUES ('2020-02-01', 567567, 890890);
INSERT INTO public.table_to_compress VALUES ('2020-02-10', 1234, 5678);
SELECT show_chunks('public.uncompressed_table');
              show_chunks               
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_2_chunk
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_4_chunk
 _timescaledb_internal._hyper_1_5_chunk
 _timescaledb_internal._hyper_1_6_chunk
(6 rows)

SELECT show_chunks('public.table_to_compress');
              show_chunks               
----------------------------------------
 _timescaledb_internal._hyper_2_7_chunk
 _timescaledb_internal._hyper_2_8_chunk
 _timescaledb_internal._hyper_2_9_chunk
(3 rows)

SELECT show_chunks('public.table_to_compress', older_than=>'1 day'::interval);
              show_chunks               
----------------------------------------
 _timescaledb_internal._hyper_2_7_chunk
 _timescaledb_internal._hyper_2_8_chunk
 _timescaledb_internal._hyper_2_9_chunk
(3 rows)

SELECT show_chunks('public.table_to_compress', newer_than=>'1 day'::interval);
 show_chunks 
-------------
(0 rows)

-- compress all chunks of the table:
SELECT compress_chunk(show_chunks('public.table_to_compress'));
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_2_7_chunk
 _timescaledb_internal._hyper_2_8_chunk
 _timescaledb_internal._hyper_2_9_chunk
(3 rows)

-- check that approx size function works. We call VACUUM to ensure all forks exist
VACUUM public.table_to_compress;
SELECT * FROM hypertable_approximate_size('public.table_to_compress');
 hypertable_approximate_size 
-----------------------------
                      262144
(1 row)

SELECT * FROM hypertable_size('public.table_to_compress');
 hypertable_size 
-----------------
          262144
(1 row)

-- and run the queries again to make sure results are the same
SELECT show_chunks('public.uncompressed_table');
              show_chunks               
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_2_chunk
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_4_chunk
 _timescaledb_internal._hyper_1_5_chunk
 _timescaledb_internal._hyper_1_6_chunk
(6 rows)

SELECT show_chunks('public.table_to_compress');
              show_chunks               
----------------------------------------
 _timescaledb_internal._hyper_2_7_chunk
 _timescaledb_internal._hyper_2_8_chunk
 _timescaledb_internal._hyper_2_9_chunk
(3 rows)

SELECT show_chunks('public.table_to_compress', older_than=>'1 day'::interval);
              show_chunks               
----------------------------------------
 _timescaledb_internal._hyper_2_7_chunk
 _timescaledb_internal._hyper_2_8_chunk
 _timescaledb_internal._hyper_2_9_chunk
(3 rows)

SELECT show_chunks('public.table_to_compress', newer_than=>'1 day'::interval);
 show_chunks 
-------------
(0 rows)

-- truncate one compressed chunk
SELECT chunk_schema || '.' || chunk_name as "CHNAME"
FROM timescaledb_information.chunks
WHERE hypertable_name = 'table_to_compress' and hypertable_schema = 'public'
ORDER BY chunk_name LIMIT 1
\gset
SELECT count(*) FROM :CHNAME;
 count 
-------
     1
(1 row)

TRUNCATE TABLE :CHNAME;
SELECT count(*) FROM :CHNAME;
 count 
-------
     0
(1 row)

-- drop all hypertables' old chunks
SELECT drop_chunks(table_name::regclass, older_than=>'1 day'::interval)
  FROM _timescaledb_catalog.hypertable
 WHERE schema_name = current_schema()
ORDER BY table_name DESC;
              drop_chunks               
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_2_chunk
 _timescaledb_internal._hyper_1_3_chunk
 _timescaledb_internal._hyper_1_4_chunk
 _timescaledb_internal._hyper_1_5_chunk
 _timescaledb_internal._hyper_1_6_chunk
 _timescaledb_internal._hyper_2_7_chunk
 _timescaledb_internal._hyper_2_8_chunk
 _timescaledb_internal._hyper_2_9_chunk
(9 rows)

SELECT show_chunks('public.uncompressed_table');
 show_chunks 
-------------
(0 rows)

SELECT show_chunks('public.table_to_compress');
 show_chunks 
-------------
(0 rows)

-- test calling on internal compressed table
SELECT
  format('%I.%I', ht.schema_name, ht.table_name) AS "TABLENAME"
FROM
  _timescaledb_catalog.hypertable ht
  INNER JOIN _timescaledb_catalog.hypertable uncompress ON (ht.id = uncompress.compressed_hypertable_id
      AND uncompress.table_name = 'table_to_compress') \gset
\set ON_ERROR_STOP 0
SELECT show_chunks(:'TABLENAME');
ERROR:  invalid operation on compressed hypertable
SELECT drop_chunks(:'TABLENAME',now());
ERROR:  hypertable has no open partitioning dimension
\set ON_ERROR_STOP 1
