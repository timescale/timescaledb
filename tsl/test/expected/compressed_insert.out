-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
CREATE TABLE metrics (time TIMESTAMPTZ NOT NULL, device TEXT, value float) WITH (tsdb.hypertable, tsdb.orderby='time');
NOTICE:  using column "time" as partitioning column
-- first try without the GUCs
BEGIN;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz + (i || ' hour')::interval, 'd1', i::float FROM generate_series(0,100) i;
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                         QUERY PLAN                          
-------------------------------------------------------------
 Append (actual rows=101.00 loops=1)
   ->  Seq Scan on _hyper_1_1_chunk (actual rows=16.00 loops=1)
   ->  Seq Scan on _hyper_1_2_chunk (actual rows=85.00 loops=1)
(3 rows)

-- should have no status aka normal uncompressed chunk
SELECT DISTINCT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics') chunk;
 chunk_status_text 
-------------------
 {}
(1 row)

ROLLBACK;
SET timescaledb.enable_direct_compress_insert = true;
SET timescaledb.enable_direct_compress_insert_sort_batches = true;
SET timescaledb.enable_direct_compress_insert_client_sorted = false;
-- EXPLAIN with too small batch
EXPLAIN (BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) INSERT INTO metrics SELECT '2025-01-01'::timestamptz, 'd1', i::float FROM generate_series(0,5) i;
WARNING:  disabling direct compress because of too small batch size
                   QUERY PLAN                   
------------------------------------------------
 Custom Scan (ModifyHypertable)
   Direct Compress: false
   ->  Insert on metrics
         ->  Function Scan on generate_series i
(4 rows)

-- EXPLAIN with large enough batch
EXPLAIN (BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) INSERT INTO metrics SELECT '2025-01-01'::timestamptz, 'd1', i::float FROM generate_series(0,500) i;
                   QUERY PLAN                   
------------------------------------------------
 Custom Scan (ModifyHypertable)
   Direct Compress: true
   ->  Insert on metrics
         ->  Function Scan on generate_series i
(4 rows)

-- simple test with compressed insert enabled
BEGIN;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,3000) i;
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                                   QUERY PLAN                                    
---------------------------------------------------------------------------------
 Append (actual rows=3001.00 loops=1)
   ->  Custom Scan (ColumnarScan) on _hyper_1_3_chunk (actual rows=960.00 loops=1)
         ->  Seq Scan on compress_hyper_2_4_chunk (actual rows=1.00 loops=1)
   ->  Custom Scan (ColumnarScan) on _hyper_1_5_chunk (actual rows=2041.00 loops=1)
         ->  Seq Scan on compress_hyper_2_6_chunk (actual rows=3.00 loops=1)
(5 rows)

SELECT first(time,rn), last(time,rn) FROM (SELECT ROW_NUMBER() OVER () as rn, time FROM metrics) sub;
            first             |             last             
------------------------------+------------------------------
 Wed Jan 01 00:00:00 2025 PST | Fri Jan 03 02:00:00 2025 PST
(1 row)

-- since the chunks are new status should be COMPRESSED, UNORDERED
SELECT DISTINCT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics') chunk;
   chunk_status_text    
------------------------
 {COMPRESSED,UNORDERED}
(1 row)

ROLLBACK;
-- simple test with compressed insert enabled and reversed order
BEGIN;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,3000) i;
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                                   QUERY PLAN                                    
---------------------------------------------------------------------------------
 Append (actual rows=3001.00 loops=1)
   ->  Custom Scan (ColumnarScan) on _hyper_1_7_chunk (actual rows=960.00 loops=1)
         ->  Seq Scan on compress_hyper_2_8_chunk (actual rows=1.00 loops=1)
   ->  Custom Scan (ColumnarScan) on _hyper_1_9_chunk (actual rows=2041.00 loops=1)
         ->  Seq Scan on compress_hyper_2_10_chunk (actual rows=3.00 loops=1)
(5 rows)

SELECT first(time,rn), last(time,rn) FROM (SELECT ROW_NUMBER() OVER () as rn, time FROM metrics) sub;
            first             |             last             
------------------------------+------------------------------
 Wed Jan 01 00:00:00 2025 PST | Fri Jan 03 02:00:00 2025 PST
(1 row)

-- since the chunks are new status should be COMPRESSED, UNORDERED
SELECT DISTINCT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics') chunk;
   chunk_status_text    
------------------------
 {COMPRESSED,UNORDERED}
(1 row)

ROLLBACK;
SET timescaledb.enable_direct_compress_insert_sort_batches = false;
-- simple test with compressed insert enabled and without batch sorting
BEGIN;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,3000) i;
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                                    QUERY PLAN                                    
----------------------------------------------------------------------------------
 Append (actual rows=3001.00 loops=1)
   ->  Custom Scan (ColumnarScan) on _hyper_1_11_chunk (actual rows=960.00 loops=1)
         ->  Seq Scan on compress_hyper_2_12_chunk (actual rows=1.00 loops=1)
   ->  Custom Scan (ColumnarScan) on _hyper_1_13_chunk (actual rows=2041.00 loops=1)
         ->  Seq Scan on compress_hyper_2_14_chunk (actual rows=3.00 loops=1)
(5 rows)

SELECT first(time,rn), last(time,rn) FROM (SELECT ROW_NUMBER() OVER () as rn, time FROM metrics) sub;
            first             |             last             
------------------------------+------------------------------
 Wed Jan 01 00:00:00 2025 PST | Fri Jan 03 02:00:00 2025 PST
(1 row)

-- since the chunks are new status should be COMPRESSED, UNORDERED
SELECT DISTINCT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics') chunk;
   chunk_status_text    
------------------------
 {COMPRESSED,UNORDERED}
(1 row)

ROLLBACK;
-- simple test with compressed insert enabled and reversed order and no batch sorting
BEGIN;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz - (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,3000) i;
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                                 QUERY PLAN                                 
----------------------------------------------------------------------------
 Custom Scan (ColumnarScan) on _hyper_1_15_chunk (actual rows=3001.00 loops=1)
   ->  Seq Scan on compress_hyper_2_16_chunk (actual rows=4.00 loops=1)
(2 rows)

SELECT first(time,rn), last(time,rn) FROM (SELECT ROW_NUMBER() OVER () as rn, time FROM metrics) sub;
            first             |             last             
------------------------------+------------------------------
 Wed Jan 01 00:00:00 2025 PST | Sun Dec 29 22:00:00 2024 PST
(1 row)

-- since the chunks are new status should be COMPRESSED, UNORDERED
SELECT DISTINCT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics') chunk;
   chunk_status_text    
------------------------
 {COMPRESSED,UNORDERED}
(1 row)

ROLLBACK;
-- test compressing into uncompressed chunk
RESET timescaledb.enable_direct_compress_insert;
RESET timescaledb.enable_direct_compress_insert_sort_batches;
RESET timescaledb.enable_direct_compress_insert_client_sorted;
BEGIN;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,3000) i;
SET timescaledb.enable_direct_compress_insert = true;
SET timescaledb.enable_direct_compress_insert_client_sorted = true;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,3000) i;
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                                    QUERY PLAN                                    
----------------------------------------------------------------------------------
 Append (actual rows=6002.00 loops=1)
   ->  Custom Scan (ColumnarScan) on _hyper_1_17_chunk (actual rows=960.00 loops=1)
         ->  Seq Scan on compress_hyper_2_19_chunk (actual rows=1.00 loops=1)
   ->  Seq Scan on _hyper_1_17_chunk (actual rows=960.00 loops=1)
   ->  Custom Scan (ColumnarScan) on _hyper_1_18_chunk (actual rows=2041.00 loops=1)
         ->  Seq Scan on compress_hyper_2_20_chunk (actual rows=3.00 loops=1)
   ->  Seq Scan on _hyper_1_18_chunk (actual rows=2041.00 loops=1)
(7 rows)

-- since the chunks are new status should be COMPRESSED, PARTIAL
SELECT DISTINCT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics') chunk;
  chunk_status_text   
----------------------
 {COMPRESSED,PARTIAL}
(1 row)

ROLLBACK;
-- simple test with compressed insert enabled and reversed order
BEGIN;
SET timescaledb.enable_direct_compress_insert = true;
SET timescaledb.enable_direct_compress_insert_client_sorted = true;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz - (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,3000) i;
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                                 QUERY PLAN                                 
----------------------------------------------------------------------------
 Custom Scan (ColumnarScan) on _hyper_1_21_chunk (actual rows=3001.00 loops=1)
   ->  Seq Scan on compress_hyper_2_22_chunk (actual rows=4.00 loops=1)
(2 rows)

-- since the chunks are new status should be COMPRESSED
SELECT DISTINCT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics') chunk;
 chunk_status_text 
-------------------
 {COMPRESSED}
(1 row)

ROLLBACK;
-- simple test with compressed insert enabled and no presorted
BEGIN;
SET timescaledb.enable_direct_compress_insert = true;
SET timescaledb.enable_direct_compress_insert_client_sorted = false;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz - (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,3000) i;
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                                 QUERY PLAN                                 
----------------------------------------------------------------------------
 Custom Scan (ColumnarScan) on _hyper_1_23_chunk (actual rows=3001.00 loops=1)
   ->  Seq Scan on compress_hyper_2_24_chunk (actual rows=4.00 loops=1)
(2 rows)

-- since the chunks are new status should be COMPRESSED, UNORDERED
SELECT DISTINCT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics') chunk;
   chunk_status_text    
------------------------
 {COMPRESSED,UNORDERED}
(1 row)

ROLLBACK;
-- simple test with compressed insert enabled and no presorted and with uncompressed data
BEGIN;
SET timescaledb.enable_direct_compress_insert = true;
SET timescaledb.enable_direct_compress_insert_client_sorted = false;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz, 'd1', 0;
WARNING:  disabling direct compress because of too small batch size
INSERT INTO metrics SELECT '2025-01-01'::timestamptz - (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,3000) i;
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                                    QUERY PLAN                                    
----------------------------------------------------------------------------------
 Append (actual rows=3002.00 loops=1)
   ->  Custom Scan (ColumnarScan) on _hyper_1_25_chunk (actual rows=3001.00 loops=1)
         ->  Seq Scan on compress_hyper_2_26_chunk (actual rows=4.00 loops=1)
   ->  Seq Scan on _hyper_1_25_chunk (actual rows=1.00 loops=1)
(4 rows)

-- since the chunks are new status should be COMPRESSED, UNORDERED, PARTIAL
SELECT DISTINCT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics') chunk;
       chunk_status_text        
--------------------------------
 {COMPRESSED,UNORDERED,PARTIAL}
(1 row)

ROLLBACK;
-- test with segmentby
BEGIN;
ALTER TABLE metrics SET (tsdb.segmentby = 'device');
SET timescaledb.enable_direct_compress_insert = true;
SET timescaledb.enable_direct_compress_insert_client_sorted = true;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz - (i || ' minute')::interval, floor(i), i::float FROM generate_series(0.0,9.8,0.2) i;
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                                QUERY PLAN                                
--------------------------------------------------------------------------
 Custom Scan (ColumnarScan) on _hyper_1_27_chunk (actual rows=50.00 loops=1)
   ->  Seq Scan on compress_hyper_2_28_chunk (actual rows=10.00 loops=1)
(2 rows)

SELECT format('%I.%I',schema_name,table_name) AS "COMPRESSED_CHUNK" FROM _timescaledb_catalog.chunk where compressed_chunk_id IS NULL \gset
-- should have 10 batches
SELECT count(*) FROM :COMPRESSED_CHUNK;
 count 
-------
    10
(1 row)

-- since the chunks are new status should be COMPRESSED
SELECT DISTINCT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics') chunk;
 chunk_status_text 
-------------------
 {COMPRESSED}
(1 row)

ROLLBACK;
-- test unique constraints prevent direct compress
BEGIN;
SET timescaledb.enable_direct_compress_insert = true;
ALTER TABLE metrics ADD CONSTRAINT unique_time_device UNIQUE (time, device);
INSERT INTO metrics SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,100) i;
WARNING:  disabling direct compress because the destination table has unique constraints
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                       QUERY PLAN                        
---------------------------------------------------------
 Seq Scan on _hyper_1_29_chunk (actual rows=101.00 loops=1)
(1 row)

SELECT DISTINCT status FROM _timescaledb_catalog.chunk WHERE compressed_chunk_id IS NOT NULL;
 status 
--------
(0 rows)

ROLLBACK;
-- test triggers prevent direct compress
BEGIN;
SET timescaledb.enable_direct_compress_insert = true;
CREATE OR REPLACE FUNCTION test_trigger() RETURNS TRIGGER AS $$ BEGIN RETURN NEW; END; $$ LANGUAGE plpgsql;
CREATE TRIGGER metrics_trigger BEFORE INSERT OR UPDATE ON metrics FOR EACH ROW EXECUTE FUNCTION test_trigger();
INSERT INTO metrics SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,100) i;
WARNING:  disabling direct compress because the destination table has triggers
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                       QUERY PLAN                        
---------------------------------------------------------
 Seq Scan on _hyper_1_30_chunk (actual rows=101.00 loops=1)
(1 row)

SELECT DISTINCT status FROM _timescaledb_catalog.chunk WHERE compressed_chunk_id IS NOT NULL;
 status 
--------
(0 rows)

ROLLBACK;
-- test caggs prevent direct compress
BEGIN;
SET timescaledb.enable_direct_compress_insert = true;
CREATE MATERIALIZED VIEW metrics_cagg WITH (tsdb.continuous) AS SELECT time_bucket('1 hour', time) AS bucket, device, avg(value) AS avg_value FROM metrics GROUP BY bucket, device WITH NO DATA;
INSERT INTO metrics SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval, 'd1', i::float FROM generate_series(0,100) i;
WARNING:  disabling direct compress because the destination table has triggers
EXPLAIN (ANALYZE, BUFFERS OFF, COSTS OFF, SUMMARY OFF, TIMING OFF) SELECT * FROM metrics;
                       QUERY PLAN                        
---------------------------------------------------------
 Seq Scan on _hyper_1_31_chunk (actual rows=101.00 loops=1)
(1 row)

SELECT DISTINCT status FROM _timescaledb_catalog.chunk WHERE compressed_chunk_id IS NOT NULL;
 status 
--------
(0 rows)

ROLLBACK;
-- test chunk status handling
CREATE TABLE metrics_status(time timestamptz) WITH (tsdb.hypertable,tsdb.partition_column='time');
INSERT INTO metrics_status SELECT '2025-01-01';
-- normal insert should result in chunk status 0
SELECT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics_status') chunk;
 chunk_status_text 
-------------------
 {}
(1 row)

SET timescaledb.enable_direct_compress_insert = true;
BEGIN;
INSERT INTO metrics_status SELECT '2025-01-01' FROM generate_series(1,9);
WARNING:  disabling direct compress because of too small batch size
-- small insert batches should not result in compressed chunk
SELECT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics_status') chunk;
 chunk_status_text 
-------------------
 {}
(1 row)

ROLLBACK;
BEGIN;
INSERT INTO metrics_status SELECT '2025-01-01' FROM generate_series(1,10);
-- status should be COMPRESSED, UNORDERED, PARTIAL since we have more than 10 rows in the chunk
SELECT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics_status') chunk;
       chunk_status_text        
--------------------------------
 {COMPRESSED,UNORDERED,PARTIAL}
(1 row)

ROLLBACK;
BEGIN;
-- compressed sorted copy into uncompressed chunk should result in chunk status 9 (compressed,partial)
SET timescaledb.enable_direct_compress_insert = true;
SET timescaledb.enable_direct_compress_insert_client_sorted = true;
INSERT INTO metrics_status SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval FROM generate_series(0,100) i;
-- status should be COMPRESSED, PARTIAL
SELECT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics_status') chunk;
  chunk_status_text   
----------------------
 {COMPRESSED,PARTIAL}
(1 row)

ROLLBACK;
TRUNCATE metrics_status;
BEGIN;
-- compressed insert into new chunk should result in chunk status 3 (compressed,unordered)
SET timescaledb.enable_direct_compress_insert = true;
SET timescaledb.enable_direct_compress_insert_client_sorted = false;
INSERT INTO metrics_status SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval FROM generate_series(0,100) i;
-- status should be COMPRESSED, UNORDERED
SELECT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics_status') chunk;
   chunk_status_text    
------------------------
 {COMPRESSED,UNORDERED}
(1 row)

ROLLBACK;
BEGIN;
-- compressed sorted copy into new chunk should result in chunk status 1 (compressed)
SET timescaledb.enable_direct_compress_insert = true;
SET timescaledb.enable_direct_compress_insert_client_sorted = true;
INSERT INTO metrics_status SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval FROM generate_series(0,100) i;
-- status should be COMPRESSED
SELECT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics_status') chunk;
 chunk_status_text 
-------------------
 {COMPRESSED}
(1 row)

ROLLBACK;
SET timescaledb.enable_direct_compress_insert = false;
SET timescaledb.enable_direct_compress_insert_client_sorted = false;
INSERT INTO metrics_status SELECT '2025-01-01';
-- no status aka normal uncompressed chunk
SELECT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics_status') chunk;
 chunk_status_text 
-------------------
 {}
(1 row)

SELECT compress_chunk(show_chunks('metrics_status'));
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_4_39_chunk
(1 row)

-- status should be COMPRESSED
SELECT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics_status') chunk;
 chunk_status_text 
-------------------
 {COMPRESSED}
(1 row)

BEGIN;
-- compressed insert into fully compressed chunk should result in chunk status 3 (compressed,unordered)
SET timescaledb.enable_direct_compress_insert = true;
SET timescaledb.enable_direct_compress_insert_client_sorted = false;
INSERT INTO metrics_status SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval FROM generate_series(0,100) i;
-- status should be COMPRESSED, UNORDERED
SELECT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics_status') chunk;
   chunk_status_text    
------------------------
 {COMPRESSED,UNORDERED}
(1 row)

ROLLBACK;
BEGIN;
-- compressed insert new chunk should result in chunk status 1 (compressed)
SET timescaledb.enable_direct_compress_insert = true;
SET timescaledb.enable_direct_compress_insert_client_sorted = true;
INSERT INTO metrics_status SELECT '2025-01-01'::timestamptz + (i || ' minute')::interval FROM generate_series(0,100) i;
-- status should be COMPRESSED
SELECT _timescaledb_functions.chunk_status_text(chunk) FROM show_chunks('metrics_status') chunk;
 chunk_status_text 
-------------------
 {COMPRESSED}
(1 row)

ROLLBACK;
