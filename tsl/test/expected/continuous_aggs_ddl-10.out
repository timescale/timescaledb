-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- Set this variable to avoid using a hard-coded path each time query
-- results are compared
\set QUERY_RESULT_TEST_EQUAL_RELPATH '../../../test/sql/include/query_result_test_equal.sql'
\set ON_ERROR_STOP 0
--DDL commands on continuous aggregates
CREATE TABLE conditions (
      timec        TIMESTAMPTZ       NOT NULL,
      location    TEXT              NOT NULL,
      temperature integer  NULL,
      humidity    DOUBLE PRECISION  NULL,
      timemeasure TIMESTAMPTZ,
      timeinterval INTERVAL
);
select table_name from create_hypertable('conditions', 'timec');
 table_name 
------------
 conditions
(1 row)

-- check that GRANTS work correctly
\c :TEST_DBNAME :ROLE_SUPERUSER
SELECT _timescaledb_internal.stop_background_workers();
 stop_background_workers 
-------------------------
 t
(1 row)

create  view mat_m1 WITH ( timescaledb.continuous)
AS
Select sum( temperature ), min(location)
from conditions
group by time_bucket('1week', timec);
GRANT select on mat_m1 to :ROLE_DEFAULT_PERM_USER;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER_2
select count(*) from mat_m1;
ERROR:  permission denied for relation mat_m1
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
select count(*) from mat_m1;
 count 
-------
     0
(1 row)

\set ON_ERROR_STOP 1
-- schema tests
\c :TEST_DBNAME :ROLE_SUPERUSER
CREATE SCHEMA rename_schema;
GRANT ALL ON SCHEMA rename_schema TO :ROLE_DEFAULT_PERM_USER;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
CREATE TABLE foo(time TIMESTAMPTZ, data INTEGER);
SELECT create_hypertable('foo', 'time');
NOTICE:  adding not-null constraint to column "time"
 create_hypertable 
-------------------
 (3,public,foo,t)
(1 row)

CREATE VIEW rename_test WITH ( timescaledb.continuous)
AS SELECT time_bucket('1week', time), COUNT(data)
    FROM foo
    GROUP BY 1;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  partial_view_schema  | partial_view_name 
------------------+----------------+-----------------------+-------------------
 public           | mat_m1         | _timescaledb_internal | _partial_view_2
 public           | rename_test    | _timescaledb_internal | _partial_view_4
(2 rows)

ALTER VIEW rename_test SET SCHEMA rename_schema;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  partial_view_schema  | partial_view_name 
------------------+----------------+-----------------------+-------------------
 public           | mat_m1         | _timescaledb_internal | _partial_view_2
 rename_schema    | rename_test    | _timescaledb_internal | _partial_view_4
(2 rows)

SELECT ca.raw_hypertable_id as "RAW_HYPERTABLE_ID",
       h.schema_name AS "MAT_SCHEMA_NAME",
       h.table_name AS "MAT_TABLE_NAME",
       partial_view_name as "PART_VIEW_NAME",
       partial_view_schema as "PART_VIEW_SCHEMA",
       direct_view_name as "DIR_VIEW_NAME",
       direct_view_schema as "DIR_VIEW_SCHEMA"
FROM _timescaledb_catalog.continuous_agg ca
INNER JOIN _timescaledb_catalog.hypertable h ON(h.id = ca.mat_hypertable_id)
WHERE user_view_name = 'rename_test'
\gset
\c :TEST_DBNAME :ROLE_SUPERUSER
ALTER VIEW :"PART_VIEW_SCHEMA".:"PART_VIEW_NAME" SET SCHEMA public;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  partial_view_schema  | partial_view_name 
------------------+----------------+-----------------------+-------------------
 public           | mat_m1         | _timescaledb_internal | _partial_view_2
 rename_schema    | rename_test    | public                | _partial_view_4
(2 rows)

--alter direct view schema
SELECT user_view_schema, user_view_name, direct_view_schema, direct_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  direct_view_schema   | direct_view_name 
------------------+----------------+-----------------------+------------------
 public           | mat_m1         | _timescaledb_internal | _direct_view_2
 rename_schema    | rename_test    | _timescaledb_internal | _direct_view_4
(2 rows)

\c :TEST_DBNAME :ROLE_SUPERUSER
ALTER VIEW :"DIR_VIEW_SCHEMA".:"DIR_VIEW_NAME" SET SCHEMA public;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name,
      direct_view_schema, direct_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  partial_view_schema  | partial_view_name |  direct_view_schema   | direct_view_name 
------------------+----------------+-----------------------+-------------------+-----------------------+------------------
 public           | mat_m1         | _timescaledb_internal | _partial_view_2   | _timescaledb_internal | _direct_view_2
 rename_schema    | rename_test    | public                | _partial_view_4   | public                | _direct_view_4
(2 rows)

\c :TEST_DBNAME :ROLE_SUPERUSER
ALTER SCHEMA rename_schema RENAME TO new_name_schema;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  partial_view_schema  | partial_view_name 
------------------+----------------+-----------------------+-------------------
 public           | mat_m1         | _timescaledb_internal | _partial_view_2
 new_name_schema  | rename_test    | public                | _partial_view_4
(2 rows)

ALTER VIEW :"PART_VIEW_NAME" SET SCHEMA new_name_schema;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  partial_view_schema  | partial_view_name 
------------------+----------------+-----------------------+-------------------
 public           | mat_m1         | _timescaledb_internal | _partial_view_2
 new_name_schema  | rename_test    | new_name_schema       | _partial_view_4
(2 rows)

\c :TEST_DBNAME :ROLE_SUPERUSER
ALTER SCHEMA new_name_schema RENAME TO foo_name_schema;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  partial_view_schema  | partial_view_name 
------------------+----------------+-----------------------+-------------------
 public           | mat_m1         | _timescaledb_internal | _partial_view_2
 foo_name_schema  | rename_test    | foo_name_schema       | _partial_view_4
(2 rows)

ALTER VIEW foo_name_schema.rename_test SET SCHEMA public;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  partial_view_schema  | partial_view_name 
------------------+----------------+-----------------------+-------------------
 public           | mat_m1         | _timescaledb_internal | _partial_view_2
 public           | rename_test    | foo_name_schema       | _partial_view_4
(2 rows)

\c :TEST_DBNAME :ROLE_SUPERUSER
ALTER SCHEMA foo_name_schema RENAME TO rename_schema;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  partial_view_schema  | partial_view_name 
------------------+----------------+-----------------------+-------------------
 public           | mat_m1         | _timescaledb_internal | _partial_view_2
 public           | rename_test    | rename_schema         | _partial_view_4
(2 rows)

ALTER VIEW rename_test RENAME TO rename_c_aggregate;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema |   user_view_name   |  partial_view_schema  | partial_view_name 
------------------+--------------------+-----------------------+-------------------
 public           | mat_m1             | _timescaledb_internal | _partial_view_2
 public           | rename_c_aggregate | rename_schema         | _partial_view_4
(2 rows)

SELECT * FROM rename_c_aggregate;
 time_bucket | count 
-------------+-------
(0 rows)

ALTER VIEW rename_schema.:"PART_VIEW_NAME" RENAME TO partial_view;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name,
      direct_view_schema, direct_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema |   user_view_name   |  partial_view_schema  | partial_view_name |  direct_view_schema   | direct_view_name 
------------------+--------------------+-----------------------+-------------------+-----------------------+------------------
 public           | mat_m1             | _timescaledb_internal | _partial_view_2   | _timescaledb_internal | _direct_view_2
 public           | rename_c_aggregate | rename_schema         | partial_view      | public                | _direct_view_4
(2 rows)

--rename direct view
ALTER VIEW :"DIR_VIEW_NAME" RENAME TO direct_view;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name,
      direct_view_schema, direct_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema |   user_view_name   |  partial_view_schema  | partial_view_name |  direct_view_schema   | direct_view_name 
------------------+--------------------+-----------------------+-------------------+-----------------------+------------------
 public           | mat_m1             | _timescaledb_internal | _partial_view_2   | _timescaledb_internal | _direct_view_2
 public           | rename_c_aggregate | rename_schema         | partial_view      | public                | direct_view
(2 rows)

-- drop_chunks tests
DROP TABLE conditions CASCADE;
NOTICE:  drop cascades to 2 other objects
DROP TABLE foo CASCADE;
NOTICE:  drop cascades to 2 other objects
CREATE TABLE drop_chunks_table(time BIGINT, data INTEGER);
SELECT hypertable_id AS drop_chunks_table_id
    FROM create_hypertable('drop_chunks_table', 'time', chunk_time_interval => 10) \gset
NOTICE:  adding not-null constraint to column "time"
CREATE OR REPLACE FUNCTION integer_now_test() returns bigint LANGUAGE SQL STABLE as $$ SELECT coalesce(max(time), bigint '0') FROM drop_chunks_table $$;
SELECT set_integer_now_func('drop_chunks_table', 'integer_now_test');
 set_integer_now_func 
----------------------
 
(1 row)

CREATE VIEW drop_chunks_view WITH ( timescaledb.continuous, timescaledb.refresh_interval='72 hours')
AS SELECT time_bucket('5', time), COUNT(data)
    FROM drop_chunks_table
    GROUP BY 1;
SELECT format('%s.%s', schema_name, table_name) AS drop_chunks_mat_table,
        schema_name AS drop_chunks_mat_schema,
        table_name AS drop_chunks_mat_table_name
    FROM _timescaledb_catalog.hypertable, _timescaledb_catalog.continuous_agg
    WHERE _timescaledb_catalog.continuous_agg.raw_hypertable_id = :drop_chunks_table_id
        AND _timescaledb_catalog.hypertable.id = _timescaledb_catalog.continuous_agg.mat_hypertable_id \gset
-- create 3 chunks, with 3 time bucket
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(0, 29) AS i;
REFRESH MATERIALIZED VIEW drop_chunks_view;
INFO:  new materialization range for public.drop_chunks_table (time column time) (15)
INFO:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 15
SELECT count(c) FROM show_chunks('drop_chunks_table') AS c;
 count 
-------
     3
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           0 |     5
           5 |     5
          10 |     5
(3 rows)

-- cannot drop directly from the materialization table
\set ON_ERROR_STOP 0
SELECT drop_chunks(schema_name => :'drop_chunks_mat_schema',
    table_name => :'drop_chunks_mat_table_name',
    newer_than => -20,
    verbose => true);
ERROR:  cannot drop_chunks on a continuous aggregate materialization table
SELECT drop_chunks(
    newer_than => -20,
    verbose => true,
    cascade_to_materializations=>true);
INFO:  dropping chunk _timescaledb_internal._hyper_5_1_chunk
INFO:  dropping chunk _timescaledb_internal._hyper_5_2_chunk
INFO:  dropping chunk _timescaledb_internal._hyper_5_3_chunk
ERROR:  cannot drop_chunks on a continuous aggregate materialization table
\set ON_ERROR_STOP 1
SELECT count(c) FROM show_chunks('drop_chunks_table') AS c;
 count 
-------
     3
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           0 |     5
           5 |     5
          10 |     5
(3 rows)

-- cannot drop from the raw table without specifying cascade_to_materializations
\set ON_ERROR_STOP 0
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => 10);
ERROR:  cascade_to_materializations options must be set explicitly
\set ON_ERROR_STOP 1
SELECT count(c) FROM show_chunks('drop_chunks_table') AS c;
 count 
-------
     3
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           0 |     5
           5 |     5
          10 |     5
(3 rows)

\set ON_ERROR_STOP 0
SELECT drop_chunks(older_than => 200);
ERROR:  cascade_to_materializations options must be set explicitly
\set ON_ERROR_STOP 1
SELECT count(c) FROM show_chunks('drop_chunks_table') AS c;
 count 
-------
     3
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           0 |     5
           5 |     5
          10 |     5
(3 rows)

-- show_chunks and drop_chunks output should be the same
\set QUERY1 'SELECT show_chunks(hypertable => \'drop_chunks_table\', older_than => 13)::REGCLASS::TEXT'
\set QUERY2 'SELECT drop_chunks(table_name => \'drop_chunks_table\', older_than => 13, cascade_to_materializations => true)::TEXT'
\set ECHO errors
 Different Rows | Total Rows from Query 1 | Total Rows from Query 2 
----------------+-------------------------+-------------------------
              0 |                       1 |                       1
(1 row)

SELECT count(c) FROM show_chunks('drop_chunks_table') AS c;
 count 
-------
     2
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
          10 |     5
(1 row)

-- drop chunks when the chunksize and time_bucket aren't aligned
DROP TABLE drop_chunks_table CASCADE;
NOTICE:  drop cascades to 2 other objects
NOTICE:  drop cascades to table _timescaledb_internal._hyper_6_4_chunk
CREATE TABLE drop_chunks_table_u(time BIGINT, data INTEGER);
SELECT hypertable_id AS drop_chunks_table_u_id
    FROM create_hypertable('drop_chunks_table_u', 'time', chunk_time_interval => 7) \gset
NOTICE:  adding not-null constraint to column "time"
CREATE OR REPLACE FUNCTION integer_now_test1() returns bigint LANGUAGE SQL STABLE as $$ SELECT coalesce(max(time), bigint '0') FROM drop_chunks_table_u $$;
SELECT set_integer_now_func('drop_chunks_table_u', 'integer_now_test1');
 set_integer_now_func 
----------------------
 
(1 row)

CREATE VIEW drop_chunks_view WITH ( timescaledb.continuous, timescaledb.refresh_interval='72 hours')
AS SELECT time_bucket('3', time), COUNT(data)
    FROM drop_chunks_table_u
    GROUP BY 1;
SELECT format('%s.%s', schema_name, table_name) AS drop_chunks_mat_table_u,
        schema_name AS drop_chunks_mat_schema,
        table_name AS drop_chunks_mat_table_u_name
    FROM _timescaledb_catalog.hypertable, _timescaledb_catalog.continuous_agg
    WHERE _timescaledb_catalog.continuous_agg.raw_hypertable_id = :drop_chunks_table_u_id
        AND _timescaledb_catalog.hypertable.id = _timescaledb_catalog.continuous_agg.mat_hypertable_id \gset
-- create 3 chunks, with 3 time bucket
INSERT INTO drop_chunks_table_u SELECT i, i FROM generate_series(0, 21) AS i;
REFRESH MATERIALIZED VIEW drop_chunks_view;
INFO:  new materialization range for public.drop_chunks_table_u (time column time) (15)
INFO:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 15
SELECT count(c) FROM show_chunks('drop_chunks_table_u') AS c;
 count 
-------
     4
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table_u') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           0 |     3
           3 |     3
           6 |     3
           9 |     3
          12 |     3
(5 rows)

-- show_chunks and drop_chunks output should be the same
\set QUERY1 'SELECT show_chunks(hypertable => \'drop_chunks_table_u\', older_than => 13)::REGCLASS::TEXT'
\set QUERY2 'SELECT drop_chunks(table_name => \'drop_chunks_table_u\', older_than => 13, cascade_to_materializations => true)::TEXT'
\set ECHO errors
 Different Rows | Total Rows from Query 1 | Total Rows from Query 2 
----------------+-------------------------+-------------------------
              0 |                       1 |                       1
(1 row)

-- everything in the first chunk (values within [0, 6]) should be dropped
-- the time_bucket [6, 8] will lose it's first value, but should still have
-- the other two
SELECT count(c) FROM show_chunks('drop_chunks_table_u') AS c;
 count 
-------
     3
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table_u') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           6 |     2
           9 |     3
          12 |     3
(3 rows)

-- TRUNCATE test
\set ON_ERROR_STOP 0
TRUNCATE drop_chunks_table_u;
ERROR:  cannot TRUNCATE a hypertable that has a continuous aggregate
TRUNCATE :drop_chunks_mat_table_u;
ERROR:  cannot TRUNCATE a hypertable underlying a continuous aggregate
\set ON_ERROR_STOP 1
-- ALTER TABLE tests
\set ON_ERROR_STOP 0
-- test a variety of ALTER TABLE statements
ALTER TABLE :drop_chunks_mat_table_u RENAME chunk_id TO bad_name;
ERROR:  cannot rename column "chunk_id" of materialization table "_materialized_hypertable_8"
ALTER TABLE :drop_chunks_mat_table_u ADD UNIQUE(chunk_id);
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u SET UNLOGGED;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u ENABLE ROW LEVEL SECURITY;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u ADD COLUMN fizzle INTEGER;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u DROP COLUMN chunk_id;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u ALTER COLUMN chunk_id DROP NOT NULL;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u ALTER COLUMN chunk_id SET DEFAULT 1;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u ALTER COLUMN chunk_id SET STORAGE EXTERNAL;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u DISABLE TRIGGER ALL;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u SET TABLESPACE foo;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u NOT OF;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u OWNER TO CURRENT_USER;
ERROR:  operation not supported on materialization tables
\set ON_ERROR_STOP 1
ALTER TABLE :drop_chunks_mat_table_u SET SCHEMA public;
ALTER TABLE :drop_chunks_mat_table_u_name RENAME TO new_name;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
CREATE INDEX new_name_idx ON new_name(chunk_id);
SELECT * FROM new_name;
 time_bucket |      agg_2_2       | chunk_id 
-------------+--------------------+----------
           6 | \x0000000000000002 |        6
           9 | \x0000000000000003 |        6
          12 | \x0000000000000002 |        6
          12 | \x0000000000000001 |        7
(4 rows)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           6 |     2
           9 |     3
          12 |     3
(3 rows)

\set ON_ERROR_STOP 0
-- no continuous aggregates on a continuous aggregate materialization table
CREATE VIEW new_name_view WITH ( timescaledb.continuous, timescaledb.refresh_interval='72 hours')
AS SELECT time_bucket('6', time_bucket), COUNT(agg_2_2)
    FROM new_name
    GROUP BY 1;
ERROR:  hypertable is a continuous aggregate materialization table
-- cannot create a continuous aggregate on a continuous aggregate view
CREATE VIEW drop_chunks_view_view WITH ( timescaledb.continuous, timescaledb.refresh_interval='72 hours')
AS SELECT time_bucket('6', time_bucket), SUM(count)
    FROM drop_chunks_view
    GROUP BY 1;
ERROR:  invalid SELECT query for continuous aggregate
\set ON_ERROR_STOP 1
DROP INDEX new_name_idx;
CREATE TABLE metrics(time timestamptz, device_id int, v1 float, v2 float);
SELECT create_hypertable('metrics','time');
NOTICE:  adding not-null constraint to column "time"
  create_hypertable   
----------------------
 (9,public,metrics,t)
(1 row)

INSERT INTO metrics SELECT generate_series('2000-01-01'::timestamptz,'2000-01-10','1m'),1,0.25,0.75;
-- check expressions in view definition
CREATE VIEW cagg_expr WITH (timescaledb.continuous)
AS
SELECT
  time_bucket('1d', time) AS time,
  'Const'::text AS Const,
  4.3::numeric AS "numeric",
  first(metrics,time),
  CASE WHEN true THEN 'foo' ELSE 'bar' END,
  COALESCE(NULL,'coalesce'),
  avg(v1) + avg(v2) AS avg1,
  avg(v1+v2) AS avg2
FROM metrics
GROUP BY 1;
NOTICE:  adding index _materialized_hypertable_10_const_time_idx ON _timescaledb_internal._materialized_hypertable_10 USING BTREE(const, time)
NOTICE:  adding index _materialized_hypertable_10_numeric_time_idx ON _timescaledb_internal._materialized_hypertable_10 USING BTREE(numeric, time)
NOTICE:  adding index _materialized_hypertable_10_case_time_idx ON _timescaledb_internal._materialized_hypertable_10 USING BTREE(case, time)
NOTICE:  adding index _materialized_hypertable_10_coalesce_time_idx ON _timescaledb_internal._materialized_hypertable_10 USING BTREE(coalesce, time)
SET timescaledb.current_timestamp_mock = '2000-01-10';
REFRESH MATERIALIZED VIEW cagg_expr;
INFO:  new materialization range for public.metrics (time column time) (947289600000000)
INFO:  materializing continuous aggregate public.cagg_expr: nothing to invalidate, new range up to 947289600000000
SELECT * FROM cagg_expr ORDER BY time LIMIT 5;
             time             | const | numeric |                    first                     | case | coalesce | avg1 | avg2 
------------------------------+-------+---------+----------------------------------------------+------+----------+------+------
 Fri Dec 31 16:00:00 1999 PST | Const |     4.3 | ("Sat Jan 01 00:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Sat Jan 01 16:00:00 2000 PST | Const |     4.3 | ("Sat Jan 01 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Sun Jan 02 16:00:00 2000 PST | Const |     4.3 | ("Sun Jan 02 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Mon Jan 03 16:00:00 2000 PST | Const |     4.3 | ("Mon Jan 03 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Tue Jan 04 16:00:00 2000 PST | Const |     4.3 | ("Tue Jan 04 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
(5 rows)

ALTER TABLE metrics set(timescaledb.compress);
--
-- cascade_to_materialization = false tests
--
DROP TABLE IF EXISTS drop_chunks_table CASCADE;
NOTICE:  table "drop_chunks_table" does not exist, skipping
DROP TABLE IF EXISTS drop_chunks_table_u CASCADE;
NOTICE:  drop cascades to 2 other objects
NOTICE:  drop cascades to table _timescaledb_internal._hyper_8_9_chunk
CREATE TABLE drop_chunks_table(time BIGINT, data INTEGER);
SELECT hypertable_id AS drop_chunks_table_u_id
    FROM create_hypertable('drop_chunks_table', 'time', chunk_time_interval => 10);
NOTICE:  adding not-null constraint to column "time"
 drop_chunks_table_u_id 
------------------------
                     12
(1 row)

CREATE OR REPLACE FUNCTION integer_now_test2() returns bigint LANGUAGE SQL STABLE as $$ SELECT coalesce(max(time), bigint '0') FROM drop_chunks_table $$;
SELECT set_integer_now_func('drop_chunks_table', 'integer_now_test2');
 set_integer_now_func 
----------------------
 
(1 row)

CREATE VIEW drop_chunks_view WITH ( timescaledb.continuous, timescaledb.refresh_interval='72 hours', timescaledb.refresh_lag = '-5', timescaledb.max_interval_per_job=10)
AS SELECT time_bucket('5', time), max(data)
    FROM drop_chunks_table
    GROUP BY 1;
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(0, 20) AS i;
\set ON_ERROR_STOP 0
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => 13, cascade_to_materializations => false);
ERROR:  older_than must be greater than the ignore_invalidation_older_than parameter of public.drop_chunks_view
ALTER VIEW drop_chunks_view SET (timescaledb.ignore_invalidation_older_than = 9);
-- 9 is too small (less than timescaledb.ignore_invalidation_older_than)
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-8), cascade_to_materializations => false);
ERROR:  older_than must be greater than the ignore_invalidation_older_than parameter of public.drop_chunks_view
-- 10 works but we don't have the completion threshold far enough along
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
ERROR:  the continuous aggregate public.drop_chunks_view is too far behind
\set ON_ERROR_STOP 1
REFRESH MATERIALIZED VIEW drop_chunks_view;
INFO:  new materialization range for public.drop_chunks_table larger than allowed in one run, truncating (time column time) (25)
INFO:  new materialization range for public.drop_chunks_table (time column time) (10)
INFO:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 10
WARNING:  REFRESH did not materialize the entire range since it was limited by the max_interval_per_job setting
\set ON_ERROR_STOP 0
--still too far behind
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
ERROR:  the continuous aggregate public.drop_chunks_view is too far behind
\set ON_ERROR_STOP 1
REFRESH MATERIALIZED VIEW drop_chunks_view;
INFO:  new materialization range for public.drop_chunks_table larger than allowed in one run, truncating (time column time) (25)
INFO:  new materialization range for public.drop_chunks_table (time column time) (20)
INFO:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 20
WARNING:  REFRESH did not materialize the entire range since it was limited by the max_interval_per_job setting
REFRESH MATERIALIZED VIEW drop_chunks_view;
INFO:  new materialization range for public.drop_chunks_table (time column time) (25)
INFO:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 25
--now, this works
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
INFO:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, no new range
INFO:  materializing continuous aggregate public.drop_chunks_view: no new range to materialize or invalidations found, exiting early
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_12_13_chunk
(1 row)

\set ON_ERROR_STOP 0
--must have older_than set and no newer than
SELECT drop_chunks(table_name => 'drop_chunks_table', cascade_to_materializations => false);
ERROR:  older_than and newer_than timestamps provided to drop_chunks cannot both be NULL
SELECT drop_chunks(table_name => 'drop_chunks_table', newer_than=>10, cascade_to_materializations => false);
ERROR:  cannot use newer_than parameter to drop_chunks with cascade_to_materializations
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => 20, newer_than=>10, cascade_to_materializations => false);
ERROR:  cannot use newer_than parameter to drop_chunks with cascade_to_materializations
\set ON_ERROR_STOP 1
--test materialization of invalidation before drop
SELECT * FROM drop_chunks_table ORDER BY time ASC limit 1;
 time | data 
------+------
   10 |   10
(1 row)

INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(20, 35) AS i;
REFRESH MATERIALIZED VIEW drop_chunks_view;
INFO:  new materialization range for public.drop_chunks_table larger than allowed in one run, truncating (time column time) (40)
INFO:  new materialization range for public.drop_chunks_table (time column time) (30)
INFO:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, new range up to 30
WARNING:  REFRESH did not materialize the entire range since it was limited by the max_interval_per_job setting
REFRESH MATERIALIZED VIEW drop_chunks_view;
INFO:  new materialization range for public.drop_chunks_table (time column time) (40)
INFO:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 40
--this is invalidated but beyond ignore_invalidation_threshold so will never be seen (current time is 29)
INSERT INTO drop_chunks_table SELECT i, 100 FROM generate_series(10, 19) AS i;
--this will be seen after the drop its within the invalidation window and will be dropped
INSERT INTO drop_chunks_table VALUES (26, 100);
--this will not be processed by the drop since chunk 30-39 is not dropped but will be seen after refresh
--shows that the drop doesn't do more work than necessary
INSERT INTO drop_chunks_table VALUES (31, 200);
--move the time up to 39
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(35, 39) AS i;
--the invalidation on 25 not yet seen
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          35 |  35
          30 |  34
          25 |  29
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(8 rows)

--dropping tables will cause the invalidation to be processed
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
INFO:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_12_14_chunk
 _timescaledb_internal._hyper_12_15_chunk
(2 rows)

--new values on 25 now seen in view
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          35 |  35
          30 |  34
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(8 rows)

--earliest datapoint now in table
SELECT * FROM drop_chunks_table ORDER BY time ASC limit 1;
 time | data 
------+------
   30 |   30
(1 row)

--we see the chunks row with the dropped flags set;
SELECT * FROM _timescaledb_catalog.chunk where dropped;
 id | hypertable_id |      schema_name      |     table_name     | compressed_chunk_id | dropped 
----+---------------+-----------------------+--------------------+---------------------+---------
 13 |            12 | _timescaledb_internal | _hyper_12_13_chunk |                     | t
 14 |            12 | _timescaledb_internal | _hyper_12_14_chunk |                     | t
 15 |            12 | _timescaledb_internal | _hyper_12_15_chunk |                     | t
(3 rows)

--still see data in the view
SELECT * FROM drop_chunks_view WHERE time_bucket < (integer_now_test2()-9) ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(6 rows)

--no data but covers dropped chunks
SELECT * FROM drop_chunks_table WHERE time < (integer_now_test2()-9) ORDER BY time DESC;
 time | data 
------+------
(0 rows)

--recreate the dropped chunk
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(0, 20) AS i;
--see data from recreated region
SELECT * FROM drop_chunks_table WHERE time < (integer_now_test2()-9) ORDER BY time DESC;
 time | data 
------+------
   20 |   20
   19 |   19
   18 |   18
   17 |   17
   16 |   16
   15 |   15
   14 |   14
   13 |   13
   12 |   12
   11 |   11
   10 |   10
    9 |    9
    8 |    8
    7 |    7
    6 |    6
    5 |    5
    4 |    4
    3 |    3
    2 |    2
    1 |    1
    0 |    0
(21 rows)

REFRESH MATERIALIZED VIEW drop_chunks_view;
INFO:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
WARNING:  REFRESH did not materialize the entire range since it was limited by the max_interval_per_job setting
REFRESH MATERIALIZED VIEW drop_chunks_view;
INFO:  new materialization range not found for public.drop_chunks_table (time column time): not enough new data past completion threshold (40)
INFO:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, no new range
INFO:  materializing continuous aggregate public.drop_chunks_view: no new range to materialize or invalidations found, exiting early
--change to bucket 31 also seen
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          35 |  39
          30 | 200
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(8 rows)

--show that the invalidation processed during drop aren't limited by max_interval_per_job
ALTER VIEW drop_chunks_view SET (timescaledb.max_interval_per_job = 5);
INSERT INTO drop_chunks_table SELECT i, 300+i FROM generate_series(31, 39) AS i;
--move the time up to 49
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(40, 49) AS i;
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          35 |  39
          30 | 200
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(8 rows)

--should see multiple rounds of invalidation in the log messages
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
INFO:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
INFO:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
INFO:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, no new range
INFO:  materializing continuous aggregate public.drop_chunks_view: no new range to materialize or invalidations found, exiting early
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_12_17_chunk
 _timescaledb_internal._hyper_12_13_chunk
 _timescaledb_internal._hyper_12_14_chunk
 _timescaledb_internal._hyper_12_15_chunk
(4 rows)

--see both 30 and 35 updated
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          35 | 339
          30 | 334
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(8 rows)

--test splitting one range for invalidation in drop_chunks and then later
ALTER VIEW drop_chunks_view SET (timescaledb.max_interval_per_job = 100);
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(50,55) AS i;
REFRESH MATERIALIZED VIEW drop_chunks_view;
INFO:  new materialization range for public.drop_chunks_table (time column time) (60)
INFO:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 60
--one command and thus one range that spans 46 (which will be processed by drop_chunks) and (51 which won't, but will be later)
INSERT INTO drop_chunks_table VALUES (46, 400), (51, 500);
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(56,59) AS i;
--neither invalidation is seen
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          55 |  55
          50 |  54
          45 |  49
          40 |  44
          35 | 339
          30 | 334
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(12 rows)

SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
INFO:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_12_18_chunk
(1 row)

--the change in bucket 45 but not 50 is seen
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          55 |  55
          50 |  54
          45 | 400
          40 |  44
          35 | 339
          30 | 334
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(12 rows)

REFRESH MATERIALIZED VIEW drop_chunks_view;
INFO:  new materialization range not found for public.drop_chunks_table (time column time): not enough new data past completion threshold (60)
INFO:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
--the change in bucket 50 is seen
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          55 |  59
          50 | 500
          45 | 400
          40 |  44
          35 | 339
          30 | 334
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(12 rows)

--no data but covers dropped chunks
SELECT * FROM drop_chunks_table WHERE time < (integer_now_test2()-9) ORDER BY time DESC;
 time | data 
------+------
(0 rows)

SELECT set_chunk_time_interval('drop_chunks_table', 1000);
 set_chunk_time_interval 
-------------------------
 
(1 row)

SELECT chunk_table, ranges FROM chunk_relation_size('drop_chunks_table');
               chunk_table                |   ranges    
------------------------------------------+-------------
 _timescaledb_internal._hyper_12_19_chunk | {"[50,60)"}
(1 row)

--recreate the dropped chunk
INSERT INTO drop_chunks_table VALUES (20, 20);
--now sees the re-entered data
SELECT * FROM drop_chunks_table WHERE time < (integer_now_test2()-9) ORDER BY time DESC;
 time | data 
------+------
   20 |   20
(1 row)

--should show chunk with old name and old ranges
SELECT chunk_table, ranges FROM chunk_relation_size('drop_chunks_table');
               chunk_table                |   ranges    
------------------------------------------+-------------
 _timescaledb_internal._hyper_12_15_chunk | {"[20,30)"}
 _timescaledb_internal._hyper_12_19_chunk | {"[50,60)"}
(2 rows)

