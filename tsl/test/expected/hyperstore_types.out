-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\ir include/hyperstore_helpers.sql
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- Function to run an explain analyze with and do replacements on the
-- emitted plan. This is intended to be used when the structure of the
-- plan is important, but not the specific chunks scanned nor the
-- number of heap fetches, rows, loops, etc.
create function explain_anonymize(text) returns setof text
language plpgsql as
$$
declare
    ln text;
begin
    for ln in
        execute format('explain (analyze, costs off, summary off, timing off, decompress_cache_stats) %s', $1)
    loop
        ln := regexp_replace(ln, 'Arrays read from cache: \d+', 'Arrays read from cache: N');
        ln := regexp_replace(ln, 'Heap Fetches: \d+', 'Heap Fetches: N');
        ln := regexp_replace(ln, 'Workers Launched: \d+', 'Workers Launched: N');
        ln := regexp_replace(ln, 'actual rows=\d+ loops=\d+', 'actual rows=N loops=N');
	ln := regexp_replace(ln, '_hyper_\d+_\d+_chunk', '_hyper_I_N_chunk');
        return next ln;
    end loop;
end;
$$;
select setseed(1);
 setseed 
---------
 
(1 row)

-- Test that decompressing and scannning floats work. These are batch
-- decompressable and can be vectorized.
\set the_table test_float
\set the_type float
\set the_generator ceil(random()*10)
\set the_aggregate sum(value)
\set the_clause value > 0.5
\ir include/hyperstore_type_table.sql
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\set ECHO queries
create table test_float(created_at timestamptz not null unique, value float);
select create_hypertable('test_float', by_range('created_at'));
 create_hypertable 
-------------------
 (1,t)
(1 row)

alter table test_float set (
      timescaledb.compress,
      timescaledb.compress_segmentby = '',
      timescaledb.compress_orderby = 'created_at'
);
select setseed(1);
 setseed 
---------
 
(1 row)

-- Insert some data to produce at least two chunks.
\set ECHO queries
insert into test_float(created_at, value)
select t, ceil(random()*10)
from generate_series('2022-06-01'::timestamp, '2022-06-10', '1 minute') t;
-- Save away the table so that we can make sure that a hyperstore
-- table and a heap table produce the same result.
create table :saved_table as select * from :the_table;
-- Compress the rows in the hyperstore.
select compress_chunk(show_chunks(:'the_table'), compress_using => 'hyperstore');
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_2_chunk
 _timescaledb_internal._hyper_1_3_chunk
(3 rows)

-- This part of the include file will run a query with the aggregate
-- provided by the including file and test that using a hyperstore
-- with compressed rows and a normal table produces the same result
-- for the query with the given aggregate.
\set ECHO queries
with
  lhs as (
      select date_trunc('hour', created_at) as created_at,
      	     sum(value) as "sum(value)"
      from test_float where (value>0.5) group by date_trunc('hour', created_at)
  ),
  rhs as (
      select date_trunc('hour', created_at) as created_at,
      	     sum(value) as "sum(value)"
      from test_float_saved where (value>0.5) group by date_trunc('hour', created_at)
  )
select lhs.*, rhs.*
from lhs full join rhs using (created_at)
where lhs.created_at is null or rhs.created_at is null;
 created_at | sum(value) | created_at | sum(value) 
------------+------------+------------+------------
(0 rows)

drop table test_float;
drop table test_float_saved;
-- Test that decompressing and scanning numerics works. These are not
-- batch decompressable.
\set the_table test_numeric
\set the_type numeric(5,2)
\set the_generator ceil(random()*10)
\set the_aggregate sum(value)
\set the_clause value > 0.5
\ir include/hyperstore_type_table.sql
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\set ECHO queries
create table test_numeric(created_at timestamptz not null unique, value numeric(5,2));
select create_hypertable('test_numeric', by_range('created_at'));
 create_hypertable 
-------------------
 (3,t)
(1 row)

alter table test_numeric set (
      timescaledb.compress,
      timescaledb.compress_segmentby = '',
      timescaledb.compress_orderby = 'created_at'
);
select setseed(1);
 setseed 
---------
 
(1 row)

-- Insert some data to produce at least two chunks.
\set ECHO queries
insert into test_numeric(created_at, value)
select t, ceil(random()*10)
from generate_series('2022-06-01'::timestamp, '2022-06-10', '1 minute') t;
-- Save away the table so that we can make sure that a hyperstore
-- table and a heap table produce the same result.
create table :saved_table as select * from :the_table;
-- Compress the rows in the hyperstore.
select compress_chunk(show_chunks(:'the_table'), compress_using => 'hyperstore');
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_3_7_chunk
 _timescaledb_internal._hyper_3_8_chunk
 _timescaledb_internal._hyper_3_9_chunk
(3 rows)

-- This part of the include file will run a query with the aggregate
-- provided by the including file and test that using a hyperstore
-- with compressed rows and a normal table produces the same result
-- for the query with the given aggregate.
\set ECHO queries
with
  lhs as (
      select date_trunc('hour', created_at) as created_at,
      	     sum(value) as "sum(value)"
      from test_numeric where (value>0.5) group by date_trunc('hour', created_at)
  ),
  rhs as (
      select date_trunc('hour', created_at) as created_at,
      	     sum(value) as "sum(value)"
      from test_numeric_saved where (value>0.5) group by date_trunc('hour', created_at)
  )
select lhs.*, rhs.*
from lhs full join rhs using (created_at)
where lhs.created_at is null or rhs.created_at is null;
 created_at | sum(value) | created_at | sum(value) 
------------+------------+------------+------------
(0 rows)

drop table test_numeric;
drop table test_numeric_saved;
-- Test that decompressing and scanning boolean columns works.
\set the_table test_bool
\set the_type boolean
\set the_generator (random() > 0.5)
\set the_aggregate count(value)
\set the_clause value = true
\ir include/hyperstore_type_table.sql
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\set ECHO queries
create table test_bool(created_at timestamptz not null unique, value boolean);
select create_hypertable('test_bool', by_range('created_at'));
 create_hypertable 
-------------------
 (5,t)
(1 row)

alter table test_bool set (
      timescaledb.compress,
      timescaledb.compress_segmentby = '',
      timescaledb.compress_orderby = 'created_at'
);
select setseed(1);
 setseed 
---------
 
(1 row)

-- Insert some data to produce at least two chunks.
\set ECHO queries
insert into test_bool(created_at, value)
select t, (random()>0.5)
from generate_series('2022-06-01'::timestamp, '2022-06-10', '1 minute') t;
-- Save away the table so that we can make sure that a hyperstore
-- table and a heap table produce the same result.
create table :saved_table as select * from :the_table;
-- Compress the rows in the hyperstore.
select compress_chunk(show_chunks(:'the_table'), compress_using => 'hyperstore');
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_5_13_chunk
 _timescaledb_internal._hyper_5_14_chunk
 _timescaledb_internal._hyper_5_15_chunk
(3 rows)

-- This part of the include file will run a query with the aggregate
-- provided by the including file and test that using a hyperstore
-- with compressed rows and a normal table produces the same result
-- for the query with the given aggregate.
\set ECHO queries
with
  lhs as (
      select date_trunc('hour', created_at) as created_at,
      	     count(value) as "count(value)"
      from test_bool where (value=true) group by date_trunc('hour', created_at)
  ),
  rhs as (
      select date_trunc('hour', created_at) as created_at,
      	     count(value) as "count(value)"
      from test_bool_saved where (value=true) group by date_trunc('hour', created_at)
  )
select lhs.*, rhs.*
from lhs full join rhs using (created_at)
where lhs.created_at is null or rhs.created_at is null;
 created_at | count(value) | created_at | count(value) 
------------+--------------+------------+--------------
(0 rows)

drop table test_bool;
drop table test_bool_saved;
\set my_uuid e0317dfc-77cd-46da-a4e9-8626ce49ccad
-- Test that text works with a simple comparison with a constant
-- value.
\set the_table test_text
\set the_type text
\set the_generator gen_random_uuid()::text
\set the_aggregate count(*)
\set the_clause value = :'my_uuid'
\ir include/hyperstore_type_table.sql
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\set ECHO queries
create table test_text(created_at timestamptz not null unique, value text);
select create_hypertable('test_text', by_range('created_at'));
 create_hypertable 
-------------------
 (7,t)
(1 row)

alter table test_text set (
      timescaledb.compress,
      timescaledb.compress_segmentby = '',
      timescaledb.compress_orderby = 'created_at'
);
select setseed(1);
 setseed 
---------
 
(1 row)

-- Insert some data to produce at least two chunks.
\set ECHO queries
insert into test_text(created_at, value)
select t, gen_random_uuid()::text
from generate_series('2022-06-01'::timestamp, '2022-06-10', '1 minute') t;
-- Save away the table so that we can make sure that a hyperstore
-- table and a heap table produce the same result.
create table :saved_table as select * from :the_table;
-- Compress the rows in the hyperstore.
select compress_chunk(show_chunks(:'the_table'), compress_using => 'hyperstore');
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_7_19_chunk
 _timescaledb_internal._hyper_7_20_chunk
 _timescaledb_internal._hyper_7_21_chunk
(3 rows)

-- This part of the include file will run a query with the aggregate
-- provided by the including file and test that using a hyperstore
-- with compressed rows and a normal table produces the same result
-- for the query with the given aggregate.
\set ECHO queries
with
  lhs as (
      select date_trunc('hour', created_at) as created_at,
      	     count(*) as "count(*)"
      from test_text where (value='e0317dfc-77cd-46da-a4e9-8626ce49ccad') group by date_trunc('hour', created_at)
  ),
  rhs as (
      select date_trunc('hour', created_at) as created_at,
      	     count(*) as "count(*)"
      from test_text_saved where (value='e0317dfc-77cd-46da-a4e9-8626ce49ccad') group by date_trunc('hour', created_at)
  )
select lhs.*, rhs.*
from lhs full join rhs using (created_at)
where lhs.created_at is null or rhs.created_at is null;
 created_at | count(*) | created_at | count(*) 
------------+----------+------------+----------
(0 rows)

drop table test_text;
drop table test_text_saved;
-- Test that we can decompress and scan JSON fields without
-- filters. This just tests that decompression works.
\set a_name temp
\set the_table test_jsonb
\set the_type jsonb
\set the_generator jsonb_build_object(:'a_name',round(random()*100))
\set the_aggregate sum((value->:'a_name')::int)
\set the_clause true
\ir include/hyperstore_type_table.sql
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\set ECHO queries
create table test_jsonb(created_at timestamptz not null unique, value jsonb);
select create_hypertable('test_jsonb', by_range('created_at'));
 create_hypertable 
-------------------
 (9,t)
(1 row)

alter table test_jsonb set (
      timescaledb.compress,
      timescaledb.compress_segmentby = '',
      timescaledb.compress_orderby = 'created_at'
);
select setseed(1);
 setseed 
---------
 
(1 row)

-- Insert some data to produce at least two chunks.
\set ECHO queries
insert into test_jsonb(created_at, value)
select t, jsonb_build_object('temp',round(random()*100))
from generate_series('2022-06-01'::timestamp, '2022-06-10', '1 minute') t;
-- Save away the table so that we can make sure that a hyperstore
-- table and a heap table produce the same result.
create table :saved_table as select * from :the_table;
-- Compress the rows in the hyperstore.
select compress_chunk(show_chunks(:'the_table'), compress_using => 'hyperstore');
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_9_25_chunk
 _timescaledb_internal._hyper_9_26_chunk
 _timescaledb_internal._hyper_9_27_chunk
(3 rows)

-- This part of the include file will run a query with the aggregate
-- provided by the including file and test that using a hyperstore
-- with compressed rows and a normal table produces the same result
-- for the query with the given aggregate.
\set ECHO queries
with
  lhs as (
      select date_trunc('hour', created_at) as created_at,
      	     sum((value->'temp')::int) as "sum((value->'temp')::int)"
      from test_jsonb where (true) group by date_trunc('hour', created_at)
  ),
  rhs as (
      select date_trunc('hour', created_at) as created_at,
      	     sum((value->'temp')::int) as "sum((value->'temp')::int)"
      from test_jsonb_saved where (true) group by date_trunc('hour', created_at)
  )
select lhs.*, rhs.*
from lhs full join rhs using (created_at)
where lhs.created_at is null or rhs.created_at is null;
 created_at | sum((value->'temp')::int) | created_at | sum((value->'temp')::int) 
------------+---------------------------+------------+---------------------------
(0 rows)

drop table test_jsonb;
drop table test_jsonb_saved;
-- Test that we can decompress and scan JSON fields with a filter
-- using JSON operators (these are function calls, so they do not have
-- simple scan keys).
\set a_name temp
\set the_table test_jsonb
\set the_type jsonb
\set the_generator jsonb_build_object(:'a_name',round(random()*100))
\set the_aggregate sum((value->:'a_name')::int)
\set the_clause ((value->:'a_name')::numeric >= 0.5) and ((value->:'a_name')::numeric <= 0.6)
\ir include/hyperstore_type_table.sql
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\set ECHO queries
create table test_jsonb(created_at timestamptz not null unique, value jsonb);
select create_hypertable('test_jsonb', by_range('created_at'));
 create_hypertable 
-------------------
 (11,t)
(1 row)

alter table test_jsonb set (
      timescaledb.compress,
      timescaledb.compress_segmentby = '',
      timescaledb.compress_orderby = 'created_at'
);
select setseed(1);
 setseed 
---------
 
(1 row)

-- Insert some data to produce at least two chunks.
\set ECHO queries
insert into test_jsonb(created_at, value)
select t, jsonb_build_object('temp',round(random()*100))
from generate_series('2022-06-01'::timestamp, '2022-06-10', '1 minute') t;
-- Save away the table so that we can make sure that a hyperstore
-- table and a heap table produce the same result.
create table :saved_table as select * from :the_table;
-- Compress the rows in the hyperstore.
select compress_chunk(show_chunks(:'the_table'), compress_using => 'hyperstore');
              compress_chunk              
------------------------------------------
 _timescaledb_internal._hyper_11_31_chunk
 _timescaledb_internal._hyper_11_32_chunk
 _timescaledb_internal._hyper_11_33_chunk
(3 rows)

-- This part of the include file will run a query with the aggregate
-- provided by the including file and test that using a hyperstore
-- with compressed rows and a normal table produces the same result
-- for the query with the given aggregate.
\set ECHO queries
with
  lhs as (
      select date_trunc('hour', created_at) as created_at,
      	     sum((value->'temp')::int) as "sum((value->'temp')::int)"
      from test_jsonb where (((value->'temp')::numeric>=0.5)and((value->'temp')::numeric<=0.6)) group by date_trunc('hour', created_at)
  ),
  rhs as (
      select date_trunc('hour', created_at) as created_at,
      	     sum((value->'temp')::int) as "sum((value->'temp')::int)"
      from test_jsonb_saved where (((value->'temp')::numeric>=0.5)and((value->'temp')::numeric<=0.6)) group by date_trunc('hour', created_at)
  )
select lhs.*, rhs.*
from lhs full join rhs using (created_at)
where lhs.created_at is null or rhs.created_at is null;
 created_at | sum((value->'temp')::int) | created_at | sum((value->'temp')::int) 
------------+---------------------------+------------+---------------------------
(0 rows)

drop table test_jsonb;
drop table test_jsonb_saved;
-- Test that we can use NAME type for a field and compare with a
-- constant value. This is a fixed-size type with a size > 8 and we
-- will try to use a scan key for this.
\set a_name temp
\set the_table test_name
\set the_type name
\set the_generator gen_random_uuid()::name
\set the_aggregate count(*)
\set the_clause value = :'my_uuid'
\ir include/hyperstore_type_table.sql
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\set ECHO queries
create table test_name(created_at timestamptz not null unique, value name);
select create_hypertable('test_name', by_range('created_at'));
 create_hypertable 
-------------------
 (13,t)
(1 row)

alter table test_name set (
      timescaledb.compress,
      timescaledb.compress_segmentby = '',
      timescaledb.compress_orderby = 'created_at'
);
select setseed(1);
 setseed 
---------
 
(1 row)

-- Insert some data to produce at least two chunks.
\set ECHO queries
insert into test_name(created_at, value)
select t, gen_random_uuid()::name
from generate_series('2022-06-01'::timestamp, '2022-06-10', '1 minute') t;
-- Save away the table so that we can make sure that a hyperstore
-- table and a heap table produce the same result.
create table :saved_table as select * from :the_table;
-- Compress the rows in the hyperstore.
select compress_chunk(show_chunks(:'the_table'), compress_using => 'hyperstore');
              compress_chunk              
------------------------------------------
 _timescaledb_internal._hyper_13_37_chunk
 _timescaledb_internal._hyper_13_38_chunk
 _timescaledb_internal._hyper_13_39_chunk
(3 rows)

-- This part of the include file will run a query with the aggregate
-- provided by the including file and test that using a hyperstore
-- with compressed rows and a normal table produces the same result
-- for the query with the given aggregate.
\set ECHO queries
with
  lhs as (
      select date_trunc('hour', created_at) as created_at,
      	     count(*) as "count(*)"
      from test_name where (value='e0317dfc-77cd-46da-a4e9-8626ce49ccad') group by date_trunc('hour', created_at)
  ),
  rhs as (
      select date_trunc('hour', created_at) as created_at,
      	     count(*) as "count(*)"
      from test_name_saved where (value='e0317dfc-77cd-46da-a4e9-8626ce49ccad') group by date_trunc('hour', created_at)
  )
select lhs.*, rhs.*
from lhs full join rhs using (created_at)
where lhs.created_at is null or rhs.created_at is null;
 created_at | count(*) | created_at | count(*) 
------------+----------+------------+----------
(0 rows)

drop table test_name;
drop table test_name_saved;
