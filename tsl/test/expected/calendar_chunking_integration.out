-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
--
-- Test calendar-based chunking with continuous aggregates, compression,
-- and retention policies.
--
SET timescaledb.enable_calendar_chunking = true;
SET timezone TO 'Europe/Stockholm';
---------------------------------------------------------------
-- SETUP: Create hypertables with calendar-based chunking
---------------------------------------------------------------
-- Monthly chunks with calendar alignment
CREATE TABLE metrics_monthly(
    time timestamptz NOT NULL,
    device_id int NOT NULL,
    value float NOT NULL
);
SELECT create_hypertable('metrics_monthly', 'time', chunk_time_interval => INTERVAL '1 month');
      create_hypertable       
------------------------------
 (1,public,metrics_monthly,t)

-- Weekly chunks with calendar alignment
CREATE TABLE metrics_weekly(
    time timestamptz NOT NULL,
    device_id int NOT NULL,
    value float NOT NULL
);
SELECT create_hypertable('metrics_weekly', 'time', chunk_time_interval => INTERVAL '7 days');
      create_hypertable      
-----------------------------
 (2,public,metrics_weekly,t)

-- Daily chunks with calendar alignment
CREATE TABLE metrics_daily(
    time timestamptz NOT NULL,
    device_id int NOT NULL,
    value float NOT NULL
);
SELECT create_hypertable('metrics_daily', 'time', chunk_time_interval => INTERVAL '1 day');
     create_hypertable      
----------------------------
 (3,public,metrics_daily,t)

-- Create table with custom origin (fiscal year starting April 1)
CREATE TABLE metrics_fiscal(
    time timestamptz NOT NULL,
    value float NOT NULL
);
SELECT create_hypertable('metrics_fiscal',
    by_range('time', INTERVAL '1 month', partition_origin => '2024-04-01'::timestamptz));
 create_hypertable 
-------------------
 (4,t)

-- Create a hypertable for CAgg tests
CREATE TABLE cagg_test_monthly(
    time timestamptz NOT NULL,
    device_id int NOT NULL,
    value float NOT NULL
);
SELECT create_hypertable('cagg_test_monthly', 'time', chunk_time_interval => INTERVAL '1 month');
       create_hypertable        
--------------------------------
 (5,public,cagg_test_monthly,t)

---------------------------------------------------------------
-- INSERT DATA spanning multiple chunks
---------------------------------------------------------------
-- Use setseed for deterministic random values
SELECT setseed(0.1);
 setseed 
---------
 

-- Insert data for monthly table (spanning 3 months)
INSERT INTO metrics_monthly
SELECT ts, device_id, random() * 100
FROM generate_series('2024-01-15'::timestamptz, '2024-03-15'::timestamptz, '1 day'::interval) ts
CROSS JOIN generate_series(1, 3) device_id;
-- Insert data for weekly table (spanning 4 weeks)
INSERT INTO metrics_weekly
SELECT ts, device_id, random() * 100
FROM generate_series('2024-01-01'::timestamptz, '2024-01-28'::timestamptz, '6 hours'::interval) ts
CROSS JOIN generate_series(1, 3) device_id;
-- Insert data for daily table (spanning 10 days)
INSERT INTO metrics_daily
SELECT ts, device_id, random() * 100
FROM generate_series('2024-01-01'::timestamptz, '2024-01-10'::timestamptz, '1 hour'::interval) ts
CROSS JOIN generate_series(1, 3) device_id;
-- Insert data for fiscal table (reset seed for deterministic values)
SELECT setseed(0.2);
 setseed 
---------
 

INSERT INTO metrics_fiscal
SELECT ts, random() * 100
FROM generate_series('2024-03-15'::timestamptz, '2024-05-15'::timestamptz, '1 day'::interval) ts;
-- Insert data for CAgg test table
INSERT INTO cagg_test_monthly
SELECT ts, device_id, (EXTRACT(epoch FROM ts) % 100)::float
FROM generate_series('2024-01-15'::timestamptz, '2024-04-15'::timestamptz, '1 hour'::interval) ts
CROSS JOIN generate_series(1, 3) device_id;
---------------------------------------------------------------
-- CONTINUOUS AGGREGATES on calendar-chunked hypertables
--
-- Test that continuous aggregates work correctly on calendar-chunked
-- hypertables. The materialization hypertable should also use
-- calendar-based chunking, inheriting the interval type and origin
-- from the source hypertable.
---------------------------------------------------------------
-- Test 1: CAgg with month bucket (variable-width) on calendar-chunked hypertable
CREATE MATERIALIZED VIEW cagg_monthly
WITH (timescaledb.continuous, timescaledb.materialized_only = true)
AS SELECT
    time_bucket('1 month', time, timezone => 'Europe/Stockholm') AS bucket,
    device_id,
    count(*) as cnt
FROM cagg_test_monthly
GROUP BY 1, 2
WITH NO DATA;
-- Test 2: CAgg with day bucket (fixed-width) on calendar-chunked hypertable
CREATE MATERIALIZED VIEW cagg_daily
WITH (timescaledb.continuous, timescaledb.materialized_only = true)
AS SELECT
    time_bucket('1 day', time, timezone => 'Europe/Stockholm') AS bucket,
    device_id,
    count(*) as cnt
FROM cagg_test_monthly
GROUP BY 1, 2
WITH NO DATA;
-- Test 3: CAgg with hour bucket (fixed-width) on calendar-chunked hypertable
CREATE MATERIALIZED VIEW cagg_hourly
WITH (timescaledb.continuous, timescaledb.materialized_only = true)
AS SELECT
    time_bucket('1 hour', time, timezone => 'Europe/Stockholm') AS bucket,
    device_id,
    count(*) as cnt
FROM cagg_test_monthly
GROUP BY 1, 2
WITH NO DATA;
-- Test 4: CAgg on metrics_fiscal (calendar-chunked with custom origin)
CREATE MATERIALIZED VIEW cagg_fiscal
WITH (timescaledb.continuous, timescaledb.materialized_only = true)
AS SELECT
    time_bucket('1 day', time, timezone => 'Europe/Stockholm') AS bucket,
    count(*) as cnt
FROM metrics_fiscal
GROUP BY 1
WITH NO DATA;
-- Verify CAggs were created successfully
SELECT view_name, materialized_only, compression_enabled
FROM timescaledb_information.continuous_aggregates
WHERE view_name LIKE 'cagg_%'
ORDER BY view_name;
  view_name   | materialized_only | compression_enabled 
--------------+-------------------+---------------------
 cagg_daily   | t                 | f
 cagg_fiscal  | t                 | f
 cagg_hourly  | t                 | f
 cagg_monthly | t                 | f

-- Refresh the CAggs and verify data
CALL refresh_continuous_aggregate('cagg_monthly', NULL, NULL);
CALL refresh_continuous_aggregate('cagg_daily', NULL, NULL);
SELECT bucket, device_id, cnt
FROM cagg_monthly
ORDER BY bucket, device_id
LIMIT 12;
            bucket             | device_id | cnt 
-------------------------------+-----------+-----
 Mon Jan 01 00:00:00 2024 CET  |         1 | 408
 Mon Jan 01 00:00:00 2024 CET  |         2 | 408
 Mon Jan 01 00:00:00 2024 CET  |         3 | 408
 Thu Feb 01 00:00:00 2024 CET  |         1 | 696
 Thu Feb 01 00:00:00 2024 CET  |         2 | 696
 Thu Feb 01 00:00:00 2024 CET  |         3 | 696
 Fri Mar 01 00:00:00 2024 CET  |         1 | 743
 Fri Mar 01 00:00:00 2024 CET  |         2 | 743
 Fri Mar 01 00:00:00 2024 CET  |         3 | 743
 Mon Apr 01 00:00:00 2024 CEST |         1 | 337
 Mon Apr 01 00:00:00 2024 CEST |         2 | 337
 Mon Apr 01 00:00:00 2024 CEST |         3 | 337

---------------------------------------------------------------
-- Verify CAgg materialization hypertables use calendar-based chunking
--
-- When a CAgg is created on a calendar-chunked hypertable, the
-- materialization hypertable should also use calendar-based chunking.
-- This is indicated by interval IS NOT NULL in the dimension catalog.
---------------------------------------------------------------
-- Check that materialization hypertables have calendar-based dimensions
-- (interval IS NOT NULL means calendar chunking, interval_length IS NULL)
SELECT
    h.table_name,
    d.column_name,
    d.interval_length IS NULL as is_calendar_chunking,
    d.interval IS NOT NULL as has_interval
FROM _timescaledb_catalog.hypertable h
JOIN _timescaledb_catalog.dimension d ON h.id = d.hypertable_id
WHERE h.table_name LIKE '_materialized_hypertable_%'
ORDER BY h.table_name;
         table_name         | column_name | is_calendar_chunking | has_interval 
----------------------------+-------------+----------------------+--------------
 _materialized_hypertable_6 | bucket      | t                    | t
 _materialized_hypertable_7 | bucket      | t                    | t
 _materialized_hypertable_8 | bucket      | t                    | t
 _materialized_hypertable_9 | bucket      | t                    | t

-- Show chunk ranges for cagg_monthly to verify calendar alignment
-- Chunks should align to month boundaries (10 months interval due to MATPARTCOL_INTERVAL_FACTOR)
SELECT chunk_name, range_start, range_end
FROM timescaledb_information.chunks
WHERE hypertable_name = '_materialized_hypertable_6'
ORDER BY range_start;
    chunk_name     |          range_start          |           range_end           
-------------------+-------------------------------+-------------------------------
 _hyper_6_25_chunk | Sat Jul 01 00:00:00 2023 CEST | Wed May 01 00:00:00 2024 CEST

-- Show chunk ranges for cagg_daily to verify calendar alignment
-- (10 day chunks due to MATPARTCOL_INTERVAL_FACTOR applied to source's 1 month interval)
SELECT chunk_name, range_start, range_end
FROM timescaledb_information.chunks
WHERE hypertable_name = '_materialized_hypertable_7'
ORDER BY range_start;
    chunk_name     |          range_start          |           range_end           
-------------------+-------------------------------+-------------------------------
 _hyper_7_26_chunk | Sat Jul 01 00:00:00 2023 CEST | Wed May 01 00:00:00 2024 CEST

---------------------------------------------------------------
-- COMPRESSION with calendar-chunked hypertables
---------------------------------------------------------------
-- Enable compression on the tables
ALTER TABLE metrics_monthly SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'device_id',
    timescaledb.compress_orderby = 'time'
);
ALTER TABLE metrics_weekly SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'device_id',
    timescaledb.compress_orderby = 'time'
);
ALTER TABLE metrics_daily SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'device_id',
    timescaledb.compress_orderby = 'time'
);
-- Compress specific chunks
SELECT compress_chunk(chunk) FROM show_chunks('metrics_monthly', older_than => '2024-03-01') chunk;
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_2_chunk

SELECT compress_chunk(chunk) FROM show_chunks('metrics_weekly', older_than => '2024-01-21') chunk;
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_2_4_chunk
 _timescaledb_internal._hyper_2_5_chunk

SELECT compress_chunk(chunk) FROM show_chunks('metrics_daily', older_than => '2024-01-08') chunk;
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_3_8_chunk
 _timescaledb_internal._hyper_3_9_chunk
 _timescaledb_internal._hyper_3_10_chunk
 _timescaledb_internal._hyper_3_11_chunk
 _timescaledb_internal._hyper_3_12_chunk
 _timescaledb_internal._hyper_3_13_chunk
 _timescaledb_internal._hyper_3_14_chunk

-- Verify compression status
SELECT chunk_name, is_compressed
FROM timescaledb_information.chunks
WHERE hypertable_name = 'metrics_monthly'
ORDER BY range_start;
    chunk_name    | is_compressed 
------------------+---------------
 _hyper_1_1_chunk | t
 _hyper_1_2_chunk | t
 _hyper_1_3_chunk | f

SELECT chunk_name, is_compressed
FROM timescaledb_information.chunks
WHERE hypertable_name = 'metrics_weekly'
ORDER BY range_start;
    chunk_name    | is_compressed 
------------------+---------------
 _hyper_2_4_chunk | t
 _hyper_2_5_chunk | t
 _hyper_2_6_chunk | f
 _hyper_2_7_chunk | f

-- Query compressed data to verify it still works
SELECT time_bucket('1 week', time, current_setting('timezone')) as week, count(*), round(avg(value)::numeric, 2) as avg_val
FROM metrics_monthly
GROUP BY 1
ORDER BY 1;
             week             | count | avg_val 
------------------------------+-------+---------
 Mon Jan 15 00:00:00 2024 CET |    21 |   60.63
 Mon Jan 22 00:00:00 2024 CET |    21 |   44.71
 Mon Jan 29 00:00:00 2024 CET |    21 |   54.96
 Mon Feb 05 00:00:00 2024 CET |    21 |   35.87
 Mon Feb 12 00:00:00 2024 CET |    21 |   45.96
 Mon Feb 19 00:00:00 2024 CET |    21 |   48.08
 Mon Feb 26 00:00:00 2024 CET |    21 |   49.33
 Mon Mar 04 00:00:00 2024 CET |    21 |   52.00
 Mon Mar 11 00:00:00 2024 CET |    15 |   40.67

---------------------------------------------------------------
-- VERIFY DATA INTEGRITY after compression
---------------------------------------------------------------
-- Count rows in original table (should include compressed chunks)
SELECT count(*) as total_rows FROM metrics_monthly;
 total_rows 
------------
        183

-- Verify aggregation still works correctly
SELECT device_id, count(*), round(avg(value)::numeric, 2) as avg_val
FROM metrics_monthly
GROUP BY device_id
ORDER BY device_id;
 device_id | count | avg_val 
-----------+-------+---------
         1 |    61 |   50.99
         2 |    61 |   50.86
         3 |    61 |   42.94

---------------------------------------------------------------
-- COMPRESSION POLICY with calendar-chunked hypertables
---------------------------------------------------------------
-- Add compression policy with 1 month threshold
SELECT add_compression_policy('metrics_monthly', INTERVAL '1 month', schedule_interval => INTERVAL '1 year') as monthly_compress_job \gset
-- Decompress all chunks so the policy has work to do
SELECT decompress_chunk(c.chunk_schema || '.' || c.chunk_name)
FROM timescaledb_information.chunks c
WHERE c.hypertable_name = 'metrics_monthly' AND c.is_compressed;
            decompress_chunk            
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_2_chunk

-- Mock time to 2024-03-01 - with 1 month policy, Jan chunk will be compressed, Feb and Mar won't
SET timescaledb.current_timestamp_mock = '2024-03-01 00:00:00+01';
-- Show chunks before running compression policy
SELECT chunk_name, is_compressed
FROM timescaledb_information.chunks
WHERE hypertable_name = 'metrics_monthly'
ORDER BY range_start;
    chunk_name    | is_compressed 
------------------+---------------
 _hyper_1_1_chunk | f
 _hyper_1_2_chunk | f
 _hyper_1_3_chunk | f

-- Run the compression policy job
CALL run_job(:monthly_compress_job);
-- Verify only Jan chunk was compressed (older than 1 month from mock time)
SELECT chunk_name, is_compressed
FROM timescaledb_information.chunks
WHERE hypertable_name = 'metrics_monthly'
ORDER BY range_start;
    chunk_name    | is_compressed 
------------------+---------------
 _hyper_1_1_chunk | t
 _hyper_1_2_chunk | f
 _hyper_1_3_chunk | f

RESET timescaledb.current_timestamp_mock;
---------------------------------------------------------------
-- CHUNK MERGING (compress_chunk_time_interval) with calendar chunks
---------------------------------------------------------------
-- Create a new table for testing chunk merging with calendar chunks
CREATE TABLE merge_test(time timestamptz NOT NULL, device_id int, value float);
SELECT create_hypertable('merge_test', 'time', chunk_time_interval => INTERVAL '1 month');
    create_hypertable     
--------------------------
 (13,public,merge_test,t)

-- Insert data spanning 4 months (Jan-Apr 2024), creating 4 monthly chunks
-- Use deterministic values: value = day of month
INSERT INTO merge_test
SELECT ts, device_id, extract(day from ts)::float
FROM generate_series('2024-01-15'::timestamptz, '2024-04-15'::timestamptz, INTERVAL '1 day') ts
CROSS JOIN generate_series(1, 2) device_id;
-- Show chunks before compression (4 monthly chunks with variable sizes)
SELECT chunk_name, range_start, range_end
FROM timescaledb_information.chunks
WHERE hypertable_name = 'merge_test'
ORDER BY range_start;
     chunk_name     |          range_start          |           range_end           
--------------------+-------------------------------+-------------------------------
 _hyper_13_39_chunk | Mon Jan 01 00:00:00 2024 CET  | Thu Feb 01 00:00:00 2024 CET
 _hyper_13_40_chunk | Thu Feb 01 00:00:00 2024 CET  | Fri Mar 01 00:00:00 2024 CET
 _hyper_13_41_chunk | Fri Mar 01 00:00:00 2024 CET  | Mon Apr 01 00:00:00 2024 CEST
 _hyper_13_42_chunk | Mon Apr 01 00:00:00 2024 CEST | Wed May 01 00:00:00 2024 CEST

-- Enable compression with chunk merging
-- compress_chunk_time_interval = '90 days' means merge chunks until total interval exceeds 90 days
-- This tests that the modulo-by-zero bug is fixed (calendar chunks have interval_length=0)
ALTER TABLE merge_test SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'device_id',
    timescaledb.compress_orderby = 'time',
    timescaledb.compress_chunk_time_interval = '90 days'
);
-- Verify the compress_interval_length was set (should be 90 days in microseconds)
SELECT d.compress_interval_length / 86400000000 as compress_interval_days
FROM _timescaledb_catalog.dimension d
JOIN _timescaledb_catalog.hypertable h ON d.hypertable_id = h.id
WHERE h.table_name = 'merge_test';
 compress_interval_days 
------------------------
                     90

-- Compress all chunks
-- Jan (31 days) + Feb (29 days, leap year) = 60 days < 90 days -> merge into Jan
-- 60 days + Mar (31 days) = 91 days > 90 days -> Mar starts new chunk
-- Mar (31 days) + Apr (30 days) = 61 days < 90 days -> merge into Mar
SELECT compress_chunk(chunk, true) FROM show_chunks('merge_test') chunk;
              compress_chunk              
------------------------------------------
 _timescaledb_internal._hyper_13_39_chunk
 _timescaledb_internal._hyper_13_39_chunk
 _timescaledb_internal._hyper_13_41_chunk
 _timescaledb_internal._hyper_13_41_chunk

-- Show chunks after compression - Jan+Feb merged, Mar+Apr merged (2 chunks total)
SELECT c.chunk_name, c.is_compressed, c.range_start, c.range_end
FROM timescaledb_information.chunks c
WHERE c.hypertable_name = 'merge_test'
ORDER BY c.range_start;
     chunk_name     | is_compressed |         range_start          |           range_end           
--------------------+---------------+------------------------------+-------------------------------
 _hyper_13_39_chunk | t             | Mon Jan 01 00:00:00 2024 CET | Fri Mar 01 00:00:00 2024 CET
 _hyper_13_41_chunk | t             | Fri Mar 01 00:00:00 2024 CET | Wed May 01 00:00:00 2024 CEST

-- Verify data integrity after merge
SELECT count(*) as total_rows FROM merge_test;
 total_rows 
------------
        184

-- Clean up merge test table
DROP TABLE merge_test;
---------------------------------------------------------------
-- RETENTION POLICY with calendar-chunked hypertables
---------------------------------------------------------------
-- Add retention policy with 2 week threshold
SELECT add_retention_policy('metrics_weekly', INTERVAL '2 weeks', schedule_interval => INTERVAL '1 year') as weekly_retention_job \gset
-- Mock time to 2024-02-01 - with 2 week policy, first two chunks will be dropped
SET timescaledb.current_timestamp_mock = '2024-02-01 00:00:00+01';
-- Show chunks before running retention policy (4 chunks: Jan 1-7, 8-14, 15-21, 22-28)
SELECT chunk_name, range_start, range_end
FROM timescaledb_information.chunks
WHERE hypertable_name = 'metrics_weekly'
ORDER BY range_start;
    chunk_name    |         range_start          |          range_end           
------------------+------------------------------+------------------------------
 _hyper_2_4_chunk | Mon Jan 01 00:00:00 2024 CET | Mon Jan 08 00:00:00 2024 CET
 _hyper_2_5_chunk | Mon Jan 08 00:00:00 2024 CET | Mon Jan 15 00:00:00 2024 CET
 _hyper_2_6_chunk | Mon Jan 15 00:00:00 2024 CET | Mon Jan 22 00:00:00 2024 CET
 _hyper_2_7_chunk | Mon Jan 22 00:00:00 2024 CET | Mon Jan 29 00:00:00 2024 CET

-- Run the retention policy job
CALL run_job(:weekly_retention_job);
-- Verify first two chunks were dropped (older than 2 weeks from mock time)
SELECT chunk_name, range_start, range_end
FROM timescaledb_information.chunks
WHERE hypertable_name = 'metrics_weekly'
ORDER BY range_start;
    chunk_name    |         range_start          |          range_end           
------------------+------------------------------+------------------------------
 _hyper_2_6_chunk | Mon Jan 15 00:00:00 2024 CET | Mon Jan 22 00:00:00 2024 CET
 _hyper_2_7_chunk | Mon Jan 22 00:00:00 2024 CET | Mon Jan 29 00:00:00 2024 CET

RESET timescaledb.current_timestamp_mock;
---------------------------------------------------------------
-- CLEANUP
---------------------------------------------------------------
-- Drop CAggs first (they depend on the tables)
DROP MATERIALIZED VIEW cagg_monthly;
NOTICE:  drop cascades to table _timescaledb_internal._hyper_6_25_chunk
DROP MATERIALIZED VIEW cagg_daily;
NOTICE:  drop cascades to table _timescaledb_internal._hyper_7_26_chunk
DROP MATERIALIZED VIEW cagg_hourly;
DROP MATERIALIZED VIEW cagg_fiscal;
DROP TABLE cagg_test_monthly;
-- Remove policies
SELECT remove_retention_policy('metrics_weekly', if_exists => true);
 remove_retention_policy 
-------------------------
 

SELECT remove_compression_policy('metrics_monthly', if_exists => true);
 remove_compression_policy 
---------------------------
 t

-- Drop objects
DROP TABLE metrics_monthly;
DROP TABLE metrics_weekly;
DROP TABLE metrics_daily;
DROP TABLE metrics_fiscal;
RESET timescaledb.enable_calendar_chunking;
