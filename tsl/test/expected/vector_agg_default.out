-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\c :TEST_DBNAME :ROLE_SUPERUSER
create function stable_abs(x int4) returns int4 as 'int4abs' language internal stable;
create table dvagg(a int, b int);
select create_hypertable('dvagg', 'a', chunk_time_interval => 1000);
NOTICE:  adding not-null constraint to column "a"
 create_hypertable  
--------------------
 (1,public,dvagg,t)
(1 row)

insert into dvagg select x, x % 5 from generate_series(1, 999) x;
alter table dvagg set (timescaledb.compress);
WARNING:  there was some uncertainty picking the default segment by for the hypertable: You do not have any indexes on columns that can be used for segment_by and thus we are not using segment_by for compression. Please make sure you are not missing any indexes
NOTICE:  default segment by for hypertable "dvagg" is set to ""
NOTICE:  default order by for hypertable "dvagg" is set to "a DESC"
select compress_chunk(show_chunks('dvagg'));
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
(1 row)

alter table dvagg add column c int default 7;
insert into dvagg select x, x % 5, 11 from generate_series(1001, 1999) x;
select compress_chunk(show_chunks('dvagg'));
NOTICE:  chunk "_hyper_1_1_chunk" is already compressed
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_3_chunk
(2 rows)

-- Just the most basic vectorized aggregation query on a table with default
-- compressed column.
explain (costs off) select sum(c) from dvagg;
                                 QUERY PLAN                                  
-----------------------------------------------------------------------------
 Finalize Aggregate
   ->  Gather
         Workers Planned: 2
         ->  Parallel Append
               ->  Custom Scan (VectorAgg)
                     ->  Custom Scan (DecompressChunk) on _hyper_1_1_chunk
                           ->  Parallel Seq Scan on compress_hyper_2_2_chunk
               ->  Custom Scan (VectorAgg)
                     ->  Custom Scan (DecompressChunk) on _hyper_1_3_chunk
                           ->  Parallel Seq Scan on compress_hyper_2_4_chunk
(10 rows)

select sum(c) from dvagg;
  sum  
-------
 17982
(1 row)

---- Uncomment to generate reference.
--set timescaledb.enable_vectorized_aggregation to off;
-- Vectorized aggregation should work with vectorized filters.
select sum(c) from dvagg where b >= 0;
  sum  
-------
 17982
(1 row)

select sum(c) from dvagg where b = 0;
 sum  
------
 3582
(1 row)

select sum(c) from dvagg where b in (0, 1);
 sum  
------
 7182
(1 row)

select sum(c) from dvagg where b in (0, 1, 3);
  sum  
-------
 10782
(1 row)

select sum(c) from dvagg where b > 10;
 sum 
-----
    
(1 row)

select count(*) from dvagg where b >= 0;
 count 
-------
  1998
(1 row)

select count(*) from dvagg where b = 0;
 count 
-------
   398
(1 row)

select count(*) from dvagg where b in (0, 1);
 count 
-------
   798
(1 row)

select count(*) from dvagg where b in (0, 1, 3);
 count 
-------
  1198
(1 row)

select count(*) from dvagg where b > 10;
 count 
-------
     0
(1 row)

explain (costs off) select sum(c) from dvagg where b in (0, 1, 3);
                                  QUERY PLAN                                   
-------------------------------------------------------------------------------
 Finalize Aggregate
   ->  Gather
         Workers Planned: 2
         ->  Parallel Append
               ->  Custom Scan (VectorAgg)
                     ->  Custom Scan (DecompressChunk) on _hyper_1_1_chunk
                           Vectorized Filter: (b = ANY ('{0,1,3}'::integer[]))
                           ->  Parallel Seq Scan on compress_hyper_2_2_chunk
               ->  Custom Scan (VectorAgg)
                     ->  Custom Scan (DecompressChunk) on _hyper_1_3_chunk
                           Vectorized Filter: (b = ANY ('{0,1,3}'::integer[]))
                           ->  Parallel Seq Scan on compress_hyper_2_4_chunk
(12 rows)

select sum(a), sum(b), sum(c) from dvagg where b in (0, 1, 3);
   sum   | sum  |  sum  
---------+------+-------
 1197600 | 1600 | 10782
(1 row)

explain (costs off) select sum(a), sum(b), sum(c) from dvagg where b in (0, 1, 3);
                                  QUERY PLAN                                   
-------------------------------------------------------------------------------
 Finalize Aggregate
   ->  Gather
         Workers Planned: 2
         ->  Parallel Append
               ->  Custom Scan (VectorAgg)
                     ->  Custom Scan (DecompressChunk) on _hyper_1_1_chunk
                           Vectorized Filter: (b = ANY ('{0,1,3}'::integer[]))
                           ->  Parallel Seq Scan on compress_hyper_2_2_chunk
               ->  Custom Scan (VectorAgg)
                     ->  Custom Scan (DecompressChunk) on _hyper_1_3_chunk
                           Vectorized Filter: (b = ANY ('{0,1,3}'::integer[]))
                           ->  Parallel Seq Scan on compress_hyper_2_4_chunk
(12 rows)

reset timescaledb.enable_vectorized_aggregation;
-- The runtime chunk exclusion should work.
explain (costs off) select sum(c) from dvagg where a < stable_abs(1000);
                             QUERY PLAN                              
---------------------------------------------------------------------
 Finalize Aggregate
   ->  Custom Scan (ChunkAppend) on dvagg
         Chunks excluded during startup: 1
         ->  Custom Scan (VectorAgg)
               ->  Custom Scan (DecompressChunk) on _hyper_1_1_chunk
                     Vectorized Filter: (a < stable_abs(1000))
                     ->  Seq Scan on compress_hyper_2_2_chunk
(7 rows)

-- Some negative cases.
explain (costs off) select sum(c) from dvagg group by grouping sets ((), (a));
                                    QUERY PLAN                                     
-----------------------------------------------------------------------------------
 MixedAggregate
   Hash Key: _hyper_1_1_chunk.a
   Group Key: ()
   ->  Append
         ->  Custom Scan (DecompressChunk) on _hyper_1_1_chunk
               ->  Sort
                     Sort Key: compress_hyper_2_2_chunk._ts_meta_sequence_num DESC
                     ->  Seq Scan on compress_hyper_2_2_chunk
         ->  Custom Scan (DecompressChunk) on _hyper_1_3_chunk
               ->  Sort
                     Sort Key: compress_hyper_2_4_chunk._ts_meta_sequence_num DESC
                     ->  Seq Scan on compress_hyper_2_4_chunk
(12 rows)

explain (costs off) select sum(c) from dvagg having sum(c) > 0;
                                 QUERY PLAN                                  
-----------------------------------------------------------------------------
 Finalize Aggregate
   Filter: (sum(_hyper_1_1_chunk.c) > 0)
   ->  Gather
         Workers Planned: 2
         ->  Parallel Append
               ->  Custom Scan (VectorAgg)
                     ->  Custom Scan (DecompressChunk) on _hyper_1_1_chunk
                           ->  Parallel Seq Scan on compress_hyper_2_2_chunk
               ->  Custom Scan (VectorAgg)
                     ->  Custom Scan (DecompressChunk) on _hyper_1_3_chunk
                           ->  Parallel Seq Scan on compress_hyper_2_4_chunk
(11 rows)

-- As a reference, the result on decompressed table.
select decompress_chunk(show_chunks('dvagg'));
            decompress_chunk            
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
 _timescaledb_internal._hyper_1_3_chunk
(2 rows)

select sum(c) from dvagg;
  sum  
-------
 17982
(1 row)

drop table dvagg;
