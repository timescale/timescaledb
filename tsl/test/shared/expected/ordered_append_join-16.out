-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
SET timescaledb.enable_now_constify TO FALSE;
SELECT
       format('include/%s.sql', :'TEST_BASE_NAME') as "TEST_QUERY_NAME",
       format('%s/shared/results/%s_results_uncompressed.out', :'TEST_OUTPUT_DIR', :'TEST_BASE_NAME') as "TEST_RESULTS_UNCOMPRESSED",
       format('%s/shared/results/%s_results_compressed.out', :'TEST_OUTPUT_DIR', :'TEST_BASE_NAME') as "TEST_RESULTS_COMPRESSED"
\gset
SELECT format('\! diff -u --label "Uncompressed results" --label "Compressed results" %s %s', :'TEST_RESULTS_UNCOMPRESSED', :'TEST_RESULTS_COMPRESSED') as "DIFF_CMD"
\gset
-- get EXPLAIN output for all variations
\set PREFIX 'EXPLAIN (analyze, costs off, timing off, summary off)'
\set PREFIX_VERBOSE 'EXPLAIN (analyze, costs off, timing off, summary off, verbose)'
set work_mem to '64MB';
set max_parallel_workers_per_gather to 0;
\set TEST_TABLE 'metrics'
\ir :TEST_QUERY_NAME
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- In the following test cases, we test that certain indexes are used. By using the
-- timescaledb.enable_decompression_sorted_merge optimization, we are pushing a sort node
-- below the DecompressChunk node, which operates on the batches. This could lead to flaky
-- tests because the input data is small and PostgreSQL switches from IndexScans to
-- SequentialScans. Disable the optimization for the following tests to ensure we have
-- stable query plans in all CI environments.
SET timescaledb.enable_decompression_sorted_merge = 0;
-- test LATERAL with ordered append in the outer query
:PREFIX
SELECT time,
  pg_typeof(l)
FROM :TEST_TABLE,
  LATERAL (
    SELECT *
    FROM (
      VALUES (1),
        (2)) v) l
ORDER BY time DESC
LIMIT 2;
QUERY PLAN
 Limit (actual rows=2 loops=1)
   ->  Nested Loop (actual rows=2 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics (actual rows=1 loops=1)
               Order: metrics."time" DESC
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                     Heap Fetches: 1
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (never executed)
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (never executed)
                     Heap Fetches: 0
         ->  Materialize (actual rows=2 loops=1)
               ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
(12 rows)

-- test LATERAL with ordered append in the lateral query
:PREFIX
SELECT time,
  pg_typeof(v)
FROM (
  VALUES (1),
    (2)) v,
  LATERAL (
    SELECT *
    FROM :TEST_TABLE
    ORDER BY time DESC
    LIMIT 2) l;
QUERY PLAN
 Nested Loop (actual rows=4 loops=1)
   ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
   ->  Materialize (actual rows=2 loops=2)
         ->  Subquery Scan on l (actual rows=2 loops=1)
               ->  Limit (actual rows=2 loops=1)
                     ->  Result (actual rows=2 loops=1)
                           ->  Custom Scan (ChunkAppend) on metrics (actual rows=2 loops=1)
                                 Order: metrics."time" DESC
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (actual rows=2 loops=1)
                                       Heap Fetches: 2
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (never executed)
                                       Heap Fetches: 0
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (never executed)
                                       Heap Fetches: 0
(14 rows)

-- test plan with best index is chosen
-- this should use device_id, time index
:PREFIX
SELECT time,
  device_id
FROM :TEST_TABLE
WHERE device_id = 1
ORDER BY time DESC
LIMIT 1;
QUERY PLAN
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics (actual rows=1 loops=1)
         Order: metrics."time" DESC
         ->  Index Only Scan using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
               Index Cond: (device_id = 1)
               Heap Fetches: 1
         ->  Index Only Scan using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk (never executed)
               Index Cond: (device_id = 1)
               Heap Fetches: 0
         ->  Index Only Scan using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk (never executed)
               Index Cond: (device_id = 1)
               Heap Fetches: 0
(12 rows)

-- test plan with best index is chosen
-- this should use time index
:PREFIX
SELECT time
FROM :TEST_TABLE
ORDER BY time DESC
LIMIT 1;
QUERY PLAN
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics (actual rows=1 loops=1)
         Order: metrics."time" DESC
         ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
               Heap Fetches: 1
         ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (never executed)
               Heap Fetches: 0
         ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (never executed)
               Heap Fetches: 0
(9 rows)

-- test LATERAL with correlated query
-- only last chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Result (actual rows=1 loops=3)
               ->  Custom Scan (ChunkAppend) on metrics o (actual rows=1 loops=3)
                     Order: o."time" DESC
                     Chunks excluded during startup: 0
                     Chunks excluded during runtime: 2
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o_1 (never executed)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o_2 (never executed)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o_3 (actual rows=1 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 3
(17 rows)

-- test LATERAL with correlated query
-- only 2nd chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-10'::timestamptz, '2000-01-11', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=2 loops=1)
   ->  Function Scan on generate_series g (actual rows=2 loops=1)
   ->  Limit (actual rows=1 loops=2)
         ->  Result (actual rows=1 loops=2)
               ->  Custom Scan (ChunkAppend) on metrics o (actual rows=1 loops=2)
                     Order: o."time"
                     Chunks excluded during startup: 0
                     Chunks excluded during runtime: 2
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o_1 (never executed)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o_2 (actual rows=1 loops=2)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 2
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o_3 (never executed)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
(17 rows)

-- test startup and runtime exclusion together
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time < now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Result (actual rows=1 loops=3)
               ->  Custom Scan (ChunkAppend) on metrics o (actual rows=1 loops=3)
                     Order: o."time" DESC
                     Chunks excluded during startup: 0
                     Chunks excluded during runtime: 2
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o_1 (never executed)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o_2 (never executed)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o_3 (actual rows=1 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 3
(17 rows)

-- test startup and runtime exclusion together
-- all chunks should be filtered
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time > now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=0 loops=3)
         ->  Result (actual rows=0 loops=3)
               ->  Custom Scan (ChunkAppend) on metrics o (actual rows=0 loops=3)
                     Order: o."time" DESC
                     Chunks excluded during startup: 3
(7 rows)

-- test JOIN
-- no exclusion on joined table because quals are not propagated yet
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.time < '2000-02-01'
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time;
QUERY PLAN
 Merge Join (actual rows=13674 loops=1)
   Merge Cond: (o1."time" = o2."time")
   ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=3598 loops=1)
               Index Cond: ((device_id = 1) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
               Heap Fetches: 3598
         ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (actual rows=5038 loops=1)
               Index Cond: ((device_id = 1) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
               Heap Fetches: 5038
         ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (actual rows=5038 loops=1)
               Index Cond: ((device_id = 1) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
               Heap Fetches: 5038
   ->  Materialize (actual rows=13674 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=13674 loops=1)
               Order: o2."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=3598 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 3598
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_2 (actual rows=5038 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 5038
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_3 (actual rows=5038 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 5038
(25 rows)

-- test JOIN
-- last chunk of o2 should not be executed
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT *
    FROM :TEST_TABLE o2
    ORDER BY time) o2 ON o1.time = o2.time
WHERE o1.time < '2000-01-08'
ORDER BY o1.time
LIMIT 10;
QUERY PLAN
 Limit (actual rows=10 loops=1)
   ->  Merge Join (actual rows=10 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=2 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o1_1 (actual rows=2 loops=1)
                     Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     Heap Fetches: 2
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     Heap Fetches: 0
         ->  Materialize (actual rows=10 loops=1)
               ->  Result (actual rows=6 loops=1)
                     ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=6 loops=1)
                           Order: o2."time"
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o2_1 (actual rows=6 loops=1)
                                 Heap Fetches: 6
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                                 Heap Fetches: 0
(21 rows)

-- test join against max query
-- not ChunkAppend so no chunk exclusion
SET enable_hashjoin = FALSE;
:PREFIX
SELECT o1.time,
  o2.*
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT max(time) AS max_time
    FROM :TEST_TABLE) o2 ON o1.time = o2.max_time
WHERE o1.device_id = 1
ORDER BY time;
QUERY PLAN
 Sort (actual rows=1 loops=1)
   Sort Key: o1_1."time"
   Sort Method: quicksort 
   ->  Nested Loop (actual rows=1 loops=1)
         ->  Result (actual rows=1 loops=1)
               InitPlan 1 (returns $0)
                 ->  Limit (actual rows=1 loops=1)
                       ->  Custom Scan (ChunkAppend) on metrics (actual rows=1 loops=1)
                             Order: metrics."time" DESC
                             ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                                   Index Cond: ("time" IS NOT NULL)
                                   Heap Fetches: 1
                             ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (never executed)
                                   Index Cond: ("time" IS NOT NULL)
                                   Heap Fetches: 0
                             ->  Index Only Scan using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk (never executed)
                                   Index Cond: ("time" IS NOT NULL)
                                   Heap Fetches: 0
         ->  Append (actual rows=1 loops=1)
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=0 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (actual rows=0 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (actual rows=1 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 1
(28 rows)

RESET enable_hashjoin;
SET enable_seqscan TO false;
-- test JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column with USING
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 USING (time)
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test NATURAL JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  NATURAL INNER JOIN :TEST_TABLE o2
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=0 loops=1)
   ->  Sort (actual rows=0 loops=1)
         Sort Key: o1."time"
         Sort Method: quicksort 
         ->  Result (actual rows=0 loops=1)
               One-Time Filter: false
(6 rows)

-- test LEFT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  LEFT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test RIGHT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  RIGHT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column with ON clause expression order switched
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o2.time = o1.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column with equality condition in WHERE clause
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON TRUE
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column with ORDER BY 2nd hypertable
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column and device_id
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
    AND o1.time = o2.time
  ORDER BY o1.time
  LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         Join Filter: (o1.device_id = o2.device_id)
         Rows Removed by Join Filter: 400
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
               ->  Index Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o1_2 (never executed)
               ->  Index Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o1_3 (never executed)
         ->  Materialize (actual rows=500 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=101 loops=1)
                     Order: o2."time"
                     ->  Index Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o2_1 (actual rows=101 loops=1)
                     ->  Index Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                     ->  Index Scan Backward using _hyper_X_X_chunk_metrics_time_idx on _hyper_X_X_chunk o2_3 (never executed)
(16 rows)

-- test JOIN on device_id
-- should not use ordered append for 2nd hypertable
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
WHERE o1.device_id = 1
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Nested Loop (actual rows=100 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=1 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=1 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 1
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Append (actual rows=100 loops=1)
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 0
(24 rows)

-- test JOIN on time column with implicit join
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1,
  :TEST_TABLE o2
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column with 3 hypertables
-- should use 3 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
  INNER JOIN :TEST_TABLE o3 ON o1.time = o3.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
  AND o3.device_id = 3
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o3."time" = o1."time")
         ->  Custom Scan (ChunkAppend) on metrics o3 (actual rows=100 loops=1)
               Order: o3."time"
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o3_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 3)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o3_2 (never executed)
                     Index Cond: (device_id = 3)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o3_3 (never executed)
                     Index Cond: (device_id = 3)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Merge Join (actual rows=100 loops=1)
                     Merge Cond: (o1."time" = o2."time")
                     ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
                           Order: o1."time"
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                                 Index Cond: (device_id = 1)
                                 Heap Fetches: 100
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                                 Index Cond: (device_id = 1)
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                                 Index Cond: (device_id = 1)
                                 Heap Fetches: 0
                     ->  Materialize (actual rows=100 loops=1)
                           ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                                 Order: o2."time"
                                 ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 100
                                 ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 0
                                 ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 0
(40 rows)

RESET enable_seqscan;
\set TEST_TABLE 'metrics_space'
\ir :TEST_QUERY_NAME
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- In the following test cases, we test that certain indexes are used. By using the
-- timescaledb.enable_decompression_sorted_merge optimization, we are pushing a sort node
-- below the DecompressChunk node, which operates on the batches. This could lead to flaky
-- tests because the input data is small and PostgreSQL switches from IndexScans to
-- SequentialScans. Disable the optimization for the following tests to ensure we have
-- stable query plans in all CI environments.
SET timescaledb.enable_decompression_sorted_merge = 0;
-- test LATERAL with ordered append in the outer query
:PREFIX
SELECT time,
  pg_typeof(l)
FROM :TEST_TABLE,
  LATERAL (
    SELECT *
    FROM (
      VALUES (1),
        (2)) v) l
ORDER BY time DESC
LIMIT 2;
QUERY PLAN
 Limit (actual rows=2 loops=1)
   ->  Nested Loop (actual rows=2 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_space (actual rows=1 loops=1)
               Order: metrics_space."time" DESC
               ->  Merge Append (actual rows=1 loops=1)
                     Sort Key: _hyper_X_X_chunk."time" DESC
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                           Heap Fetches: 1
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                           Heap Fetches: 1
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                           Heap Fetches: 1
               ->  Merge Append (never executed)
                     Sort Key: _hyper_X_X_chunk."time" DESC
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                           Heap Fetches: 0
               ->  Merge Append (never executed)
                     Sort Key: _hyper_X_X_chunk."time" DESC
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                           Heap Fetches: 0
         ->  Materialize (actual rows=2 loops=1)
               ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
(30 rows)

-- test LATERAL with ordered append in the lateral query
:PREFIX
SELECT time,
  pg_typeof(v)
FROM (
  VALUES (1),
    (2)) v,
  LATERAL (
    SELECT *
    FROM :TEST_TABLE
    ORDER BY time DESC
    LIMIT 2) l;
QUERY PLAN
 Nested Loop (actual rows=4 loops=1)
   ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
   ->  Materialize (actual rows=2 loops=2)
         ->  Subquery Scan on l (actual rows=2 loops=1)
               ->  Limit (actual rows=2 loops=1)
                     ->  Result (actual rows=2 loops=1)
                           ->  Custom Scan (ChunkAppend) on metrics_space (actual rows=2 loops=1)
                                 Order: metrics_space."time" DESC
                                 ->  Merge Append (actual rows=2 loops=1)
                                       Sort Key: _hyper_X_X_chunk."time" DESC
                                       ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=2 loops=1)
                                             Heap Fetches: 2
                                       ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                                             Heap Fetches: 1
                                       ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                                             Heap Fetches: 1
                                 ->  Merge Append (never executed)
                                       Sort Key: _hyper_X_X_chunk."time" DESC
                                       ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                             Heap Fetches: 0
                                       ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                             Heap Fetches: 0
                                       ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                             Heap Fetches: 0
                                 ->  Merge Append (never executed)
                                       Sort Key: _hyper_X_X_chunk."time" DESC
                                       ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                             Heap Fetches: 0
                                       ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                             Heap Fetches: 0
                                       ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                             Heap Fetches: 0
(32 rows)

-- test plan with best index is chosen
-- this should use device_id, time index
:PREFIX
SELECT time,
  device_id
FROM :TEST_TABLE
WHERE device_id = 1
ORDER BY time DESC
LIMIT 1;
QUERY PLAN
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics_space (actual rows=1 loops=1)
         Order: metrics_space."time" DESC
         ->  Index Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
               Filter: (device_id = 1)
         ->  Index Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
               Filter: (device_id = 1)
         ->  Index Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
               Filter: (device_id = 1)
(9 rows)

-- test plan with best index is chosen
-- this should use time index
:PREFIX
SELECT time
FROM :TEST_TABLE
ORDER BY time DESC
LIMIT 1;
QUERY PLAN
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics_space (actual rows=1 loops=1)
         Order: metrics_space."time" DESC
         ->  Merge Append (actual rows=1 loops=1)
               Sort Key: _hyper_X_X_chunk."time" DESC
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                     Heap Fetches: 1
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                     Heap Fetches: 1
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                     Heap Fetches: 1
         ->  Merge Append (never executed)
               Sort Key: _hyper_X_X_chunk."time" DESC
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                     Heap Fetches: 0
         ->  Merge Append (never executed)
               Sort Key: _hyper_X_X_chunk."time" DESC
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                     Heap Fetches: 0
(27 rows)

-- test LATERAL with correlated query
-- only last chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Result (actual rows=1 loops=3)
               ->  Custom Scan (ChunkAppend) on metrics_space o (actual rows=1 loops=3)
                     Order: o."time" DESC
                     ->  Merge Append (actual rows=0 loops=3)
                           Sort Key: o_1."time" DESC
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_1 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_2 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_3 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
                     ->  Merge Append (actual rows=0 loops=3)
                           Sort Key: o_4."time" DESC
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_4 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_5 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_6 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
                     ->  Merge Append (actual rows=1 loops=3)
                           Sort Key: o_7."time" DESC
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_7 (actual rows=1 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 3
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_8 (actual rows=1 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 3
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_9 (actual rows=1 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 3
(39 rows)

-- test LATERAL with correlated query
-- only 2nd chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-10'::timestamptz, '2000-01-11', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=2 loops=1)
   ->  Function Scan on generate_series g (actual rows=2 loops=1)
   ->  Limit (actual rows=1 loops=2)
         ->  Result (actual rows=1 loops=2)
               ->  Custom Scan (ChunkAppend) on metrics_space o (actual rows=1 loops=2)
                     Order: o."time"
                     ->  Merge Append (actual rows=0 loops=2)
                           Sort Key: o_1."time"
                           ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_1 (actual rows=0 loops=2)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
                           ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_2 (actual rows=0 loops=2)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
                           ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_3 (actual rows=0 loops=2)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
                     ->  Merge Append (actual rows=1 loops=2)
                           Sort Key: o_4."time"
                           ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_4 (actual rows=1 loops=2)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 2
                           ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_5 (actual rows=1 loops=2)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 2
                           ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_6 (actual rows=1 loops=2)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 2
                     ->  Merge Append (never executed)
                           Sort Key: o_7."time"
                           ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_7 (never executed)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
                           ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_8 (never executed)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
                           ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_9 (never executed)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Heap Fetches: 0
(39 rows)

-- test startup and runtime exclusion together
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time < now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Result (actual rows=1 loops=3)
               ->  Custom Scan (ChunkAppend) on metrics_space o (actual rows=1 loops=3)
                     Order: o."time" DESC
                     ->  Merge Append (actual rows=0 loops=3)
                           Sort Key: o_1."time" DESC
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_1 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_2 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_3 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Heap Fetches: 0
                     ->  Merge Append (actual rows=0 loops=3)
                           Sort Key: o_4."time" DESC
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_4 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_5 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_6 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Heap Fetches: 0
                     ->  Merge Append (actual rows=1 loops=3)
                           Sort Key: o_7."time" DESC
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_7 (actual rows=1 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Heap Fetches: 3
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_8 (actual rows=1 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Heap Fetches: 3
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_9 (actual rows=1 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Heap Fetches: 3
(39 rows)

-- test startup and runtime exclusion together
-- all chunks should be filtered
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time > now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=0 loops=3)
         ->  Result (actual rows=0 loops=3)
               ->  Custom Scan (ChunkAppend) on metrics_space o (actual rows=0 loops=3)
                     Order: o."time" DESC
                     ->  Merge Append (actual rows=0 loops=3)
                           Sort Key: o_1."time" DESC
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_1 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_2 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_3 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Heap Fetches: 0
                     ->  Merge Append (actual rows=0 loops=3)
                           Sort Key: o_4."time" DESC
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_4 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_5 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_6 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Heap Fetches: 0
                     ->  Merge Append (actual rows=0 loops=3)
                           Sort Key: o_7."time" DESC
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_7 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_8 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o_9 (actual rows=0 loops=3)
                                 Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Heap Fetches: 0
(39 rows)

-- test JOIN
-- no exclusion on joined table because quals are not propagated yet
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.time < '2000-02-01'
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time;
QUERY PLAN
 Merge Join (actual rows=13674 loops=1)
   Merge Cond: (o1."time" = o2."time")
   ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=3598 loops=1)
               Index Cond: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               Filter: (device_id = 1)
         ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (actual rows=5038 loops=1)
               Index Cond: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               Filter: (device_id = 1)
         ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (actual rows=5038 loops=1)
               Index Cond: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               Filter: (device_id = 1)
   ->  Materialize (actual rows=13674 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=13674 loops=1)
               Order: o2."time"
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=3598 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 3598
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_2 (actual rows=5038 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 5038
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_3 (actual rows=5038 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 5038
(25 rows)

-- test JOIN
-- last chunk of o2 should not be executed
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT *
    FROM :TEST_TABLE o2
    ORDER BY time) o2 ON o1.time = o2.time
WHERE o1.time < '2000-01-08'
ORDER BY o1.time
LIMIT 10;
QUERY PLAN
 Limit (actual rows=10 loops=1)
   ->  Merge Join (actual rows=10 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=2 loops=1)
               Order: o1."time"
               ->  Merge Append (actual rows=2 loops=1)
                     Sort Key: o1_1."time"
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=2 loops=1)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 2
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (actual rows=1 loops=1)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 1
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (actual rows=1 loops=1)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 1
               ->  Merge Append (never executed)
                     Sort Key: o1_4."time"
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_4 (never executed)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_5 (never executed)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_6 (never executed)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 0
         ->  Materialize (actual rows=10 loops=1)
               ->  Result (actual rows=6 loops=1)
                     ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=6 loops=1)
                           Order: o2."time"
                           ->  Merge Append (actual rows=6 loops=1)
                                 Sort Key: o2_1."time"
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_1 (actual rows=2 loops=1)
                                       Heap Fetches: 2
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_2 (actual rows=4 loops=1)
                                       Heap Fetches: 4
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_3 (actual rows=2 loops=1)
                                       Heap Fetches: 2
                           ->  Merge Append (never executed)
                                 Sort Key: o2_4."time"
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_4 (never executed)
                                       Heap Fetches: 0
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_5 (never executed)
                                       Heap Fetches: 0
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_6 (never executed)
                                       Heap Fetches: 0
                           ->  Merge Append (never executed)
                                 Sort Key: o2_7."time"
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_7 (never executed)
                                       Heap Fetches: 0
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_8 (never executed)
                                       Heap Fetches: 0
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_9 (never executed)
                                       Heap Fetches: 0
(55 rows)

-- test join against max query
-- not ChunkAppend so no chunk exclusion
SET enable_hashjoin = FALSE;
:PREFIX
SELECT o1.time,
  o2.*
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT max(time) AS max_time
    FROM :TEST_TABLE) o2 ON o1.time = o2.max_time
WHERE o1.device_id = 1
ORDER BY time;
QUERY PLAN
 Sort (actual rows=1 loops=1)
   Sort Key: o1_1."time"
   Sort Method: quicksort 
   ->  Nested Loop (actual rows=1 loops=1)
         ->  Result (actual rows=1 loops=1)
               InitPlan 1 (returns $0)
                 ->  Limit (actual rows=1 loops=1)
                       ->  Custom Scan (ChunkAppend) on metrics_space (actual rows=1 loops=1)
                             Order: metrics_space."time" DESC
                             ->  Merge Append (actual rows=1 loops=1)
                                   Sort Key: _hyper_X_X_chunk."time" DESC
                                   ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 1
                                   ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 1
                                   ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (actual rows=1 loops=1)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 1
                             ->  Merge Append (never executed)
                                   Sort Key: _hyper_X_X_chunk."time" DESC
                                   ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
                                   ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
                                   ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
                             ->  Merge Append (never executed)
                                   Sort Key: _hyper_X_X_chunk."time" DESC
                                   ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
                                   ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
                                   ->  Index Only Scan Backward using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
         ->  Append (actual rows=1 loops=1)
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o1_1 (actual rows=0 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o1_2 (actual rows=0 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o1_3 (actual rows=1 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 1
(52 rows)

RESET enable_hashjoin;
SET enable_seqscan TO false;
-- test JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column with USING
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 USING (time)
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test NATURAL JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  NATURAL INNER JOIN :TEST_TABLE o2
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=0 loops=1)
   ->  Sort (actual rows=0 loops=1)
         Sort Key: o1."time"
         Sort Method: quicksort 
         ->  Result (actual rows=0 loops=1)
               One-Time Filter: false
(6 rows)

-- test LEFT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  LEFT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test RIGHT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  RIGHT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column with ON clause expression order switched
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o2.time = o1.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column with equality condition in WHERE clause
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON TRUE
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column with ORDER BY 2nd hypertable
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column and device_id
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
    AND o1.time = o2.time
  ORDER BY o1.time
  LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         Join Filter: (o1.device_id = o2.device_id)
         Rows Removed by Join Filter: 400
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Merge Append (actual rows=100 loops=1)
                     Sort Key: o1_1."time"
                     ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=21 loops=1)
                     ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (actual rows=60 loops=1)
                     ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (actual rows=21 loops=1)
               ->  Merge Append (never executed)
                     Sort Key: o1_4."time"
                     ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_4 (never executed)
                     ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_5 (never executed)
                     ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_6 (never executed)
               ->  Merge Append (never executed)
                     Sort Key: o1_7."time"
                     ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_7 (never executed)
                     ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_8 (never executed)
                     ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_9 (never executed)
         ->  Materialize (actual rows=500 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=101 loops=1)
                     Order: o2."time"
                     ->  Merge Append (actual rows=101 loops=1)
                           Sort Key: o2_1."time"
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_1 (actual rows=21 loops=1)
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_2 (actual rows=61 loops=1)
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_3 (actual rows=21 loops=1)
                     ->  Merge Append (never executed)
                           Sort Key: o2_4."time"
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_4 (never executed)
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_5 (never executed)
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_6 (never executed)
                     ->  Merge Append (never executed)
                           Sort Key: o2_7."time"
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_7 (never executed)
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_8 (never executed)
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o2_9 (never executed)
(40 rows)

-- test JOIN on device_id
-- should not use ordered append for 2nd hypertable
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
WHERE o1.device_id = 1
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Nested Loop (actual rows=100 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=1 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=1 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Append (actual rows=100 loops=1)
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 0
(21 rows)

-- test JOIN on time column with implicit join
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1,
  :TEST_TABLE o2
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column with 3 hypertables
-- should use 3 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
  INNER JOIN :TEST_TABLE o3 ON o1.time = o3.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
  AND o3.device_id = 3
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o3."time" = o1."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o3 (actual rows=100 loops=1)
               Order: o3."time"
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o3_1 (actual rows=100 loops=1)
                     Filter: (device_id = 3)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o3_2 (never executed)
                     Filter: (device_id = 3)
               ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o3_3 (never executed)
                     Filter: (device_id = 3)
         ->  Materialize (actual rows=100 loops=1)
               ->  Merge Join (actual rows=100 loops=1)
                     Merge Cond: (o1."time" = o2."time")
                     ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
                           Order: o1."time"
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                                 Filter: (device_id = 1)
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_2 (never executed)
                                 Filter: (device_id = 1)
                           ->  Index Scan using _hyper_X_X_chunk_metrics_space_time_idx on _hyper_X_X_chunk o1_3 (never executed)
                                 Filter: (device_id = 1)
                     ->  Materialize (actual rows=100 loops=1)
                           ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                                 Order: o2."time"
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 100
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_2 (never executed)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 0
                                 ->  Index Only Scan using _hyper_X_X_chunk_metrics_space_device_id_time_idx on _hyper_X_X_chunk o2_3 (never executed)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 0
(34 rows)

RESET enable_seqscan;
\set TEST_TABLE 'metrics_compressed'
\ir :TEST_QUERY_NAME
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- In the following test cases, we test that certain indexes are used. By using the
-- timescaledb.enable_decompression_sorted_merge optimization, we are pushing a sort node
-- below the DecompressChunk node, which operates on the batches. This could lead to flaky
-- tests because the input data is small and PostgreSQL switches from IndexScans to
-- SequentialScans. Disable the optimization for the following tests to ensure we have
-- stable query plans in all CI environments.
SET timescaledb.enable_decompression_sorted_merge = 0;
-- test LATERAL with ordered append in the outer query
:PREFIX
SELECT time,
  pg_typeof(l)
FROM :TEST_TABLE,
  LATERAL (
    SELECT *
    FROM (
      VALUES (1),
        (2)) v) l
ORDER BY time DESC
LIMIT 2;
QUERY PLAN
 Limit (actual rows=2 loops=1)
   ->  Sort (actual rows=2 loops=1)
         Sort Key: _hyper_X_X_chunk."time" DESC
         Sort Method: top-N heapsort 
         ->  Nested Loop (actual rows=136740 loops=1)
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=25190 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=30 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=25190 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=30 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=17990 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=20 loops=1)
               ->  Materialize (actual rows=2 loops=68370)
                     ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
(14 rows)

-- test LATERAL with ordered append in the lateral query
:PREFIX
SELECT time,
  pg_typeof(v)
FROM (
  VALUES (1),
    (2)) v,
  LATERAL (
    SELECT *
    FROM :TEST_TABLE
    ORDER BY time DESC
    LIMIT 2) l;
QUERY PLAN
 Nested Loop (actual rows=4 loops=1)
   ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
   ->  Materialize (actual rows=2 loops=2)
         ->  Subquery Scan on l (actual rows=2 loops=1)
               ->  Limit (actual rows=2 loops=1)
                     ->  Sort (actual rows=2 loops=1)
                           Sort Key: _hyper_X_X_chunk."time" DESC
                           Sort Method: top-N heapsort 
                           ->  Result (actual rows=68370 loops=1)
                                 ->  Append (actual rows=68370 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=25190 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=30 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=25190 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=30 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=17990 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=20 loops=1)
(16 rows)

-- test plan with best index is chosen
-- this should use device_id, time index
:PREFIX
SELECT time,
  device_id
FROM :TEST_TABLE
WHERE device_id = 1
ORDER BY time DESC
LIMIT 1;
QUERY PLAN
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics_compressed (actual rows=1 loops=1)
         Order: metrics_compressed."time" DESC
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=1 loops=1)
               ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (never executed)
               ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (never executed)
               ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                     Index Cond: (device_id = 1)
(12 rows)

-- test plan with best index is chosen
-- this should use time index
:PREFIX
SELECT time
FROM :TEST_TABLE
ORDER BY time DESC
LIMIT 1;
QUERY PLAN
 Limit (actual rows=1 loops=1)
   ->  Sort (actual rows=1 loops=1)
         Sort Key: _hyper_X_X_chunk."time" DESC
         Sort Method: top-N heapsort 
         ->  Append (actual rows=68370 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=25190 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=30 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=25190 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=30 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=17990 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=20 loops=1)
(11 rows)

-- test LATERAL with correlated query
-- only last chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Sort (actual rows=1 loops=3)
               Sort Key: o."time" DESC
               Sort Method: top-N heapsort 
               ->  Result (actual rows=3600 loops=3)
                     ->  Custom Scan (ChunkAppend) on metrics_compressed o (actual rows=3600 loops=3)
                           Chunks excluded during startup: 0
                           Chunks excluded during runtime: 2
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_1 (never executed)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_X_X_chunk (never executed)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_2 (never executed)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_X_X_chunk (never executed)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_3 (actual rows=3600 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Rows Removed by Filter: 4063
                                 ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=8 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 12
(24 rows)

-- test LATERAL with correlated query
-- only 2nd chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-10'::timestamptz, '2000-01-11', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=2 loops=1)
   ->  Function Scan on generate_series g (actual rows=2 loops=1)
   ->  Limit (actual rows=1 loops=2)
         ->  Sort (actual rows=1 loops=2)
               Sort Key: o."time"
               Sort Method: top-N heapsort 
               ->  Result (actual rows=3600 loops=2)
                     ->  Custom Scan (ChunkAppend) on metrics_compressed o (actual rows=3600 loops=2)
                           Chunks excluded during startup: 0
                           Chunks excluded during runtime: 2
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_1 (never executed)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_X_X_chunk (never executed)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_2 (actual rows=3600 loops=2)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Rows Removed by Filter: 3900
                                 ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=8 loops=2)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 22
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_3 (never executed)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_X_X_chunk (never executed)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
(24 rows)

-- test startup and runtime exclusion together
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time < now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Sort (actual rows=1 loops=3)
               Sort Key: o."time" DESC
               Sort Method: top-N heapsort 
               ->  Result (actual rows=3600 loops=3)
                     ->  Custom Scan (ChunkAppend) on metrics_compressed o (actual rows=3600 loops=3)
                           Chunks excluded during startup: 0
                           Chunks excluded during runtime: 2
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_1 (never executed)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 ->  Seq Scan on compress_hyper_X_X_chunk (never executed)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_2 (never executed)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 ->  Seq Scan on compress_hyper_X_X_chunk (never executed)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_3 (actual rows=3600 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Rows Removed by Filter: 4063
                                 ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=8 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 12
(24 rows)

-- test startup and runtime exclusion together
-- all chunks should be filtered
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time > now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=0 loops=3)
         ->  Sort (actual rows=0 loops=3)
               Sort Key: o."time" DESC
               Sort Method: quicksort 
               ->  Result (actual rows=0 loops=3)
                     ->  Custom Scan (ChunkAppend) on metrics_compressed o (actual rows=0 loops=3)
                           Chunks excluded during startup: 3
(9 rows)

-- test JOIN
-- no exclusion on joined table because quals are not propagated yet
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.time < '2000-02-01'
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time;
QUERY PLAN
 Merge Join (actual rows=13674 loops=1)
   Merge Cond: (o1."time" = o2."time")
   ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=3598 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (actual rows=5038 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (actual rows=5038 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
   ->  Materialize (actual rows=13674 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=13674 loops=1)
               Order: o2."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=3598 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=4 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (actual rows=5038 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=6 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (actual rows=5038 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=6 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
(37 rows)

-- test JOIN
-- last chunk of o2 should not be executed
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT *
    FROM :TEST_TABLE o2
    ORDER BY time) o2 ON o1.time = o2.time
WHERE o1.time < '2000-01-08'
ORDER BY o1.time
LIMIT 10;
QUERY PLAN
 Limit (actual rows=10 loops=1)
   ->  Merge Join (actual rows=10 loops=1)
         Merge Cond: (o1_1."time" = o2_1."time")
         ->  Sort (actual rows=2 loops=1)
               Sort Key: o1_1."time"
               Sort Method: quicksort 
               ->  Append (actual rows=26390 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=17990 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=20 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (actual rows=8400 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Rows Removed by Filter: 1790
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=15 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                                 Rows Removed by Filter: 15
         ->  Materialize (actual rows=10 loops=1)
               ->  Sort (actual rows=6 loops=1)
                     Sort Key: o2_1."time"
                     Sort Method: quicksort 
                     ->  Result (actual rows=68370 loops=1)
                           ->  Append (actual rows=68370 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=17990 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=20 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (actual rows=25190 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=30 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (actual rows=25190 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=30 loops=1)
(29 rows)

-- test join against max query
-- not ChunkAppend so no chunk exclusion
SET enable_hashjoin = FALSE;
:PREFIX
SELECT o1.time,
  o2.*
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT max(time) AS max_time
    FROM :TEST_TABLE) o2 ON o1.time = o2.max_time
WHERE o1.device_id = 1
ORDER BY time;
QUERY PLAN
 Merge Join (actual rows=1 loops=1)
   Merge Cond: (o1."time" = (max(_hyper_X_X_chunk."time")))
   ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=3598 loops=1)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (actual rows=5038 loops=1)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (actual rows=5038 loops=1)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
   ->  Sort (actual rows=1 loops=1)
         Sort Key: (max(_hyper_X_X_chunk."time"))
         Sort Method: quicksort 
         ->  Aggregate (actual rows=1 loops=1)
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=17990 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=20 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=25190 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=30 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=25190 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=30 loops=1)
(24 rows)

RESET enable_hashjoin;
SET enable_seqscan TO false;
-- test JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with USING
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 USING (time)
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test NATURAL JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  NATURAL INNER JOIN :TEST_TABLE o2
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=0 loops=1)
   ->  Sort (actual rows=0 loops=1)
         Sort Key: o1."time"
         Sort Method: quicksort 
         ->  Result (actual rows=0 loops=1)
               One-Time Filter: false
(6 rows)

-- test LEFT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  LEFT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test RIGHT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  RIGHT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with ON clause expression order switched
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o2.time = o1.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with equality condition in WHERE clause
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON TRUE
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with ORDER BY 2nd hypertable
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column and device_id
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
    AND o1.time = o2.time
  ORDER BY o1.time
  LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: ((o1_1."time" = o2_1."time") AND (o1_1.device_id = o2_1.device_id))
         ->  Sort (actual rows=100 loops=1)
               Sort Key: o1_1."time", o1_1.device_id
               Sort Method: quicksort 
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=17990 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=20 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (actual rows=25190 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=30 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (actual rows=25190 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=30 loops=1)
         ->  Sort (actual rows=100 loops=1)
               Sort Key: o2_1."time", o2_1.device_id
               Sort Method: quicksort 
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=17990 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=20 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (actual rows=25190 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=30 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (actual rows=25190 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=30 loops=1)
(23 rows)

-- test JOIN on device_id
-- should not use ordered append for 2nd hypertable
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
WHERE o1.device_id = 1
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Nested Loop (actual rows=100 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=1 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=1 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Append (actual rows=100 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 1)
(24 rows)

-- test JOIN on time column with implicit join
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1,
  :TEST_TABLE o2
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with 3 hypertables
-- should use 3 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
  INNER JOIN :TEST_TABLE o3 ON o1.time = o3.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
  AND o3.device_id = 3
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o3."time" = o1."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o3 (actual rows=100 loops=1)
               Order: o3."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o3_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_2 (actual rows=1 loops=1)
                           Index Cond: (device_id = 3)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o3_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_2 (never executed)
                           Index Cond: (device_id = 3)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o3_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_2 (never executed)
                           Index Cond: (device_id = 3)
         ->  Materialize (actual rows=100 loops=1)
               ->  Merge Join (actual rows=100 loops=1)
                     Merge Cond: (o1."time" = o2."time")
                     ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
                           Order: o1."time"
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                                 ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                                       Index Cond: (device_id = 1)
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                                 ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                                       Index Cond: (device_id = 1)
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                                 ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk (never executed)
                                       Index Cond: (device_id = 1)
                     ->  Materialize (actual rows=100 loops=1)
                           ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                                 Order: o2."time"
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                                       ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=1 loops=1)
                                             Index Cond: (device_id = 2)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                                       ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                             Index Cond: (device_id = 2)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                                       ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_4_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                             Index Cond: (device_id = 2)
(40 rows)

RESET enable_seqscan;
\set TEST_TABLE 'metrics_space_compressed'
\ir :TEST_QUERY_NAME
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- In the following test cases, we test that certain indexes are used. By using the
-- timescaledb.enable_decompression_sorted_merge optimization, we are pushing a sort node
-- below the DecompressChunk node, which operates on the batches. This could lead to flaky
-- tests because the input data is small and PostgreSQL switches from IndexScans to
-- SequentialScans. Disable the optimization for the following tests to ensure we have
-- stable query plans in all CI environments.
SET timescaledb.enable_decompression_sorted_merge = 0;
-- test LATERAL with ordered append in the outer query
:PREFIX
SELECT time,
  pg_typeof(l)
FROM :TEST_TABLE,
  LATERAL (
    SELECT *
    FROM (
      VALUES (1),
        (2)) v) l
ORDER BY time DESC
LIMIT 2;
QUERY PLAN
 Limit (actual rows=2 loops=1)
   ->  Sort (actual rows=2 loops=1)
         Sort Key: _hyper_X_X_chunk."time" DESC
         Sort Method: top-N heapsort 
         ->  Nested Loop (actual rows=136740 loops=1)
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=15114 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=15114 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=3598 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=10794 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=12 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=3598 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=4 loops=1)
               ->  Materialize (actual rows=2 loops=68370)
                     ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
(26 rows)

-- test LATERAL with ordered append in the lateral query
:PREFIX
SELECT time,
  pg_typeof(v)
FROM (
  VALUES (1),
    (2)) v,
  LATERAL (
    SELECT *
    FROM :TEST_TABLE
    ORDER BY time DESC
    LIMIT 2) l;
QUERY PLAN
 Nested Loop (actual rows=4 loops=1)
   ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
   ->  Materialize (actual rows=2 loops=2)
         ->  Subquery Scan on l (actual rows=2 loops=1)
               ->  Limit (actual rows=2 loops=1)
                     ->  Sort (actual rows=2 loops=1)
                           Sort Key: _hyper_X_X_chunk."time" DESC
                           Sort Method: top-N heapsort 
                           ->  Result (actual rows=68370 loops=1)
                                 ->  Append (actual rows=68370 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=15114 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=18 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=15114 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=18 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=3598 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=10794 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=12 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=3598 loops=1)
                                             ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=4 loops=1)
(28 rows)

-- test plan with best index is chosen
-- this should use device_id, time index
:PREFIX
SELECT time,
  device_id
FROM :TEST_TABLE
WHERE device_id = 1
ORDER BY time DESC
LIMIT 1;
QUERY PLAN
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics_space_compressed (actual rows=1 loops=1)
         Order: metrics_space_compressed."time" DESC
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=1 loops=1)
               ->  Sort (actual rows=1 loops=1)
                     Sort Key: compress_hyper_X_X_chunk._ts_meta_sequence_num
                     Sort Method: quicksort 
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                           Filter: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (never executed)
               ->  Sort (never executed)
                     Sort Key: compress_hyper_X_X_chunk._ts_meta_sequence_num
                     ->  Seq Scan on compress_hyper_X_X_chunk (never executed)
                           Filter: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (never executed)
               ->  Sort (never executed)
                     Sort Key: compress_hyper_X_X_chunk._ts_meta_sequence_num
                     ->  Seq Scan on compress_hyper_X_X_chunk (never executed)
                           Filter: (device_id = 1)
(19 rows)

-- test plan with best index is chosen
-- this should use time index
:PREFIX
SELECT time
FROM :TEST_TABLE
ORDER BY time DESC
LIMIT 1;
QUERY PLAN
 Limit (actual rows=1 loops=1)
   ->  Sort (actual rows=1 loops=1)
         Sort Key: _hyper_X_X_chunk."time" DESC
         Sort Method: top-N heapsort 
         ->  Append (actual rows=68370 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=15114 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=18 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=15114 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=18 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=3598 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=4 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=10794 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=12 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=3598 loops=1)
                     ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=4 loops=1)
(23 rows)

-- test LATERAL with correlated query
-- only last chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Sort (actual rows=1 loops=3)
               Sort Key: o."time" DESC
               Sort Method: top-N heapsort 
               ->  Result (actual rows=3600 loops=3)
                     ->  Custom Scan (ChunkAppend) on metrics_space_compressed o (actual rows=3600 loops=3)
                           ->  Merge Append (actual rows=0 loops=3)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_1 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_2 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 18
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_3 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                           ->  Merge Append (actual rows=0 loops=3)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_4 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_5 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 18
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_6 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                           ->  Merge Append (actual rows=3600 loops=3)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_7 (actual rows=720 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 813
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=2 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 2
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_8 (actual rows=2160 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 2438
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=5 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 7
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_9 (actual rows=720 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 813
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=2 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 2
(59 rows)

-- test LATERAL with correlated query
-- only 2nd chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-10'::timestamptz, '2000-01-11', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=2 loops=1)
   ->  Function Scan on generate_series g (actual rows=2 loops=1)
   ->  Limit (actual rows=1 loops=2)
         ->  Sort (actual rows=1 loops=2)
               Sort Key: o."time"
               Sort Method: top-N heapsort 
               ->  Result (actual rows=3600 loops=2)
                     ->  Custom Scan (ChunkAppend) on metrics_space_compressed o (actual rows=3600 loops=2)
                           ->  Merge Append (actual rows=0 loops=2)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_1 (actual rows=0 loops=2)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=2)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 4
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_2 (actual rows=0 loops=2)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=2)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 12
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_3 (actual rows=0 loops=2)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=2)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 4
                           ->  Merge Append (actual rows=3600 loops=2)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_4 (actual rows=720 loops=2)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 780
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=2 loops=2)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 4
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_5 (actual rows=2160 loops=2)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 2340
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=4 loops=2)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 14
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_6 (actual rows=720 loops=2)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 780
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=2 loops=2)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 4
                           ->  Merge Append (actual rows=0 loops=2)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_7 (actual rows=0 loops=2)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=2)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_8 (actual rows=0 loops=2)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=2)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 18
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_9 (actual rows=0 loops=2)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=2)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
(59 rows)

-- test startup and runtime exclusion together
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time < now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Sort (actual rows=1 loops=3)
               Sort Key: o."time" DESC
               Sort Method: top-N heapsort 
               ->  Result (actual rows=3600 loops=3)
                     ->  Custom Scan (ChunkAppend) on metrics_space_compressed o (actual rows=3600 loops=3)
                           ->  Merge Append (actual rows=0 loops=3)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_1 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_2 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 18
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_3 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                           ->  Merge Append (actual rows=0 loops=3)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_4 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_5 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 18
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_6 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                           ->  Merge Append (actual rows=3600 loops=3)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_7 (actual rows=720 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                       Rows Removed by Filter: 813
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=2 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 2
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_8 (actual rows=2160 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                       Rows Removed by Filter: 2438
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=5 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 7
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_9 (actual rows=720 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                       Rows Removed by Filter: 813
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=2 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 2
(59 rows)

-- test startup and runtime exclusion together
-- all chunks should be filtered
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time > now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
QUERY PLAN
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=0 loops=3)
         ->  Sort (actual rows=0 loops=3)
               Sort Key: o."time" DESC
               Sort Method: quicksort 
               ->  Result (actual rows=0 loops=3)
                     ->  Custom Scan (ChunkAppend) on metrics_space_compressed o (actual rows=0 loops=3)
                           ->  Merge Append (actual rows=0 loops=3)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_1 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_2 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 18
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_3 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                           ->  Merge Append (actual rows=0 loops=3)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_4 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_5 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 18
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_6 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=0 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 6
                           ->  Merge Append (actual rows=0 loops=3)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_7 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                       Rows Removed by Filter: 1533
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=2 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 2
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_8 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                       Rows Removed by Filter: 4598
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=5 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 7
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o_9 (actual rows=0 loops=3)
                                       Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                       Rows Removed by Filter: 1533
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=2 loops=3)
                                             Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                             Rows Removed by Filter: 2
(59 rows)

-- test JOIN
-- no exclusion on joined table because quals are not propagated yet
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.time < '2000-02-01'
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time;
QUERY PLAN
 Merge Join (actual rows=13674 loops=1)
   Merge Cond: (o1."time" = o2."time")
   ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=3598 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (actual rows=5038 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (actual rows=5038 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
   ->  Materialize (actual rows=13674 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=13674 loops=1)
               Order: o2."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=3598 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (actual rows=5038 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (actual rows=5038 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
(37 rows)

-- test JOIN
-- last chunk of o2 should not be executed
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT *
    FROM :TEST_TABLE o2
    ORDER BY time) o2 ON o1.time = o2.time
WHERE o1.time < '2000-01-08'
ORDER BY o1.time
LIMIT 10;
QUERY PLAN
 Limit (actual rows=10 loops=1)
   ->  Merge Join (actual rows=10 loops=1)
         Merge Cond: (o1_1."time" = o2_1."time")
         ->  Sort (actual rows=2 loops=1)
               Sort Key: o1_1."time"
               Sort Method: quicksort 
               ->  Append (actual rows=26390 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=3598 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (actual rows=10794 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=12 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (actual rows=3598 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_4 (actual rows=1680 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Rows Removed by Filter: 358
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=3 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                                 Rows Removed by Filter: 3
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_5 (actual rows=5040 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Rows Removed by Filter: 1074
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=9 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                                 Rows Removed by Filter: 9
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_6 (actual rows=1680 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Rows Removed by Filter: 358
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=3 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                                 Rows Removed by Filter: 3
         ->  Materialize (actual rows=10 loops=1)
               ->  Sort (actual rows=6 loops=1)
                     Sort Key: o2_1."time"
                     Sort Method: quicksort 
                     ->  Result (actual rows=68370 loops=1)
                           ->  Append (actual rows=68370 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=3598 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=4 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (actual rows=10794 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=12 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (actual rows=3598 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=4 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_4 (actual rows=5038 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=6 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_5 (actual rows=15114 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=18 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_6 (actual rows=5038 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=6 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_7 (actual rows=5038 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_8 (actual rows=15114 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=18 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_9 (actual rows=5038 loops=1)
                                       ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
(61 rows)

-- test join against max query
-- not ChunkAppend so no chunk exclusion
SET enable_hashjoin = FALSE;
:PREFIX
SELECT o1.time,
  o2.*
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT max(time) AS max_time
    FROM :TEST_TABLE) o2 ON o1.time = o2.max_time
WHERE o1.device_id = 1
ORDER BY time;
QUERY PLAN
 Merge Join (actual rows=1 loops=1)
   Merge Cond: (o1."time" = (max(_hyper_X_X_chunk."time")))
   ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=3598 loops=1)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (actual rows=5038 loops=1)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (actual rows=5038 loops=1)
               ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
   ->  Sort (actual rows=1 loops=1)
         Sort Key: (max(_hyper_X_X_chunk."time"))
         Sort Method: quicksort 
         ->  Aggregate (actual rows=1 loops=1)
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=3598 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=10794 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=12 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=3598 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=15114 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=15114 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_X_X_chunk (actual rows=6 loops=1)
(36 rows)

RESET enable_hashjoin;
SET enable_seqscan TO false;
-- test JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with USING
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 USING (time)
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test NATURAL JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  NATURAL INNER JOIN :TEST_TABLE o2
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=0 loops=1)
   ->  Sort (actual rows=0 loops=1)
         Sort Key: o1."time"
         Sort Method: quicksort 
         ->  Result (actual rows=0 loops=1)
               One-Time Filter: false
(6 rows)

-- test LEFT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  LEFT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test RIGHT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  RIGHT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with ON clause expression order switched
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o2.time = o1.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with equality condition in WHERE clause
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON TRUE
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with ORDER BY 2nd hypertable
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column and device_id
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
    AND o1.time = o2.time
  ORDER BY o1.time
  LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: ((o1_1."time" = o2_1."time") AND (o1_1.device_id = o2_1.device_id))
         ->  Sort (actual rows=100 loops=1)
               Sort Key: o1_1."time", o1_1.device_id
               Sort Method: quicksort 
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=3598 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (actual rows=10794 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=12 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (actual rows=3598 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_4 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_5 (actual rows=15114 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_6 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_7 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_8 (actual rows=15114 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_9 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=6 loops=1)
         ->  Sort (actual rows=100 loops=1)
               Sort Key: o2_1."time", o2_1.device_id
               Sort Method: quicksort 
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=3598 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (actual rows=10794 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=12 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (actual rows=3598 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_4 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_5 (actual rows=15114 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_6 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_7 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_8 (actual rows=15114 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_9 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=6 loops=1)
(47 rows)

-- test JOIN on device_id
-- should not use ordered append for 2nd hypertable
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
WHERE o1.device_id = 1
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Nested Loop (actual rows=100 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=1 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=1 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Append (actual rows=100 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 1)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk compress_hyper_X_X_chunk_1 (never executed)
                                 Index Cond: (device_id = 1)
(24 rows)

-- test JOIN on time column with implicit join
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1,
  :TEST_TABLE o2
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with 3 hypertables
-- should use 3 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
  INNER JOIN :TEST_TABLE o3 ON o1.time = o3.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
  AND o3.device_id = 3
ORDER BY o1.time
LIMIT 100;
QUERY PLAN
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o3."time" = o1."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o3 (actual rows=100 loops=1)
               Order: o3."time"
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o3_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 3)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o3_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 3)
               ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o3_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                           Index Cond: (device_id = 3)
         ->  Materialize (actual rows=100 loops=1)
               ->  Merge Join (actual rows=100 loops=1)
                     Merge Cond: (o1."time" = o2."time")
                     ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
                           Order: o1."time"
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_1 (actual rows=100 loops=1)
                                 ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                                       Index Cond: (device_id = 1)
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_2 (never executed)
                                 ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                       Index Cond: (device_id = 1)
                           ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o1_3 (never executed)
                                 ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                       Index Cond: (device_id = 1)
                     ->  Materialize (actual rows=100 loops=1)
                           ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                                 Order: o2."time"
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_1 (actual rows=100 loops=1)
                                       ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (actual rows=1 loops=1)
                                             Index Cond: (device_id = 2)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_2 (never executed)
                                       ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                             Index Cond: (device_id = 2)
                                 ->  Custom Scan (DecompressChunk) on _hyper_X_X_chunk o2_3 (never executed)
                                       ->  Index Scan Backward using compress_hyper_X_X_chunk__compressed_hypertable_6_device_id__t on compress_hyper_X_X_chunk (never executed)
                                             Index Cond: (device_id = 2)
(40 rows)

RESET enable_seqscan;
-- get results for all the queries
-- run queries on uncompressed hypertable and store result
\set PREFIX ''
\set PREFIX_VERBOSE ''
\set ECHO none
 table_name 
 i4418_1
(1 row)

 table_name 
 i4418_2
(1 row)

QUERY PLAN
 Sort (actual rows=20 loops=1)
   Sort Key: (time_bucket('@ 1 day'::interval, tbl1_1."time"))
   Sort Method: quicksort 
   ->  HashAggregate (actual rows=20 loops=1)
         Group Key: time_bucket('@ 1 day'::interval, tbl1_1."time")
         Batches: 1 
         ->  Merge Join (actual rows=9121 loops=1)
               Merge Cond: ((tbl1_1.device = tbl2_1.device) AND (tbl1_1."time" = tbl2_1."time"))
               ->  Sort (actual rows=9121 loops=1)
                     Sort Key: tbl1_1.device, tbl1_1."time"
                     Sort Method: quicksort 
                     ->  Append (actual rows=9121 loops=1)
                           ->  Seq Scan on _hyper_X_X_chunk tbl1_1 (actual rows=1300 loops=1)
                           ->  Seq Scan on _hyper_X_X_chunk tbl1_2 (actual rows=3360 loops=1)
                           ->  Seq Scan on _hyper_X_X_chunk tbl1_3 (actual rows=3360 loops=1)
                           ->  Seq Scan on _hyper_X_X_chunk tbl1_4 (actual rows=1101 loops=1)
               ->  Sort (actual rows=9121 loops=1)
                     Sort Key: tbl2_1.device, tbl2_1."time"
                     Sort Method: quicksort 
                     ->  Append (actual rows=9121 loops=1)
                           ->  Seq Scan on _hyper_X_X_chunk tbl2_1 (actual rows=1300 loops=1)
                           ->  Seq Scan on _hyper_X_X_chunk tbl2_2 (actual rows=3360 loops=1)
                           ->  Seq Scan on _hyper_X_X_chunk tbl2_3 (actual rows=3360 loops=1)
                           ->  Seq Scan on _hyper_X_X_chunk tbl2_4 (actual rows=1101 loops=1)
(24 rows)

